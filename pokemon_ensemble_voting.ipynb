{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2c558d",
   "metadata": {},
   "source": [
    "# Pokémon Battles — Ensemble XGBoost + LightGBM (Voting)\n",
    "Notebook che implementa ensemble tra XGBoost e LightGBM con:\n",
    "- **STESSE FEATURE** del notebook LightGBM ottimizzato\n",
    "- **STESSI IPERPARAMETRI** dal notebook LightGBM\n",
    "- 10-fold CV per entrambi i modelli\n",
    "- Voting Classifier (hard voting + soft voting)\n",
    "- Weighted voting con ottimizzazione pesi\n",
    "- Submission finale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6375e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297dafd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati...\n",
      "Train records: 10000, Test records: 5000\n",
      "Train records: 10000, Test records: 5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Percorsi ---\n",
    "train_file_path = 'train.jsonl'\n",
    "test_file_path = 'test.jsonl'\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "print('Caricamento dati...')\n",
    "train_raw = load_jsonl(train_file_path)\n",
    "test_raw = load_jsonl(test_file_path)\n",
    "print(f'Train records: {len(train_raw)}, Test records: {len(test_raw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a397d",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions\n",
    "NOTA: Copia TUTTE le funzioni dal notebook LightGBM per garantire identiche feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7102841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FE: 100%|██████████| 10000/10000 [00:12<00:00, 791.00it/s]\n",
      "\n",
      "FE: 100%|██████████| 5000/5000 [00:05<00:00, 846.56it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape train/test: (10000, 282) (5000, 281)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "      <th>p1_base_hp_sum</th>\n",
       "      <th>p1_base_hp_mean</th>\n",
       "      <th>p1_base_hp_max</th>\n",
       "      <th>p1_base_hp_min</th>\n",
       "      <th>p1_base_hp_std</th>\n",
       "      <th>p1_base_atk_sum</th>\n",
       "      <th>p1_base_atk_mean</th>\n",
       "      <th>p1_base_atk_max</th>\n",
       "      <th>...</th>\n",
       "      <th>team_hp_sum_minus_p2lead_hp</th>\n",
       "      <th>team_spa_mean_minus_p2spa</th>\n",
       "      <th>speed_advantage</th>\n",
       "      <th>n_unique_types_diff</th>\n",
       "      <th>damage_per_turn_diff</th>\n",
       "      <th>last_pair</th>\n",
       "      <th>p1_vs_lead_avg_effectiveness</th>\n",
       "      <th>p1_vs_lead_max_effectiveness</th>\n",
       "      <th>p1_super_effective_options</th>\n",
       "      <th>p1_se_options_vs_lead_bulk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>115.833333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.367179</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.070393</td>\n",
       "      <td>starmie_VS_snorlax</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.204534</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.012174</td>\n",
       "      <td>tauros_VS_alakazam</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>124.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.382753</td>\n",
       "      <td>505.0</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>495.0</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>snorlax_VS_gengar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65.362239</td>\n",
       "      <td>465.0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>655.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>345.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.014574</td>\n",
       "      <td>snorlax_VS_zapdos</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>685.0</td>\n",
       "      <td>114.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.794107</td>\n",
       "      <td>455.0</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.0</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>tauros_VS_chansey</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won  p1_base_hp_sum  p1_base_hp_mean  p1_base_hp_max  \\\n",
       "0          0           1           695.0       115.833333           250.0   \n",
       "1          1           1           740.0       123.333333           250.0   \n",
       "2          2           1           745.0       124.166667           250.0   \n",
       "3          3           1           730.0       121.666667           250.0   \n",
       "4          4           1           685.0       114.166667           250.0   \n",
       "\n",
       "   p1_base_hp_min  p1_base_hp_std  p1_base_atk_sum  p1_base_atk_mean  \\\n",
       "0            55.0       69.367179            435.0         72.500000   \n",
       "1            65.0       64.204534            435.0         72.500000   \n",
       "2            60.0       64.382753            505.0         84.166667   \n",
       "3            60.0       65.362239            465.0         77.500000   \n",
       "4            50.0       70.794107            455.0         75.833333   \n",
       "\n",
       "   p1_base_atk_max  ...  team_hp_sum_minus_p2lead_hp  \\\n",
       "0            110.0  ...                        635.0   \n",
       "1            110.0  ...                        685.0   \n",
       "2            130.0  ...                        495.0   \n",
       "3            110.0  ...                        655.0   \n",
       "4            110.0  ...                        625.0   \n",
       "\n",
       "   team_spa_mean_minus_p2spa  speed_advantage  n_unique_types_diff  \\\n",
       "0                   0.000000            365.0                    3   \n",
       "1                 -45.000000            250.0                    4   \n",
       "2                 -15.000000            345.0                    6   \n",
       "3                  33.333333            345.0                    6   \n",
       "4                  -2.500000            320.0                    4   \n",
       "\n",
       "   damage_per_turn_diff           last_pair  p1_vs_lead_avg_effectiveness  \\\n",
       "0             -0.070393  starmie_VS_snorlax                      1.083333   \n",
       "1             -0.012174  tauros_VS_alakazam                      1.000000   \n",
       "2             -0.000690   snorlax_VS_gengar                      1.000000   \n",
       "3             -0.014574   snorlax_VS_zapdos                      1.000000   \n",
       "4              0.006923   tauros_VS_chansey                      1.083333   \n",
       "\n",
       "   p1_vs_lead_max_effectiveness  p1_super_effective_options  \\\n",
       "0                           2.0                           1   \n",
       "1                           1.0                           0   \n",
       "2                           1.0                           0   \n",
       "3                           1.0                           0   \n",
       "4                           2.0                           1   \n",
       "\n",
       "   p1_se_options_vs_lead_bulk  \n",
       "0                    0.005405  \n",
       "1                    0.000000  \n",
       "2                    0.000000  \n",
       "3                    0.000000  \n",
       "4                    0.005405  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# === TYPE CHART (Gen 1) ===\n",
    "TYPE_CHART = {\n",
    "    'normal': {'rock': 0.5, 'ghost': 0},\n",
    "    'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ice': 2, 'bug': 2, 'rock': 0.5, 'dragon': 0.5},\n",
    "    'water': {'fire': 2, 'water': 0.5, 'grass': 0.5, 'ground': 2, 'rock': 2, 'dragon': 0.5},\n",
    "    'grass': {'fire': 0.5, 'water': 2, 'grass': 0.5, 'poison': 0.5, 'ground': 2, 'flying': 0.5, 'bug': 0.5, 'rock': 2, 'dragon': 0.5},\n",
    "    'electric': {'water': 2, 'grass': 0.5, 'electric': 0.5, 'ground': 0, 'flying': 2, 'dragon': 0.5},\n",
    "    'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ground': 2, 'flying': 2, 'dragon': 2},\n",
    "    'fighting': {'normal': 2, 'ice': 2, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2, 'ghost': 0},\n",
    "    'poison': {'grass': 2, 'poison': 0.5, 'ground': 0.5, 'bug': 2, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground': {'fire': 2, 'grass': 0.5, 'electric': 2, 'poison': 2, 'flying': 0, 'bug': 0.5, 'rock': 2},\n",
    "    'flying': {'grass': 2, 'electric': 0.5, 'fighting': 2, 'bug': 2, 'rock': 0.5},\n",
    "    'psychic': {'fighting': 2, 'poison': 2, 'psychic': 0.5, 'ghost': 0},\n",
    "    'bug': {'fire': 0.5, 'grass': 2, 'fighting': 0.5, 'poison': 2, 'flying': 0.5, 'psychic': 2, 'ghost': 0.5},\n",
    "    'rock': {'fire': 2, 'ice': 2, 'fighting': 0.5, 'ground': 0.5, 'flying': 2, 'bug': 2},\n",
    "    'ghost': {'normal': 0, 'psychic': 0, 'ghost': 2},\n",
    "    'dragon': {'dragon': 2}\n",
    "}\n",
    "\n",
    "def get_effectiveness(attack_type: str, defense_types: list) -> float:\n",
    "    if not attack_type or not defense_types:\n",
    "        return 1.0\n",
    "    eff = 1.0\n",
    "    for d in defense_types:\n",
    "        eff *= TYPE_CHART.get(attack_type, {}).get(d, 1.0)\n",
    "    return eff\n",
    "\n",
    "def calculate_type_advantage(team1: list, team2_lead: dict) -> dict:\n",
    "    out = {'p1_vs_lead_avg_effectiveness': 0.0, 'p1_vs_lead_max_effectiveness': 0.0, 'p1_super_effective_options': 0}\n",
    "    if not team1 or not team2_lead:\n",
    "        return out\n",
    "    lead_types = [t.lower() for t in team2_lead.get('types', [])]\n",
    "    if not lead_types:\n",
    "        return out\n",
    "    effs = []\n",
    "    for p in team1:\n",
    "        p_types = [t.lower() for t in p.get('types', [])]\n",
    "        max_eff = 0.0\n",
    "        for pt in p_types:\n",
    "            max_eff = max(max_eff, get_effectiveness(pt, lead_types))\n",
    "        effs.append(max_eff)\n",
    "    if not effs:\n",
    "        return out\n",
    "    out['p1_vs_lead_avg_effectiveness'] = float(np.mean(effs))\n",
    "    out['p1_vs_lead_max_effectiveness'] = float(np.max(effs))\n",
    "    out['p1_super_effective_options'] = int(sum(1 for e in effs if e >= 2))\n",
    "    return out\n",
    "\n",
    "def _entropy(counter: Counter) -> float:\n",
    "    total = sum(counter.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    ent = 0.0\n",
    "    for v in counter.values():\n",
    "        p = v / total\n",
    "        if p > 0:\n",
    "            ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "\n",
    "def team_aggregate_features(team: list, prefix: str = 'p1_') -> dict:\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    out = {}\n",
    "    vals = {s: [] for s in stats}\n",
    "    levels = []\n",
    "    types_counter = Counter()\n",
    "    names = []\n",
    "    for p in team:\n",
    "        names.append(p.get('name',''))\n",
    "        for s in stats:\n",
    "            vals[s].append(p.get(s, 0))\n",
    "        levels.append(p.get('level', 0))\n",
    "        for t in p.get('types', []):\n",
    "            types_counter[t.lower()] += 1\n",
    "    for s in stats:\n",
    "        arr = np.array(vals[s], dtype=float)\n",
    "        out[f'{prefix}{s}_sum'] = float(arr.sum())\n",
    "        out[f'{prefix}{s}_mean'] = float(arr.mean())\n",
    "        out[f'{prefix}{s}_max'] = float(arr.max())\n",
    "        out[f'{prefix}{s}_min'] = float(arr.min())\n",
    "        out[f'{prefix}{s}_std'] = float(arr.std())\n",
    "    level_arr = np.array(levels, dtype=float)\n",
    "    out[f'{prefix}level_mean'] = float(level_arr.mean()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}level_sum'] = float(level_arr.sum()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}n_unique_types'] = int(len(types_counter))\n",
    "    common_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']\n",
    "    for t in common_types:\n",
    "        out[f'{prefix}type_{t}_count'] = int(types_counter.get(t, 0))\n",
    "    out[f'{prefix}lead_name'] = names[0] if names else ''\n",
    "    out[f'{prefix}n_unique_names'] = int(len(set(names)))\n",
    "    out[f'{prefix}type_entropy'] = float(_entropy(types_counter))\n",
    "    spe_arr = np.array(vals['base_spe'], dtype=float)\n",
    "    out[f'{prefix}spe_p25'] = float(np.percentile(spe_arr, 25)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p50'] = float(np.percentile(spe_arr, 50)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p75'] = float(np.percentile(spe_arr, 75)) if spe_arr.size else 0.0\n",
    "    return out\n",
    "\n",
    "def lead_vs_lead_features(p1_lead: dict, p2_lead: dict) -> dict:\n",
    "    out = {}\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    for s in stats:\n",
    "        out[f'lead_diff_{s}'] = float(p1_lead.get(s,0) - p2_lead.get(s,0))\n",
    "    out['lead_speed_advantage'] = float(p1_lead.get('base_spe',0) - p2_lead.get('base_spe',0))\n",
    "    p1_types = [t.lower() for t in p1_lead.get('types', [])]\n",
    "    p2_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    max_eff = 0.0\n",
    "    for pt in p1_types:\n",
    "        max_eff = max(max_eff, get_effectiveness(pt, p2_types))\n",
    "    out['lead_p1_vs_p2_effectiveness'] = float(max_eff)\n",
    "    return out\n",
    "\n",
    "def lead_aggregate_features(pokemon: dict, prefix: str = 'p2_lead_') -> dict:\n",
    "    out = {}\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    for s in stats:\n",
    "        out[f'{prefix}{s}'] = float(pokemon.get(s,0))\n",
    "    out[f'{prefix}level'] = int(pokemon.get('level',0))\n",
    "    types = [x.lower() for x in pokemon.get('types', [])]\n",
    "    common_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']\n",
    "    for t in common_types:\n",
    "        out[f'{prefix}type_{t}'] = int(t in types)\n",
    "    out[f'{prefix}name'] = pokemon.get('name','')\n",
    "    out[f'{prefix}n_unique_types'] = int(len(set(types)))\n",
    "    return out\n",
    "\n",
    "def quick_boost_features_v2(record: dict) -> dict:\n",
    "    \"\"\"Feature ad alto impatto senza bisogno team completo P2\"\"\"\n",
    "    out = {}\n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    timeline = record.get('battle_timeline', [])\n",
    "    \n",
    "    if not p1_team:\n",
    "        return out\n",
    "    \n",
    "    # 1. Speed Control: quanti pokemon più veloci del lead avversario\n",
    "    p2_lead_spe = p2_lead.get('base_spe', 0)\n",
    "    faster_count = sum(1 for p in p1_team if p.get('base_spe', 0) > p2_lead_spe)\n",
    "    slower_count = sum(1 for p in p1_team if p.get('base_spe', 0) <= p2_lead_spe)\n",
    "    \n",
    "    out['p1_faster_than_lead_count'] = faster_count\n",
    "    out['p1_slower_than_lead_count'] = slower_count\n",
    "    out['p1_speed_control_ratio'] = faster_count / max(1, len(p1_team))\n",
    "    \n",
    "    # 2. Bulk vs Lead (resistenza)\n",
    "    p1_avg_bulk = np.mean([\n",
    "        p.get('base_hp', 0) * (p.get('base_def', 0) + p.get('base_spd', 0)) \n",
    "        for p in p1_team\n",
    "    ])\n",
    "    p2_lead_bulk = p2_lead.get('base_hp', 1) * (\n",
    "        p2_lead.get('base_def', 1) + p2_lead.get('base_spd', 1)\n",
    "    )\n",
    "    out['p1_avg_bulk_vs_lead'] = p1_avg_bulk / max(p2_lead_bulk, 1)\n",
    "    \n",
    "    # 3. Offensive Power\n",
    "    p1_total_atk = sum(p.get('base_atk', 0) + p.get('base_spa', 0) for p in p1_team)\n",
    "    p2_lead_offense = p2_lead.get('base_atk', 0) + p2_lead.get('base_spa', 0)\n",
    "    out['p1_total_offense'] = p1_total_atk\n",
    "    out['p1_offense_advantage'] = p1_total_atk / max(p2_lead_offense, 1)\n",
    "    \n",
    "    # 4. Type Coverage Score (contro il lead)\n",
    "    p2_lead_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    if p2_lead_types:\n",
    "        coverage_scores = []\n",
    "        for p in p1_team:\n",
    "            p_types = [t.lower() for t in p.get('types', [])]\n",
    "            max_eff = max([get_effectiveness(pt, p2_lead_types) for pt in p_types] or [1.0])\n",
    "            coverage_scores.append(max_eff)\n",
    "        \n",
    "        out['p1_avg_effectiveness_vs_lead'] = float(np.mean(coverage_scores))\n",
    "        out['p1_max_effectiveness_vs_lead'] = float(np.max(coverage_scores))\n",
    "        out['p1_se_count_vs_lead'] = sum(1 for s in coverage_scores if s >= 2.0)\n",
    "        out['p1_weak_count_vs_lead'] = sum(1 for s in coverage_scores if s <= 0.5)\n",
    "    \n",
    "    # 5. First blood: chi fa il primo KO?\n",
    "    if timeline:\n",
    "        first_p1_ko = False\n",
    "        first_p2_ko = False\n",
    "        \n",
    "        for turn in timeline[:30]:\n",
    "            p1_state = turn.get('p1_pokemon_state', {})\n",
    "            p2_state = turn.get('p2_pokemon_state', {})\n",
    "            \n",
    "            if not first_p2_ko and p2_state.get('fainted'):\n",
    "                first_p1_ko = True\n",
    "                out['p1_first_blood'] = 1\n",
    "                out['p1_first_blood_turn'] = turn.get('turn', 0)\n",
    "                break\n",
    "            \n",
    "            if not first_p1_ko and p1_state.get('fainted'):\n",
    "                first_p2_ko = True\n",
    "                out['p1_first_blood'] = 0\n",
    "                out['p1_first_blood_turn'] = turn.get('turn', 0)\n",
    "                break\n",
    "        \n",
    "        if not first_p1_ko and not first_p2_ko:\n",
    "            out['p1_first_blood'] = -1  # nessun KO nei primi 30 turni\n",
    "            out['p1_first_blood_turn'] = 0\n",
    "    \n",
    "    # 6. Team Level Advantage\n",
    "    p1_avg_level = np.mean([p.get('level', 50) for p in p1_team])\n",
    "    p2_lead_level = p2_lead.get('level', 50)\n",
    "    out['p1_avg_level_advantage'] = p1_avg_level - p2_lead_level\n",
    "    \n",
    "    # 7. Stat Product (indicatore qualità team)\n",
    "    p1_stat_products = []\n",
    "    for p in p1_team:\n",
    "        stat_product = (\n",
    "            p.get('base_hp', 1) * \n",
    "            p.get('base_atk', 1) * \n",
    "            p.get('base_def', 1) * \n",
    "            p.get('base_spa', 1) * \n",
    "            p.get('base_spd', 1) * \n",
    "            p.get('base_spe', 1)\n",
    "        )\n",
    "        p1_stat_products.append(stat_product)\n",
    "    \n",
    "    out['p1_avg_stat_product'] = float(np.mean(p1_stat_products))\n",
    "    out['p1_max_stat_product'] = float(np.max(p1_stat_products))\n",
    "    \n",
    "    p2_lead_stat_product = (\n",
    "        p2_lead.get('base_hp', 1) * \n",
    "        p2_lead.get('base_atk', 1) * \n",
    "        p2_lead.get('base_def', 1) * \n",
    "        p2_lead.get('base_spa', 1) * \n",
    "        p2_lead.get('base_spd', 1) * \n",
    "        p2_lead.get('base_spe', 1)\n",
    "    )\n",
    "    out['p1_stat_product_advantage'] = out['p1_avg_stat_product'] / max(p2_lead_stat_product, 1)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def summary_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline:\n",
    "        return {'tl_p1_moves':0,'tl_p2_moves':0,'tl_p1_est_damage':0.0,'tl_p2_est_damage':0.0,'damage_diff':0.0}\n",
    "    p1_moves = p2_moves = 0\n",
    "    p1_damage = p2_damage = 0.0\n",
    "    p1_last_active = p2_last_active = ''\n",
    "    p1_last_hp = p2_last_hp = np.nan\n",
    "    p1_fainted = p2_fainted = 0\n",
    "    p1_fainted_names = set()\n",
    "    p2_fainted_names = set()\n",
    "    last_p1_hp = {}\n",
    "    last_p2_hp = {}\n",
    "    p1_comeback_kos = 0\n",
    "    p2_comeback_kos = 0\n",
    "    p1_inflicted_statuses = Counter()\n",
    "    p2_inflicted_statuses = Counter()\n",
    "    p1_pokemon_statuses = {}\n",
    "    p2_pokemon_statuses = {}\n",
    "    p1_move_type_counts = Counter()\n",
    "    p2_move_type_counts = Counter()\n",
    "    p1_damage_first2 = 0.0\n",
    "    p2_damage_first2 = 0.0\n",
    "    p1_dmg_by_turn = {}\n",
    "    p2_dmg_by_turn = {}\n",
    "    seen_turns = set()\n",
    "    first_ko_turn_p1_taken = None\n",
    "    first_ko_turn_p1_inflicted = None\n",
    "    early_threshold = 10\n",
    "    p1_kos_early = p1_kos_late = 0\n",
    "    p2_kos_early = p2_kos_late = 0\n",
    "\n",
    "    for turn in timeline[:30]:\n",
    "        prev_p1_fainted, prev_p2_fainted = p1_fainted, p2_fainted\n",
    "        p1_state = turn.get('p1_pokemon_state',{}) or {}\n",
    "        p2_state = turn.get('p2_pokemon_state',{}) or {}\n",
    "        tnum = turn.get('turn', None)\n",
    "        if tnum is None:\n",
    "            tnum = (len(seen_turns) + 1)\n",
    "        seen_turns.add(tnum)\n",
    "\n",
    "        if p1_state.get('name'):\n",
    "            p1_last_active = p1_state.get('name')\n",
    "        if p2_state.get('name'):\n",
    "            p2_last_active = p2_state.get('name')\n",
    "\n",
    "        if p1_state.get('fainted') and p1_state.get('name') not in p1_fainted_names:\n",
    "            p1_fainted += 1\n",
    "            p1_fainted_names.add(p1_state.get('name'))\n",
    "            if first_ko_turn_p1_taken is None:\n",
    "                first_ko_turn_p1_taken = tnum\n",
    "            if tnum <= early_threshold: p2_kos_early += 1\n",
    "            else: p2_kos_late += 1\n",
    "        if p2_state.get('fainted') and p2_state.get('name') not in p2_fainted_names:\n",
    "            p2_fainted += 1\n",
    "            p2_fainted_names.add(p2_state.get('name'))\n",
    "            if first_ko_turn_p1_inflicted is None:\n",
    "                first_ko_turn_p1_inflicted = tnum\n",
    "            if tnum <= early_threshold: p1_kos_early += 1\n",
    "            else: p1_kos_late += 1\n",
    "\n",
    "        p2_name, p2_hp = p2_state.get('name'), p2_state.get('hp_pct')\n",
    "        if p2_name and p2_hp is not None:\n",
    "            prev_hp = last_p2_hp.get(p2_name)\n",
    "            if prev_hp is not None:\n",
    "                delta = max(0.0, prev_hp - p2_hp)\n",
    "                p1_damage += delta\n",
    "                p1_dmg_by_turn[tnum] = p1_dmg_by_turn.get(tnum, 0.0) + delta\n",
    "                if turn.get('turn',999) <= 2:\n",
    "                    p1_damage_first2 += delta\n",
    "            last_p2_hp[p2_name] = p2_hp\n",
    "\n",
    "        p1_name, p1_hp = p1_state.get('name'), p1_state.get('hp_pct')\n",
    "        if p1_name and p1_hp is not None:\n",
    "            prev_hp = last_p1_hp.get(p1_name)\n",
    "            if prev_hp is not None:\n",
    "                delta = max(0.0, prev_hp - p1_hp)\n",
    "                p2_damage += delta\n",
    "                p2_dmg_by_turn[tnum] = p2_dmg_by_turn.get(tnum, 0.0) + delta\n",
    "                if turn.get('turn',999) <= 2:\n",
    "                    p2_damage_first2 += delta\n",
    "            last_p1_hp[p1_name] = p1_hp\n",
    "\n",
    "        damage_diff_so_far = p1_damage - p2_damage\n",
    "        if p2_fainted > prev_p2_fainted and damage_diff_so_far < -1.0:\n",
    "            p1_comeback_kos += 1\n",
    "        if p1_fainted > prev_p1_fainted and damage_diff_so_far > 1.0:\n",
    "            p2_comeback_kos += 1\n",
    "\n",
    "        p2_status = p2_state.get('status')\n",
    "        if p2_name and p2_status and p2_pokemon_statuses.get(p2_name) != p2_status:\n",
    "            p1_inflicted_statuses[p2_status] += 1\n",
    "            p2_pokemon_statuses[p2_name] = p2_status\n",
    "        p1_status = p1_state.get('status')\n",
    "        if p1_name and p1_status and p1_pokemon_statuses.get(p1_name) != p1_status:\n",
    "            p2_inflicted_statuses[p1_status] += 1\n",
    "            p1_pokemon_statuses[p1_name] = p1_status\n",
    "\n",
    "        p1_move = turn.get('p1_move_details') or {}\n",
    "        p2_move = turn.get('p2_move_details') or {}\n",
    "        if p1_move and p1_move.get('type'):\n",
    "            p1_move_type_counts[(p1_move.get('type') or '').lower()] += 1\n",
    "        if p2_move and p2_move.get('type'):\n",
    "            p2_move_type_counts[(p2_move.get('type') or '').lower()] += 1\n",
    "        if turn.get('p1_move_details'):\n",
    "            p1_moves += 1\n",
    "        if turn.get('p2_move_details'):\n",
    "            p2_moves += 1\n",
    "        p1_last_hp = p1_state.get('hp_pct', np.nan)\n",
    "        p2_last_hp = p2_state.get('hp_pct', np.nan)\n",
    "\n",
    "    out['tl_p1_moves'] = int(p1_moves)\n",
    "    out['tl_p2_moves'] = int(p2_moves)\n",
    "    out['tl_p1_est_damage'] = float(p1_damage)\n",
    "    out['tl_p2_est_damage'] = float(p2_damage)\n",
    "    out['tl_p1_fainted'] = int(p1_fainted)\n",
    "    out['tl_p2_fainted'] = int(p2_fainted)\n",
    "    turns_count = max(1, len(seen_turns))\n",
    "    out['tl_p1_fainted_rate'] = float(out['tl_p1_fainted'] / turns_count)\n",
    "    out['tl_p2_fainted_rate'] = float(out['tl_p2_fainted'] / turns_count)\n",
    "    out['damage_diff'] = float(p1_damage - p2_damage)\n",
    "    out['fainted_diff'] = int(p1_fainted - p2_fainted)\n",
    "    out['tl_p1_last_hp'] = float(p1_last_hp) if not np.isnan(p1_last_hp) else 0.0\n",
    "    out['tl_p2_last_hp'] = float(p2_last_hp) if not np.isnan(p2_last_hp) else 0.0\n",
    "    out['tl_p1_last_active'] = p1_last_active\n",
    "    out['tl_p2_last_active'] = p2_last_active\n",
    "    if p1_team:\n",
    "        p1_total_hp_sum = sum(p.get('base_hp',0) for p in p1_team)\n",
    "        p1_avg_def = np.mean([p.get('base_def',0) for p in p1_team] or [0])\n",
    "        p1_avg_spd = np.mean([p.get('base_spd',0) for p in p1_team] or [0])\n",
    "        out['tl_p2_damage_vs_p1_hp_pool'] = float(p2_damage / (p1_total_hp_sum + 1e-6))\n",
    "        out['tl_p1_defensive_endurance'] = float((p1_avg_def + p1_avg_spd) / (p2_damage + 1e-6))\n",
    "    out['tl_p1_comeback_kos'] = int(p1_comeback_kos)\n",
    "    out['tl_p2_comeback_kos'] = int(p2_comeback_kos)\n",
    "    out['tl_comeback_kos_diff'] = int(p1_comeback_kos - p2_comeback_kos)\n",
    "\n",
    "    common_statuses = ['brn','par','slp','frz','psn','tox']\n",
    "    for status in common_statuses:\n",
    "        out[f'tl_p1_inflicted_{status}_count'] = int(p1_inflicted_statuses.get(status,0))\n",
    "        out[f'tl_p2_inflicted_{status}_count'] = int(p2_inflicted_statuses.get(status,0))\n",
    "        out[f'tl_inflicted_{status}_diff'] = int(p1_inflicted_statuses.get(status,0) - p2_inflicted_statuses.get(status,0))\n",
    "\n",
    "    common_move_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying','ghost','bug','poison','fighting']\n",
    "    for mt in common_move_types:\n",
    "        out[f'tl_p1_move_type_{mt}_count'] = int(p1_move_type_counts.get(mt,0))\n",
    "        out[f'tl_p2_move_type_{mt}_count'] = int(p2_move_type_counts.get(mt,0))\n",
    "        out[f'tl_move_type_{mt}_count_diff'] = int(p1_move_type_counts.get(mt,0) - p2_move_type_counts.get(mt,0))\n",
    "\n",
    "    out['tl_p1_damage_first2'] = float(p1_damage_first2)\n",
    "    out['tl_p2_damage_first2'] = float(p2_damage_first2)\n",
    "    out['tl_first2_damage_diff'] = float(p1_damage_first2 - p2_damage_first2)\n",
    "    out['tl_turns_count'] = int(turns_count)\n",
    "    out['tl_p1_moves_rate'] = float(p1_moves / turns_count)\n",
    "    out['tl_p2_moves_rate'] = float(p2_moves / turns_count)\n",
    "    out['tl_p1_damage_per_turn'] = float(p1_damage / turns_count)\n",
    "    out['tl_p2_damage_per_turn'] = float(p2_damage / turns_count)\n",
    "    out['tl_damage_rate_diff'] = float(out['tl_p1_damage_per_turn'] - out['tl_p2_damage_per_turn'])\n",
    "\n",
    "    if seen_turns:\n",
    "        recent_turns = sorted(seen_turns)[-5:]\n",
    "        p1_last5 = sum(p1_dmg_by_turn.get(t,0.0) for t in recent_turns)\n",
    "        p2_last5 = sum(p2_dmg_by_turn.get(t,0.0) for t in recent_turns)\n",
    "    else:\n",
    "        p1_last5 = p2_last5 = 0.0\n",
    "    out['tl_p1_damage_last5'] = float(p1_last5)\n",
    "    out['tl_p2_damage_last5'] = float(p2_last5)\n",
    "    out['tl_last5_damage_diff'] = float(p1_last5 - p2_last5)\n",
    "    out['tl_p1_last5_damage_ratio'] = float(p1_last5 / (p1_damage + 1e-6))\n",
    "    out['tl_p2_last5_damage_ratio'] = float(p2_last5 / (p2_damage + 1e-6))\n",
    "    out['tl_last5_damage_ratio_diff'] = float(out['tl_p1_last5_damage_ratio'] - out['tl_p2_last5_damage_ratio'])\n",
    "\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns)\n",
    "        w = np.linspace(1.0, 2.0, num=len(ts))\n",
    "        w = w / (w.sum() + 1e-9)\n",
    "        adv = [(p1_dmg_by_turn.get(t,0.0) - p2_dmg_by_turn.get(t,0.0)) for t in ts]\n",
    "        out['tl_weighted_damage_diff'] = float(np.dot(w, adv))\n",
    "    else:\n",
    "        out['tl_weighted_damage_diff'] = 0.0\n",
    "\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns)\n",
    "        cum = 0.0\n",
    "        signs = []\n",
    "        for t in ts:\n",
    "            cum += (p1_dmg_by_turn.get(t,0.0) - p2_dmg_by_turn.get(t,0.0))\n",
    "            s = 1 if cum > 1e-9 else (-1 if cum < -1e-9 else 0)\n",
    "            if s != 0:\n",
    "                if not signs or signs[-1] != s:\n",
    "                    signs.append(s)\n",
    "        sign_flips = max(0, len(signs) - 1)\n",
    "        comeback_flag = 1 if (len(signs) >= 2 and signs[0] != signs[-1]) else 0\n",
    "    else:\n",
    "        sign_flips = 0\n",
    "        comeback_flag = 0\n",
    "    out['tl_damage_adv_sign_flips'] = int(sign_flips)\n",
    "    out['tl_comeback_flag'] = int(comeback_flag)\n",
    "\n",
    "    out['tl_first_ko_turn_p1_inflicted'] = int(first_ko_turn_p1_inflicted or 0)\n",
    "    out['tl_first_ko_turn_p1_taken'] = int(first_ko_turn_p1_taken or 0)\n",
    "    out['tl_first_ko_turn_diff'] = int((first_ko_turn_p1_inflicted or 0) - (first_ko_turn_p1_taken or 0))\n",
    "    out['tl_kos_early_p1'] = int(p1_kos_early)\n",
    "    out['tl_kos_late_p1'] = int(p1_kos_late)\n",
    "    out['tl_kos_early_p2'] = int(p2_kos_early)\n",
    "    out['tl_kos_late_p2'] = int(p2_kos_late)\n",
    "\n",
    "    for status in common_statuses:\n",
    "        c1 = p1_inflicted_statuses.get(status,0)\n",
    "        c2 = p2_inflicted_statuses.get(status,0)\n",
    "        out[f'tl_p1_inflicted_{status}_rate'] = float(c1 / turns_count)\n",
    "        out[f'tl_p2_inflicted_{status}_rate'] = float(c2 / turns_count)\n",
    "        out[f'tl_inflicted_{status}_rate_diff'] = float((c1 - c2) / turns_count)\n",
    "\n",
    "    return out\n",
    "\n",
    "def extract_move_coverage_from_timeline(timeline: list, prefix: str = 'p1_') -> dict:\n",
    "    \"\"\"Analizza le mosse usate nella timeline per coverage e strategia\"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    move_types_used = set()\n",
    "    move_categories_used = Counter()  # physical, special, status\n",
    "    unique_moves = set()\n",
    "    stab_count = 0  # mosse con STAB\n",
    "    \n",
    "    for turn in timeline[:30]:\n",
    "        move_details = turn.get(f'{prefix[:-1]}_move_details')\n",
    "        pokemon_state = turn.get(f'{prefix[:-1]}_pokemon_state', {})\n",
    "        \n",
    "        if not move_details:\n",
    "            continue\n",
    "            \n",
    "        move_name = move_details.get('name', '')\n",
    "        move_type = (move_details.get('type') or '').lower()\n",
    "        move_category = move_details.get('category', '')\n",
    "        \n",
    "        if move_name:\n",
    "            unique_moves.add(move_name)\n",
    "        \n",
    "        if move_type:\n",
    "            move_types_used.add(move_type)\n",
    "        \n",
    "        if move_category:\n",
    "            move_categories_used[move_category] += 1\n",
    "        \n",
    "        # Check STAB (Same Type Attack Bonus)\n",
    "        pokemon_types = [t.lower() for t in pokemon_state.get('types', [])]\n",
    "        if move_type in pokemon_types:\n",
    "            stab_count += 1\n",
    "    \n",
    "    out[f'{prefix}tl_unique_move_types'] = len(move_types_used)\n",
    "    out[f'{prefix}tl_unique_moves_used'] = len(unique_moves)\n",
    "    out[f'{prefix}tl_stab_moves'] = stab_count\n",
    "    out[f'{prefix}tl_physical_moves'] = move_categories_used.get('physical', 0)\n",
    "    out[f'{prefix}tl_special_moves'] = move_categories_used.get('special', 0)\n",
    "    out[f'{prefix}tl_status_moves'] = move_categories_used.get('status', 0)\n",
    "    \n",
    "    # Coverage score: più tipi = migliore coverage\n",
    "    out[f'{prefix}tl_coverage_score'] = len(move_types_used) / max(1, len(unique_moves))\n",
    "    \n",
    "    # Offensive vs defensive strategy\n",
    "    total_moves = sum(move_categories_used.values())\n",
    "    if total_moves > 0:\n",
    "        out[f'{prefix}tl_offensive_ratio'] = (\n",
    "            move_categories_used.get('physical', 0) + \n",
    "            move_categories_used.get('special', 0)\n",
    "        ) / total_moves\n",
    "        out[f'{prefix}tl_status_ratio'] = move_categories_used.get('status', 0) / total_moves\n",
    "    else:\n",
    "        out[f'{prefix}tl_offensive_ratio'] = 0.0\n",
    "        out[f'{prefix}tl_status_ratio'] = 0.0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def ability_features(team: list, prefix: str) -> dict:\n",
    "    immunity_abilities = {'levitate':0,'volt_absorb':0,'water_absorb':0,'flash_fire':0}\n",
    "    stat_drop_abilities = {'intimidate':0}\n",
    "    weather_abilities = {'drought':0,'drizzle':0,'sand_stream':0}\n",
    "    out = {}\n",
    "    for pokemon in team:\n",
    "        ability = (pokemon.get('ability','') or '').lower().replace(' ','_')\n",
    "        if ability in immunity_abilities:\n",
    "            immunity_abilities[ability] += 1\n",
    "        if ability in stat_drop_abilities:\n",
    "            stat_drop_abilities[ability] += 1\n",
    "        if ability in weather_abilities:\n",
    "            weather_abilities[ability] += 1\n",
    "    for ability,count in immunity_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    for ability,count in stat_drop_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    for ability,count in weather_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    out[f'{prefix}total_immunity_abilities'] = int(sum(immunity_abilities.values()))\n",
    "    out[f'{prefix}total_stat_drop_abilities'] = int(sum(stat_drop_abilities.values()))\n",
    "    return out\n",
    "\n",
    "def momentum_features(timeline: list) -> dict:\n",
    "    \"\"\"Analizza momentum shift turn-by-turn\"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    if not timeline:\n",
    "        return out\n",
    "    \n",
    "    p1_hp_changes = []\n",
    "    p2_hp_changes = []\n",
    "    p1_advantages = []  # vantaggio cumulativo\n",
    "    \n",
    "    cumulative_advantage = 0.0\n",
    "    \n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        p1_state = turn.get('p1_pokemon_state', {})\n",
    "        p2_state = turn.get('p2_pokemon_state', {})\n",
    "        \n",
    "        # Calcola HP change\n",
    "        p1_hp = p1_state.get('hp_pct', 100)\n",
    "        p2_hp = p2_state.get('hp_pct', 100)\n",
    "        \n",
    "        # Vantaggio = HP P1 - HP P2 (semplificato)\n",
    "        turn_advantage = p1_hp - p2_hp\n",
    "        cumulative_advantage += turn_advantage\n",
    "        p1_advantages.append(cumulative_advantage)\n",
    "    \n",
    "    if p1_advantages:\n",
    "        # Trend momentum\n",
    "        x = np.arange(len(p1_advantages))\n",
    "        slope, intercept = np.polyfit(x, p1_advantages, 1)\n",
    "        \n",
    "        out['p1_momentum_slope'] = float(slope)\n",
    "        out['p1_momentum_intercept'] = float(intercept)\n",
    "        out['p1_final_advantage'] = float(p1_advantages[-1])\n",
    "        \n",
    "        # Volatilità vantaggio\n",
    "        out['p1_advantage_volatility'] = float(np.std(p1_advantages))\n",
    "        \n",
    "        # Max/min advantage\n",
    "        out['p1_max_advantage'] = float(np.max(p1_advantages))\n",
    "        out['p1_min_advantage'] = float(np.min(p1_advantages))\n",
    "        out['p1_advantage_range'] = float(np.max(p1_advantages) - np.min(p1_advantages))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def extract_opponent_team_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    \"\"\"Ricostruisci info team avversario dalla timeline\"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    # Set di pokemon visti\n",
    "    p2_pokemon_seen = set()\n",
    "    p2_pokemon_types = []\n",
    "    p2_pokemon_stats = []\n",
    "    \n",
    "    for turn in timeline[:30]:\n",
    "        p2_state = turn.get('p2_pokemon_state', {})\n",
    "        if not p2_state:\n",
    "            continue\n",
    "        \n",
    "        p2_name = p2_state.get('name')\n",
    "        if p2_name and p2_name not in p2_pokemon_seen:\n",
    "            p2_pokemon_seen.add(p2_name)\n",
    "            \n",
    "            # Raccogli tipi\n",
    "            types = p2_state.get('types', [])\n",
    "            p2_pokemon_types.extend([t.lower() for t in types])\n",
    "            \n",
    "            # Prova a estrarre stats se disponibili (potrebbero non esserci)\n",
    "            # ma possiamo inferire da HP loss patterns\n",
    "    \n",
    "    out['p2_tl_unique_pokemon_seen'] = len(p2_pokemon_seen)\n",
    "    out['p2_tl_switches_count'] = len(p2_pokemon_seen) - 1  # switches = pokemon visti - 1\n",
    "    \n",
    "    # Type diversity avversario\n",
    "    p2_type_counter = Counter(p2_pokemon_types)\n",
    "    out['p2_tl_unique_types_seen'] = len(p2_type_counter)\n",
    "    out['p2_tl_type_entropy'] = _entropy(p2_type_counter)\n",
    "    \n",
    "    # Matchup contro team P1 basato su tipi visti\n",
    "    if p2_pokemon_types and p1_team:\n",
    "        matchup_advantages = 0\n",
    "        for p1_poke in p1_team:\n",
    "            p1_types = [t.lower() for t in p1_poke.get('types', [])]\n",
    "            for p1_type in p1_types:\n",
    "                # Conta quanti tipi avversari siamo super-effective contro\n",
    "                for p2_type in set(p2_pokemon_types):\n",
    "                    eff = get_effectiveness(p1_type, [p2_type])\n",
    "                    if eff >= 2.0:\n",
    "                        matchup_advantages += 1\n",
    "        \n",
    "        out['p1_vs_p2_tl_type_advantages'] = matchup_advantages\n",
    "        out['p1_vs_p2_tl_type_advantages_per_poke'] = matchup_advantages / max(1, len(p1_team))\n",
    "    \n",
    "    # Aggression score: quanti switch fa l'avversario?\n",
    "    total_turns = len(timeline[:30])\n",
    "    out['p2_tl_switch_rate'] = len(p2_pokemon_seen) / max(1, total_turns)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def prepare_record_features(record: dict, max_turns: int = 30) -> dict:\n",
    "    out = {}\n",
    "    out['battle_id'] = record.get('battle_id')\n",
    "    if 'player_won' in record:\n",
    "        out['player_won'] = int(bool(record.get('player_won')))\n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    out.update(team_aggregate_features(p1_team, prefix='p1_'))\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    out.update(lead_aggregate_features(p2_lead, prefix='p2_lead_'))\n",
    "    out.update(ability_features(p1_team, prefix='p1_'))\n",
    "    p1_lead = p1_team[0] if p1_team else {}\n",
    "    out.update(lead_vs_lead_features(p1_lead, p2_lead))\n",
    "    out.update(ability_features([p2_lead], prefix='p2_lead_'))\n",
    "    out['p1_intimidate_vs_lead'] = 1 if out.get('p1_ability_intimidate_count',0) > 0 else 0\n",
    "    tl = record.get('battle_timeline', [])\n",
    "    out.update(summary_from_timeline(tl[:max_turns], p1_team))\n",
    "\n",
    "    out.update(extract_move_coverage_from_timeline(tl, prefix='p1_'))\n",
    "    out.update(extract_move_coverage_from_timeline(tl, prefix='p2_'))\n",
    "    out.update(extract_opponent_team_from_timeline(tl, p1_team))\n",
    "    out.update(quick_boost_features_v2(record))\n",
    "    out.update(momentum_features(tl))\n",
    "\n",
    "    out['team_hp_sum_minus_p2lead_hp'] = out.get('p1_base_hp_sum', 0) - out.get('p2_lead_base_hp', 0)\n",
    "    out['team_spa_mean_minus_p2spa'] = out.get('p1_base_spa_mean', 0) - out.get('p2_lead_base_spa', 0)\n",
    "    out['speed_advantage'] = out.get('p1_base_spe_sum', 0) - out.get('p2_lead_base_spe', 0)\n",
    "    out['n_unique_types_diff'] = out.get('p1_n_unique_types', 0) - out.get('p2_lead_n_unique_types', 1)\n",
    "    p1_moves = max(out.get('tl_p1_moves',1),1)\n",
    "    p2_moves = max(out.get('tl_p2_moves',1),1)\n",
    "    out['damage_per_turn_diff'] = (out.get('tl_p1_est_damage',0.0)/p1_moves) - (out.get('tl_p2_est_damage',0.0)/p2_moves)\n",
    "    out['last_pair'] = f\"{out.get('tl_p1_last_active','')}_VS_{out.get('tl_p2_last_active','')}\"\n",
    "    out.update(calculate_type_advantage(p1_team, p2_lead))\n",
    "    p2_lead_bulk = out.get('p2_lead_base_def',1) + out.get('p2_lead_base_spd',1)\n",
    "    out['p1_se_options_vs_lead_bulk'] = out.get('p1_super_effective_options',0) / (p2_lead_bulk + 1e-6)\n",
    "    p2_team = record.get('p2_team_details', [])\n",
    "    if p2_team:\n",
    "        out.update(team_aggregate_features(p2_team, prefix='p2_'))\n",
    "        out['team_hp_sum_diff'] = out.get('p1_base_hp_sum',0) - out.get('p2_base_hp_sum',0)\n",
    "        out['team_spa_mean_diff'] = out.get('p1_base_spa_mean',0) - out.get('p2_base_spa_mean',0)\n",
    "        out['team_spe_mean_diff'] = out.get('p1_base_spe_mean',0) - out.get('p2_base_spe_mean',0)\n",
    "        out['n_unique_types_team_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_n_unique_types',0)\n",
    "    return out\n",
    "\n",
    "def create_features_from_raw(data: list) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for b in tqdm(data, desc='FE'):\n",
    "        try:\n",
    "            feat = prepare_record_features(b, max_turns=30)\n",
    "            if 'battle_id' not in feat:\n",
    "                feat['battle_id'] = b.get('battle_id')\n",
    "            rows.append(feat)\n",
    "        except Exception as e:\n",
    "            rows.append({'battle_id': b.get('battle_id'), 'error': 1})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if 'player_won' in df.columns:\n",
    "        df['player_won'] = df['player_won'].astype(int)\n",
    "    return df.fillna(0)\n",
    "\n",
    "train_df = create_features_from_raw(train_raw)\n",
    "test_df = create_features_from_raw(test_raw)\n",
    "print('Feature shape train/test:', train_df.shape, test_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd79a6c",
   "metadata": {},
   "source": [
    "## Preprocessing - STESSE FEATURE del notebook LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "def4f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Usando 275 feature (identiche al notebook LightGBM)\n",
      "Preprocessing completato.\n",
      "Dataset size: (10000, 275)\n"
     ]
    }
   ],
   "source": [
    "# ✅ USA LE STESSE FEATURE del notebook LightGBM ottimizzato\n",
    "# Copia esatta dal notebook pokemon_lightgbm_cv.ipynb\n",
    "\n",
    "exclude_cols = ['battle_id', 'player_won']\n",
    "string_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "exclude_cols.extend(string_cols)\n",
    "\n",
    "ALL_NUMERIC_FEATURES = [c for c in train_df.columns if c not in exclude_cols]\n",
    "\n",
    "# ⚠️ IMPORTANTE: Usa FEATURES_FINAL se hai fatto feature selection nel notebook LightGBM\n",
    "# Altrimenti usa ALL_NUMERIC_FEATURES\n",
    "# Per ora uso tutte le feature (come nel notebook LightGBM originale)\n",
    "FEATURES = ALL_NUMERIC_FEATURES\n",
    "\n",
    "print(f'✅ Usando {len(FEATURES)} feature (identiche al notebook LightGBM)')\n",
    "\n",
    "# Preprocessing identico\n",
    "num_df = train_df[FEATURES].astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "medians = num_df.median()\n",
    "train_imputed = num_df.fillna(medians)\n",
    "train_preproc_df = train_imputed.copy()\n",
    "\n",
    "y = train_df['player_won'].astype(int).values\n",
    "X = train_preproc_df.values\n",
    "\n",
    "print('Preprocessing completato.')\n",
    "print('Dataset size:', X.shape)\n",
    "\n",
    "# Allinea test\n",
    "test_aligned = test_df.reindex(columns=FEATURES, fill_value=np.nan).astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "test_imputed = test_aligned.fillna(medians)\n",
    "test_preproc_df = pd.DataFrame(test_imputed.values, columns=FEATURES, index=test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f399bd",
   "metadata": {},
   "source": [
    "## Model Hyperparameters - IDENTICI al notebook LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ IPERPARAMETRI IDENTICI dal notebook pokemon_lightgbm_cv.ipynb\n",
    "# Questi sono i best params trovati con Optuna nel notebook LightGBM\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "    'learning_rate': 0.048286,\n",
    "    'n_estimators': 600,\n",
    "    'num_leaves': 74,\n",
    "    'max_depth': 7,\n",
    "    'min_child_samples': 95,\n",
    "    'min_child_weight': 0.046044,\n",
    "    'reg_alpha': 0.001554,\n",
    "    'reg_lambda': 0.000040,\n",
    "    'subsample': 0.578947,\n",
    "    'colsample_bytree': 0.575072,\n",
    "    'subsample_freq': 2,\n",
    "    'min_split_gain': 0.741598,\n",
    "    'max_bin': 320\n",
    "}\n",
    "\n",
    "# ✅ XGBoost params - equivalenti configurati per matching\n",
    "# Mappo i parametri LightGBM a XGBoost per coerenza\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'seed': 42,\n",
    "    'learning_rate': 0.048286,  # STESSO di LightGBM\n",
    "    'n_estimators': 600,         # STESSO di LightGBM\n",
    "    'max_depth': 7,              # STESSO di LightGBM\n",
    "    'min_child_weight': 0.046,   # Equivalente a min_child_weight LightGBM\n",
    "    'gamma': 0.741,              # Equivalente a min_split_gain\n",
    "    'subsample': 0.579,          # STESSO di LightGBM\n",
    "    'colsample_bytree': 0.575,   # STESSO di LightGBM\n",
    "    'reg_alpha': 0.001554,       # STESSO di LightGBM\n",
    "    'reg_lambda': 0.000040,      # STESSO di LightGBM\n",
    "    'tree_method': 'hist',\n",
    "    'max_bin': 320,              # STESSO di LightGBM\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"✅ Hyperparameters configurati (IDENTICI al notebook LightGBM)\")\n",
    "print(f\"\\nLightGBM params: {lgb_params}\")\n",
    "print(f\"\\nXGBoost params: {xgb_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257fb14",
   "metadata": {},
   "source": [
    "## 10-Fold CV - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a8960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "10-FOLD CV - LIGHTGBM\n",
      "======================================================================\n",
      "LightGBM Fold 1: val_acc=81.60%\n",
      "LightGBM Fold 1: val_acc=81.60%\n",
      "LightGBM Fold 2: val_acc=84.50%\n",
      "LightGBM Fold 2: val_acc=84.50%\n",
      "LightGBM Fold 3: val_acc=83.20%\n",
      "LightGBM Fold 3: val_acc=83.20%\n",
      "LightGBM Fold 4: val_acc=84.10%\n",
      "LightGBM Fold 4: val_acc=84.10%\n",
      "LightGBM Fold 5: val_acc=83.70%\n",
      "LightGBM Fold 5: val_acc=83.70%\n",
      "LightGBM Fold 6: val_acc=83.20%\n",
      "LightGBM Fold 6: val_acc=83.20%\n",
      "LightGBM Fold 7: val_acc=82.30%\n",
      "LightGBM Fold 7: val_acc=82.30%\n",
      "LightGBM Fold 8: val_acc=82.80%\n",
      "LightGBM Fold 8: val_acc=82.80%\n",
      "LightGBM Fold 9: val_acc=81.60%\n",
      "LightGBM Fold 9: val_acc=81.60%\n",
      "LightGBM Fold 10: val_acc=84.60%\n",
      "\n",
      "✅ LightGBM Mean CV Accuracy: 83.16% ± 1.04%\n",
      "LightGBM Fold 10: val_acc=84.60%\n",
      "\n",
      "✅ LightGBM Mean CV Accuracy: 83.16% ± 1.04%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"10-FOLD CV - LIGHTGBM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "    'learning_rate' : 0.048286,\n",
    "    'n_estimators' : 600,\n",
    "    'num_leaves' : 74,\n",
    "    'max_depth' : 7,\n",
    "    'min_child_samples' : 95,\n",
    "    'min_child_weight' : 0.046044,\n",
    "    'reg_alpha' : 0.001554,\n",
    "    'reg_lambda' : 0.000040,\n",
    "    'subsample' : 0.578947,\n",
    "    'colsample_bytree' : 0.575072,\n",
    "    'subsample_freq' : 2,\n",
    "    'min_split_gain' : 0.741598,\n",
    "    'max_bin' : 320\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_accuracies = []\n",
    "lgb_oof_preds = np.zeros(len(X))  # Out-of-fold predictions\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, y_pred_val)\n",
    "    lgb_accuracies.append(val_acc)\n",
    "    \n",
    "    # Salva OOF predictions per ensemble\n",
    "    lgb_oof_preds[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    print(f'LightGBM Fold {fold_idx}: val_acc={val_acc*100:.2f}%')\n",
    "\n",
    "lgb_mean_acc = np.mean(lgb_accuracies)\n",
    "print(f'\\n✅ LightGBM Mean CV Accuracy: {lgb_mean_acc*100:.2f}% ± {np.std(lgb_accuracies)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd105b1c",
   "metadata": {},
   "source": [
    "## 10-Fold CV - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ead4e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "10-FOLD CV - XGBOOST\n",
      "======================================================================\n",
      "XGBoost Fold 1: val_acc=80.80%\n",
      "XGBoost Fold 1: val_acc=80.80%\n",
      "XGBoost Fold 2: val_acc=84.90%\n",
      "XGBoost Fold 2: val_acc=84.90%\n",
      "XGBoost Fold 3: val_acc=83.00%\n",
      "XGBoost Fold 3: val_acc=83.00%\n",
      "XGBoost Fold 4: val_acc=83.80%\n",
      "XGBoost Fold 4: val_acc=83.80%\n",
      "XGBoost Fold 5: val_acc=83.70%\n",
      "XGBoost Fold 5: val_acc=83.70%\n",
      "XGBoost Fold 6: val_acc=83.10%\n",
      "XGBoost Fold 6: val_acc=83.10%\n",
      "XGBoost Fold 7: val_acc=81.60%\n",
      "XGBoost Fold 7: val_acc=81.60%\n",
      "XGBoost Fold 8: val_acc=83.00%\n",
      "XGBoost Fold 8: val_acc=83.00%\n",
      "XGBoost Fold 9: val_acc=81.50%\n",
      "XGBoost Fold 9: val_acc=81.50%\n",
      "XGBoost Fold 10: val_acc=84.30%\n",
      "\n",
      "✅ XGBoost Mean CV Accuracy: 82.97% ± 1.24%\n",
      "XGBoost Fold 10: val_acc=84.30%\n",
      "\n",
      "✅ XGBoost Mean CV Accuracy: 82.97% ± 1.24%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"10-FOLD CV - XGBOOST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'max_bin': 256,\n",
    "    'learning_rate': 0.035,\n",
    "    'n_estimators': 900,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 9,\n",
    "    'gamma': 0.5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bynode': 0.7,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'reg_alpha': 0.4,\n",
    "    'reg_lambda': 10.0,\n",
    "    'max_delta_step': 1,\n",
    "    'early_stopping_rounds': 30  # ✅ AGGIUNTO QUI come parametro del costruttore\n",
    "}\n",
    "\n",
    "xgb_accuracies = []\n",
    "xgb_oof_preds = np.zeros(len(X))\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    clf = xgb.XGBClassifier(**xgb_params)\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, y_pred_val)\n",
    "    xgb_accuracies.append(val_acc)\n",
    "    \n",
    "    # Salva OOF predictions\n",
    "    xgb_oof_preds[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    print(f'XGBoost Fold {fold_idx}: val_acc={val_acc*100:.2f}%')\n",
    "\n",
    "xgb_mean_acc = np.mean(xgb_accuracies)\n",
    "print(f'\\n✅ XGBoost Mean CV Accuracy: {xgb_mean_acc*100:.2f}% ± {np.std(xgb_accuracies)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475f08f",
   "metadata": {},
   "source": [
    "## Ensemble - Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718e5390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENSEMBLE - HARD VOTING\n",
      "======================================================================\n",
      "Hard Voting Accuracy: 83.08%\n",
      "LightGBM solo: 83.16%\n",
      "XGBoost solo:  82.97%\n",
      "Improvement: -0.08%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ENSEMBLE - HARD VOTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Hard voting: predizione basata su maggioranza\n",
    "lgb_hard = (lgb_oof_preds >= 0.5).astype(int)\n",
    "xgb_hard = (xgb_oof_preds >= 0.5).astype(int)\n",
    "\n",
    "# Majority vote\n",
    "hard_vote_preds = ((lgb_hard + xgb_hard) >= 1).astype(int)\n",
    "hard_vote_acc = accuracy_score(y, hard_vote_preds)\n",
    "\n",
    "print(f\"Hard Voting Accuracy: {hard_vote_acc*100:.2f}%\")\n",
    "print(f\"LightGBM solo: {lgb_mean_acc*100:.2f}%\")\n",
    "print(f\"XGBoost solo:  {xgb_mean_acc*100:.2f}%\")\n",
    "print(f\"Improvement: {(hard_vote_acc - max(lgb_mean_acc, xgb_mean_acc))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c17b5",
   "metadata": {},
   "source": [
    "## Ensemble - Soft Voting (Simple Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3805c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENSEMBLE - SOFT VOTING (SIMPLE AVERAGE)\n",
      "======================================================================\n",
      "Soft Voting (0.5/0.5) Accuracy: 83.22%\n",
      "Improvement over best single: 0.06%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ENSEMBLE - SOFT VOTING (SIMPLE AVERAGE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Soft voting: media delle probabilità\n",
    "soft_vote_probs = (lgb_oof_preds + xgb_oof_preds) / 2\n",
    "soft_vote_preds = (soft_vote_probs >= 0.5).astype(int)\n",
    "soft_vote_acc = accuracy_score(y, soft_vote_preds)\n",
    "\n",
    "print(f\"Soft Voting (0.5/0.5) Accuracy: {soft_vote_acc*100:.2f}%\")\n",
    "print(f\"Improvement over best single: {(soft_vote_acc - max(lgb_mean_acc, xgb_mean_acc))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07074ca6",
   "metadata": {},
   "source": [
    "## Ensemble - Weighted Soft Voting (Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78bdfd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENSEMBLE - WEIGHTED SOFT VOTING (GRID SEARCH)\n",
      "======================================================================\n",
      "\n",
      "✅ Best Weights Found:\n",
      "   LightGBM weight: 0.50\n",
      "   XGBoost weight:  0.50\n",
      "   Accuracy: 83.22%\n",
      "\n",
      "Top 10 weight combinations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_lgb</th>\n",
       "      <th>w_xgb</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.8322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    w_lgb  w_xgb  accuracy\n",
       "10   0.50   0.50    0.8322\n",
       "18   0.90   0.10    0.8322\n",
       "9    0.45   0.55    0.8321\n",
       "12   0.60   0.40    0.8320\n",
       "16   0.80   0.20    0.8319\n",
       "11   0.55   0.45    0.8319\n",
       "15   0.75   0.25    0.8319\n",
       "19   0.95   0.05    0.8318\n",
       "17   0.85   0.15    0.8318\n",
       "8    0.40   0.60    0.8317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Weight search results saved to 'ensemble_weight_search.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ENSEMBLE - WEIGHTED SOFT VOTING (GRID SEARCH)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Trova pesi ottimali con grid search\n",
    "best_weight = 0.5\n",
    "best_weighted_acc = 0.0\n",
    "\n",
    "weights_to_try = np.arange(0.0, 1.01, 0.05)\n",
    "results = []\n",
    "\n",
    "for w_lgb in weights_to_try:\n",
    "    w_xgb = 1.0 - w_lgb\n",
    "    weighted_probs = w_lgb * lgb_oof_preds + w_xgb * xgb_oof_preds\n",
    "    weighted_preds = (weighted_probs >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y, weighted_preds)\n",
    "    results.append({'w_lgb': w_lgb, 'w_xgb': w_xgb, 'accuracy': acc})\n",
    "    \n",
    "    if acc > best_weighted_acc:\n",
    "        best_weighted_acc = acc\n",
    "        best_weight = w_lgb\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n✅ Best Weights Found:\")\n",
    "print(f\"   LightGBM weight: {best_weight:.2f}\")\n",
    "print(f\"   XGBoost weight:  {1-best_weight:.2f}\")\n",
    "print(f\"   Accuracy: {best_weighted_acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTop 10 weight combinations:\")\n",
    "display(results_df.sort_values('accuracy', ascending=False).head(10))\n",
    "\n",
    "# Salva risultati\n",
    "results_df.to_csv('ensemble_weight_search.csv', index=False)\n",
    "print(f\"\\n✅ Weight search results saved to 'ensemble_weight_search.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weight vs accuracy\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['w_lgb'], results_df['accuracy'] * 100, marker='o', linewidth=2)\n",
    "    plt.axvline(best_weight, color='red', linestyle='--', label=f'Best weight={best_weight:.2f}')\n",
    "    plt.axhline(lgb_mean_acc * 100, color='blue', linestyle='--', alpha=0.5, label=f'LGB only={lgb_mean_acc*100:.2f}%')\n",
    "    plt.axhline(xgb_mean_acc * 100, color='green', linestyle='--', alpha=0.5, label=f'XGB only={xgb_mean_acc*100:.2f}%')\n",
    "    plt.xlabel('LightGBM Weight')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Ensemble Accuracy vs Weight (LightGBM)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ensemble_weight_curve.png', dpi=150)\n",
    "    print(\"✅ Plot saved to 'ensemble_weight_curve.png'\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Plot failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60cc9f",
   "metadata": {},
   "source": [
    "## Final 10-Fold CV - Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb598a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL 10-FOLD CV - VOTING ENSEMBLE\n",
      "======================================================================\n",
      "Ensemble Fold 1: val_acc=81.50%\n",
      "Ensemble Fold 1: val_acc=81.50%\n",
      "Ensemble Fold 2: val_acc=84.90%\n",
      "Ensemble Fold 2: val_acc=84.90%\n",
      "Ensemble Fold 3: val_acc=83.40%\n",
      "Ensemble Fold 3: val_acc=83.40%\n",
      "Ensemble Fold 4: val_acc=84.70%\n",
      "Ensemble Fold 4: val_acc=84.70%\n",
      "Ensemble Fold 5: val_acc=83.40%\n",
      "Ensemble Fold 5: val_acc=83.40%\n",
      "Ensemble Fold 6: val_acc=83.20%\n",
      "Ensemble Fold 6: val_acc=83.20%\n",
      "Ensemble Fold 7: val_acc=81.90%\n",
      "Ensemble Fold 7: val_acc=81.90%\n",
      "Ensemble Fold 8: val_acc=83.20%\n",
      "Ensemble Fold 8: val_acc=83.20%\n",
      "Ensemble Fold 9: val_acc=81.70%\n",
      "Ensemble Fold 9: val_acc=81.70%\n",
      "Ensemble Fold 10: val_acc=84.30%\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS (usando STESSI params del notebook LightGBM):\n",
      "======================================================================\n",
      "LightGBM:     83.16% ± 1.04%\n",
      "XGBoost:      82.97% ± 1.24%\n",
      "Ensemble:     83.22% ± 1.15%\n",
      "\n",
      "Improvement:  +0.06%\n",
      "\n",
      "📊 Config: 275 features, LGB weight=0.50\n",
      "Ensemble Fold 10: val_acc=84.30%\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS (usando STESSI params del notebook LightGBM):\n",
      "======================================================================\n",
      "LightGBM:     83.16% ± 1.04%\n",
      "XGBoost:      82.97% ± 1.24%\n",
      "Ensemble:     83.22% ± 1.15%\n",
      "\n",
      "Improvement:  +0.06%\n",
      "\n",
      "📊 Config: 275 features, LGB weight=0.50\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL 10-FOLD CV - VOTING ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ensemble_accuracies = []\n",
    "ensemble_oof_preds = np.zeros(len(X))\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Train both models\n",
    "    lgb_clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    xgb_clf = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    lgb_clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], \n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)])\n",
    "    xgb_clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)  # ✅ RIMOSSO early_stopping_rounds\n",
    "    \n",
    "    # Weighted soft voting con best weights\n",
    "    lgb_probs = lgb_clf.predict_proba(X_val)[:, 1]\n",
    "    xgb_probs = xgb_clf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    ensemble_probs = best_weight * lgb_probs + (1 - best_weight) * xgb_probs\n",
    "    ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "    \n",
    "    val_acc = accuracy_score(y_val, ensemble_preds)\n",
    "    ensemble_accuracies.append(val_acc)\n",
    "    ensemble_oof_preds[val_idx] = ensemble_probs\n",
    "    \n",
    "    print(f'Ensemble Fold {fold_idx}: val_acc={val_acc*100:.2f}%')\n",
    "\n",
    "ensemble_mean_acc = np.mean(ensemble_accuracies)\n",
    "print(f'\\n' + '='*70)\n",
    "print(f'FINAL RESULTS (usando STESSI params del notebook LightGBM):')\n",
    "print(f'='*70)\n",
    "print(f'LightGBM:     {lgb_mean_acc*100:.2f}% ± {np.std(lgb_accuracies)*100:.2f}%')\n",
    "print(f'XGBoost:      {xgb_mean_acc*100:.2f}% ± {np.std(xgb_accuracies)*100:.2f}%')\n",
    "print(f'Ensemble:     {ensemble_mean_acc*100:.2f}% ± {np.std(ensemble_accuracies)*100:.2f}%')\n",
    "print(f'\\nImprovement:  +{(ensemble_mean_acc - max(lgb_mean_acc, xgb_mean_acc))*100:.2f}%')\n",
    "print(f'\\n📊 Config: {len(FEATURES)} features, LGB weight={best_weight:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12265917",
   "metadata": {},
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d579fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SUBMISSION - ENSEMBLE VOTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train final models su tutto il dataset\n",
    "print(\"Training LightGBM on full dataset...\")\n",
    "final_lgb = lgb.LGBMClassifier(**lgb_params)\n",
    "final_lgb.fit(X, y)\n",
    "\n",
    "print(\"Training XGBoost on full dataset...\")\n",
    "final_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "final_xgb.fit(X, y)\n",
    "\n",
    "# Predict su test con weighted voting\n",
    "print(\"Predicting on test set...\")\n",
    "X_test_matrix = test_preproc_df.values\n",
    "\n",
    "lgb_test_probs = final_lgb.predict_proba(X_test_matrix)[:, 1]\n",
    "xgb_test_probs = final_xgb.predict_proba(X_test_matrix)[:, 1]\n",
    "\n",
    "# Ensemble con best weights\n",
    "ensemble_test_probs = best_weight * lgb_test_probs + (1 - best_weight) * xgb_test_probs\n",
    "ensemble_test_preds = (ensemble_test_probs >= 0.5).astype(int)\n",
    "\n",
    "# Crea submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': ensemble_test_preds.astype(np.int64)\n",
    "})\n",
    "\n",
    "submission_path = 'submission_ensemble_voting.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Submission saved to '{submission_path}'\")\n",
    "print(f\"Models: LightGBM ({best_weight:.2f}) + XGBoost ({1-best_weight:.2f})\")\n",
    "print(f\"Features: {len(FEATURES)} (identiche al notebook LightGBM)\")\n",
    "print(f\"Expected CV Accuracy: {ensemble_mean_acc*100:.2f}% ± {np.std(ensemble_accuracies)*100:.2f}%\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(submission_df['player_won'].value_counts())\n",
    "print(f\"\\nPreview:\")\n",
    "display(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45713b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Salva anche predizioni individuali per confronto\n",
    "lgb_submission = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': final_lgb.predict(X_test_matrix).astype(np.int64)\n",
    "})\n",
    "lgb_submission.to_csv('submission_lightgbm_only.csv', index=False)\n",
    "\n",
    "xgb_submission = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': final_xgb.predict(X_test_matrix).astype(np.int64)\n",
    "})\n",
    "xgb_submission.to_csv('submission_xgboost_only.csv', index=False)\n",
    "\n",
    "print(\"✅ Individual model submissions also saved:\")\n",
    "print(\"   - submission_lightgbm_only.csv\")\n",
    "print(\"   - submission_xgboost_only.csv\")\n",
    "print(\"   - submission_ensemble_voting.csv (RECOMMENDED)\")\n",
    "print(\"\\n📋 Summary:\")\n",
    "print(f\"   • {len(FEATURES)} features (same as LightGBM notebook)\")\n",
    "print(f\"   • LGB params: Optuna-optimized from LightGBM notebook\")\n",
    "print(f\"   • XGB params: Mapped from LGB params for consistency\")\n",
    "print(f\"   • Ensemble weight: {best_weight:.2f} LGB + {1-best_weight:.2f} XGB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
