{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b7eeca",
   "metadata": {},
   "source": [
    "# Pokémon battles — XGBoost with 10-fold outer CV + Grid Search\n",
    "Notebook breve che esegue: feature engineering, split train/val/test, 10-fold outer CV con GridSearchCV interno, valutazione per fold, valutazione su holdout e generazione submission.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aebef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati...\n",
      "Train records: 10000, Test records: 5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Percorsi (modificare se necessario) ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "train_file_path = 'train.jsonl'\n",
    "test_file_path = 'test.jsonl'\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "print('Caricamento dati...')\n",
    "train_raw = load_jsonl(train_file_path)\n",
    "test_raw = load_jsonl(test_file_path)\n",
    "print(f'Train records: {len(train_raw)}, Test records: {len(test_raw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e15c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FE: 100%|██████████| 10000/10000 [00:05<00:00, 1770.65it/s]\n",
      "FE: 100%|██████████| 5000/5000 [00:02<00:00, 1825.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape train/test: (10000, 232) (5000, 231)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "      <th>p1_base_hp_sum</th>\n",
       "      <th>p1_base_hp_mean</th>\n",
       "      <th>p1_base_hp_max</th>\n",
       "      <th>p1_base_hp_min</th>\n",
       "      <th>p1_base_hp_std</th>\n",
       "      <th>p1_base_atk_sum</th>\n",
       "      <th>p1_base_atk_mean</th>\n",
       "      <th>p1_base_atk_max</th>\n",
       "      <th>...</th>\n",
       "      <th>team_hp_sum_minus_p2lead_hp</th>\n",
       "      <th>team_spa_mean_minus_p2spa</th>\n",
       "      <th>speed_advantage</th>\n",
       "      <th>n_unique_types_diff</th>\n",
       "      <th>damage_per_turn_diff</th>\n",
       "      <th>last_pair</th>\n",
       "      <th>p1_vs_lead_avg_effectiveness</th>\n",
       "      <th>p1_vs_lead_max_effectiveness</th>\n",
       "      <th>p1_super_effective_options</th>\n",
       "      <th>p1_se_options_vs_lead_bulk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>115.833333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.367179</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.070393</td>\n",
       "      <td>starmie_VS_snorlax</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.204534</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.012174</td>\n",
       "      <td>tauros_VS_alakazam</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>124.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.382753</td>\n",
       "      <td>505.0</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>495.0</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>snorlax_VS_gengar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65.362239</td>\n",
       "      <td>465.0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>655.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>345.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.014574</td>\n",
       "      <td>snorlax_VS_zapdos</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>685.0</td>\n",
       "      <td>114.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.794107</td>\n",
       "      <td>455.0</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.0</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>tauros_VS_chansey</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won  p1_base_hp_sum  p1_base_hp_mean  p1_base_hp_max  \\\n",
       "0          0           1           695.0       115.833333           250.0   \n",
       "1          1           1           740.0       123.333333           250.0   \n",
       "2          2           1           745.0       124.166667           250.0   \n",
       "3          3           1           730.0       121.666667           250.0   \n",
       "4          4           1           685.0       114.166667           250.0   \n",
       "\n",
       "   p1_base_hp_min  p1_base_hp_std  p1_base_atk_sum  p1_base_atk_mean  \\\n",
       "0            55.0       69.367179            435.0         72.500000   \n",
       "1            65.0       64.204534            435.0         72.500000   \n",
       "2            60.0       64.382753            505.0         84.166667   \n",
       "3            60.0       65.362239            465.0         77.500000   \n",
       "4            50.0       70.794107            455.0         75.833333   \n",
       "\n",
       "   p1_base_atk_max  ...  team_hp_sum_minus_p2lead_hp  \\\n",
       "0            110.0  ...                        635.0   \n",
       "1            110.0  ...                        685.0   \n",
       "2            130.0  ...                        495.0   \n",
       "3            110.0  ...                        655.0   \n",
       "4            110.0  ...                        625.0   \n",
       "\n",
       "   team_spa_mean_minus_p2spa  speed_advantage  n_unique_types_diff  \\\n",
       "0                   0.000000            365.0                    3   \n",
       "1                 -45.000000            250.0                    4   \n",
       "2                 -15.000000            345.0                    6   \n",
       "3                  33.333333            345.0                    6   \n",
       "4                  -2.500000            320.0                    4   \n",
       "\n",
       "   damage_per_turn_diff           last_pair  p1_vs_lead_avg_effectiveness  \\\n",
       "0             -0.070393  starmie_VS_snorlax                      1.083333   \n",
       "1             -0.012174  tauros_VS_alakazam                      1.000000   \n",
       "2             -0.000690   snorlax_VS_gengar                      1.000000   \n",
       "3             -0.014574   snorlax_VS_zapdos                      1.000000   \n",
       "4              0.006923   tauros_VS_chansey                      1.083333   \n",
       "\n",
       "   p1_vs_lead_max_effectiveness  p1_super_effective_options  \\\n",
       "0                           2.0                           1   \n",
       "1                           1.0                           0   \n",
       "2                           1.0                           0   \n",
       "3                           1.0                           0   \n",
       "4                           2.0                           1   \n",
       "\n",
       "   p1_se_options_vs_lead_bulk  \n",
       "0                    0.005405  \n",
       "1                    0.000000  \n",
       "2                    0.000000  \n",
       "3                    0.000000  \n",
       "4                    0.005405  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# === TYPE CHART (Gen 1) ===\n",
    "TYPE_CHART = {\n",
    "    'normal': {'rock': 0.5, 'ghost': 0},\n",
    "    'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ice': 2, 'bug': 2, 'rock': 0.5, 'dragon': 0.5},\n",
    "    'water': {'fire': 2, 'water': 0.5, 'grass': 0.5, 'ground': 2, 'rock': 2, 'dragon': 0.5},\n",
    "    'grass': {'fire': 0.5, 'water': 2, 'grass': 0.5, 'poison': 0.5, 'ground': 2, 'flying': 0.5, 'bug': 0.5, 'rock': 2, 'dragon': 0.5},\n",
    "    'electric': {'water': 2, 'grass': 0.5, 'electric': 0.5, 'ground': 0, 'flying': 2, 'dragon': 0.5},\n",
    "    'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ground': 2, 'flying': 2, 'dragon': 2},\n",
    "    'fighting': {'normal': 2, 'ice': 2, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2, 'ghost': 0},\n",
    "    'poison': {'grass': 2, 'poison': 0.5, 'ground': 0.5, 'bug': 2, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground': {'fire': 2, 'grass': 0.5, 'electric': 2, 'poison': 2, 'flying': 0, 'bug': 0.5, 'rock': 2},\n",
    "    'flying': {'grass': 2, 'electric': 0.5, 'fighting': 2, 'bug': 2, 'rock': 0.5},\n",
    "    'psychic': {'fighting': 2, 'poison': 2, 'psychic': 0.5, 'ghost': 0},\n",
    "    'bug': {'fire': 0.5, 'grass': 2, 'fighting': 0.5, 'poison': 2, 'flying': 0.5, 'psychic': 2, 'ghost': 0.5},\n",
    "    'rock': {'fire': 2, 'ice': 2, 'fighting': 0.5, 'ground': 0.5, 'flying': 2, 'bug': 2},\n",
    "    'ghost': {'normal': 0, 'psychic': 0, 'ghost': 2},\n",
    "    'dragon': {'dragon': 2}\n",
    "}\n",
    "\n",
    "def get_effectiveness(attack_type: str, defense_types: list) -> float:\n",
    "    if not attack_type or not defense_types:\n",
    "        return 1.0\n",
    "    eff = 1.0\n",
    "    for d in defense_types:\n",
    "        eff *= TYPE_CHART.get(attack_type, {}).get(d, 1.0)\n",
    "    return eff\n",
    "\n",
    "def calculate_type_advantage(team1: list, team2_lead: dict) -> dict:\n",
    "    out = {'p1_vs_lead_avg_effectiveness': 0.0, 'p1_vs_lead_max_effectiveness': 0.0, 'p1_super_effective_options': 0}\n",
    "    if not team1 or not team2_lead:\n",
    "        return out\n",
    "    lead_types = [t.lower() for t in team2_lead.get('types', [])]\n",
    "    if not lead_types:\n",
    "        return out\n",
    "    effs = []\n",
    "    for p in team1:\n",
    "        p_types = [t.lower() for t in p.get('types', [])]\n",
    "        max_eff = 0.0\n",
    "        for pt in p_types:\n",
    "            max_eff = max(max_eff, get_effectiveness(pt, lead_types))\n",
    "        effs.append(max_eff)\n",
    "    if not effs:\n",
    "        return out\n",
    "    out['p1_vs_lead_avg_effectiveness'] = float(np.mean(effs))\n",
    "    out['p1_vs_lead_max_effectiveness'] = float(np.max(effs))\n",
    "    out['p1_super_effective_options'] = int(sum(1 for e in effs if e >= 2))\n",
    "    return out\n",
    "\n",
    "def _entropy(counter: Counter) -> float:\n",
    "    total = sum(counter.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    ent = 0.0\n",
    "    for v in counter.values():\n",
    "        p = v / total\n",
    "        if p > 0:\n",
    "            ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "\n",
    "def team_aggregate_features(team: list, prefix: str = 'p1_') -> dict:\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    out = {}\n",
    "    vals = {s: [] for s in stats}\n",
    "    levels = []\n",
    "    types_counter = Counter()\n",
    "    names = []\n",
    "    for p in team:\n",
    "        names.append(p.get('name',''))\n",
    "        for s in stats:\n",
    "            vals[s].append(p.get(s, 0))\n",
    "        levels.append(p.get('level', 0))\n",
    "        for t in p.get('types', []):\n",
    "            types_counter[t.lower()] += 1\n",
    "    for s in stats:\n",
    "        arr = np.array(vals[s], dtype=float)\n",
    "        out[f'{prefix}{s}_sum'] = float(arr.sum())\n",
    "        out[f'{prefix}{s}_mean'] = float(arr.mean())\n",
    "        out[f'{prefix}{s}_max'] = float(arr.max())\n",
    "        out[f'{prefix}{s}_min'] = float(arr.min())\n",
    "        out[f'{prefix}{s}_std'] = float(arr.std())\n",
    "    level_arr = np.array(levels, dtype=float)\n",
    "    out[f'{prefix}level_mean'] = float(level_arr.mean()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}level_sum'] = float(level_arr.sum()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}n_unique_types'] = int(len(types_counter))\n",
    "    common_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']\n",
    "    for t in common_types:\n",
    "        out[f'{prefix}type_{t}_count'] = int(types_counter.get(t, 0))\n",
    "    out[f'{prefix}lead_name'] = names[0] if names else ''\n",
    "    out[f'{prefix}n_unique_names'] = int(len(set(names)))\n",
    "    out[f'{prefix}type_entropy'] = float(_entropy(types_counter))\n",
    "    spe_arr = np.array(vals['base_spe'], dtype=float)\n",
    "    out[f'{prefix}spe_p25'] = float(np.percentile(spe_arr, 25)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p50'] = float(np.percentile(spe_arr, 50)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p75'] = float(np.percentile(spe_arr, 75)) if spe_arr.size else 0.0\n",
    "    return out\n",
    "\n",
    "def lead_vs_lead_features(p1_lead: dict, p2_lead: dict) -> dict:\n",
    "    out = {}\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    for s in stats:\n",
    "        out[f'lead_diff_{s}'] = float(p1_lead.get(s,0) - p2_lead.get(s,0))\n",
    "    out['lead_speed_advantage'] = float(p1_lead.get('base_spe',0) - p2_lead.get('base_spe',0))\n",
    "    p1_types = [t.lower() for t in p1_lead.get('types', [])]\n",
    "    p2_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    max_eff = 0.0\n",
    "    for pt in p1_types:\n",
    "        max_eff = max(max_eff, get_effectiveness(pt, p2_types))\n",
    "    out['lead_p1_vs_p2_effectiveness'] = float(max_eff)\n",
    "    return out\n",
    "\n",
    "def lead_aggregate_features(pokemon: dict, prefix: str = 'p2_lead_') -> dict:\n",
    "    out = {}\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    for s in stats:\n",
    "        out[f'{prefix}{s}'] = float(pokemon.get(s,0))\n",
    "    out[f'{prefix}level'] = int(pokemon.get('level',0))\n",
    "    types = [x.lower() for x in pokemon.get('types', [])]\n",
    "    common_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']\n",
    "    for t in common_types:\n",
    "        out[f'{prefix}type_{t}'] = int(t in types)\n",
    "    out[f'{prefix}name'] = pokemon.get('name','')\n",
    "    out[f'{prefix}n_unique_types'] = int(len(set(types)))\n",
    "    return out\n",
    "\n",
    "def summary_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline:\n",
    "        return {'tl_p1_moves':0,'tl_p2_moves':0,'tl_p1_est_damage':0.0,'tl_p2_est_damage':0.0,'damage_diff':0.0}\n",
    "    p1_moves = p2_moves = 0\n",
    "    p1_damage = p2_damage = 0.0\n",
    "    p1_last_active = p2_last_active = ''\n",
    "    p1_last_hp = p2_last_hp = np.nan\n",
    "    p1_fainted = p2_fainted = 0\n",
    "    p1_fainted_names = set()\n",
    "    p2_fainted_names = set()\n",
    "    last_p1_hp = {}\n",
    "    last_p2_hp = {}\n",
    "    p1_comeback_kos = 0\n",
    "    p2_comeback_kos = 0\n",
    "    p1_inflicted_statuses = Counter()\n",
    "    p2_inflicted_statuses = Counter()\n",
    "    p1_pokemon_statuses = {}\n",
    "    p2_pokemon_statuses = {}\n",
    "    p1_move_type_counts = Counter()\n",
    "    p2_move_type_counts = Counter()\n",
    "    p1_damage_first2 = 0.0\n",
    "    p2_damage_first2 = 0.0\n",
    "\n",
    "    # NEW: per-turn damage accumulation, KO timing and early/late KO counters\n",
    "    p1_dmg_by_turn = {}  # damage inflitto da p1 (contro p2) per turno\n",
    "    p2_dmg_by_turn = {}  # damage inflitto da p2 (contro p1) per turno\n",
    "    seen_turns = set()\n",
    "    first_ko_turn_p1_taken = None   # primo KO subìto da p1 (p1_fainted++)\n",
    "    first_ko_turn_p1_inflicted = None  # primo KO inflitto da p1 (p2_fainted++)\n",
    "    early_threshold = 10\n",
    "    p1_kos_early = p1_kos_late = 0\n",
    "    p2_kos_early = p2_kos_late = 0\n",
    "\n",
    "    for turn in timeline[:30]:\n",
    "        prev_p1_fainted, prev_p2_fainted = p1_fainted, p2_fainted\n",
    "        p1_state = turn.get('p1_pokemon_state',{}) or {}\n",
    "        p2_state = turn.get('p2_pokemon_state',{}) or {}\n",
    "        tnum = turn.get('turn', None)\n",
    "        if tnum is None:\n",
    "            # fallback: usa lunghezza dei turni visti + 1\n",
    "            tnum = (len(seen_turns) + 1)\n",
    "        seen_turns.add(tnum)\n",
    "\n",
    "        if p1_state.get('name'):\n",
    "            p1_last_active = p1_state.get('name')\n",
    "        if p2_state.get('name'):\n",
    "            p2_last_active = p2_state.get('name')\n",
    "\n",
    "        if p1_state.get('fainted') and p1_state.get('name') not in p1_fainted_names:\n",
    "            p1_fainted += 1\n",
    "            p1_fainted_names.add(p1_state.get('name'))\n",
    "            if first_ko_turn_p1_taken is None:\n",
    "                first_ko_turn_p1_taken = tnum\n",
    "            if tnum <= early_threshold: p2_kos_early += 1\n",
    "            else: p2_kos_late += 1\n",
    "        if p2_state.get('fainted') and p2_state.get('name') not in p2_fainted_names:\n",
    "            p2_fainted += 1\n",
    "            p2_fainted_names.add(p2_state.get('name'))\n",
    "            if first_ko_turn_p1_inflicted is None:\n",
    "                first_ko_turn_p1_inflicted = tnum\n",
    "            if tnum <= early_threshold: p1_kos_early += 1\n",
    "            else: p1_kos_late += 1\n",
    "\n",
    "        p2_name, p2_hp = p2_state.get('name'), p2_state.get('hp_pct')\n",
    "        if p2_name and p2_hp is not None:\n",
    "            prev_hp = last_p2_hp.get(p2_name)\n",
    "            if prev_hp is not None:\n",
    "                delta = max(0.0, prev_hp - p2_hp)\n",
    "                p1_damage += delta\n",
    "                p1_dmg_by_turn[tnum] = p1_dmg_by_turn.get(tnum, 0.0) + delta\n",
    "                if turn.get('turn',999) <= 2:\n",
    "                    p1_damage_first2 += delta\n",
    "            last_p2_hp[p2_name] = p2_hp\n",
    "\n",
    "        p1_name, p1_hp = p1_state.get('name'), p1_state.get('hp_pct')\n",
    "        if p1_name and p1_hp is not None:\n",
    "            prev_hp = last_p1_hp.get(p1_name)\n",
    "            if prev_hp is not None:\n",
    "                delta = max(0.0, prev_hp - p1_hp)\n",
    "                p2_damage += delta\n",
    "                p2_dmg_by_turn[tnum] = p2_dmg_by_turn.get(tnum, 0.0) + delta\n",
    "                if turn.get('turn',999) <= 2:\n",
    "                    p2_damage_first2 += delta\n",
    "            last_p1_hp[p1_name] = p1_hp\n",
    "\n",
    "        damage_diff_so_far = p1_damage - p2_damage\n",
    "        if p2_fainted > prev_p2_fainted and damage_diff_so_far < -1.0:\n",
    "            p1_comeback_kos += 1\n",
    "        if p1_fainted > prev_p1_fainted and damage_diff_so_far > 1.0:\n",
    "            p2_comeback_kos += 1\n",
    "\n",
    "        p2_status = p2_state.get('status')\n",
    "        if p2_name and p2_status and p2_pokemon_statuses.get(p2_name) != p2_status:\n",
    "            p1_inflicted_statuses[p2_status] += 1\n",
    "            p2_pokemon_statuses[p2_name] = p2_status\n",
    "        p1_status = p1_state.get('status')\n",
    "        if p1_name and p1_status and p1_pokemon_statuses.get(p1_name) != p1_status:\n",
    "            p2_inflicted_statuses[p1_status] += 1\n",
    "            p1_pokemon_statuses[p1_name] = p1_status\n",
    "\n",
    "        p1_move = turn.get('p1_move_details') or {}\n",
    "        p2_move = turn.get('p2_move_details') or {}\n",
    "        if p1_move and p1_move.get('type'):\n",
    "            p1_move_type_counts[(p1_move.get('type') or '').lower()] += 1\n",
    "        if p2_move and p2_move.get('type'):\n",
    "            p2_move_type_counts[(p2_move.get('type') or '').lower()] += 1\n",
    "        if turn.get('p1_move_details'):\n",
    "            p1_moves += 1\n",
    "        if turn.get('p2_move_details'):\n",
    "            p2_moves += 1\n",
    "        p1_last_hp = p1_state.get('hp_pct', np.nan)\n",
    "        p2_last_hp = p2_state.get('hp_pct', np.nan)\n",
    "\n",
    "    # ...existing code computing out[...] baseline metrics...\n",
    "    out['tl_p1_moves'] = int(p1_moves)\n",
    "    out['tl_p2_moves'] = int(p2_moves)\n",
    "    out['tl_p1_est_damage'] = float(p1_damage)\n",
    "    out['tl_p2_est_damage'] = float(p2_damage)\n",
    "    out['damage_diff'] = float(p1_damage - p2_damage)\n",
    "    out['fainted_diff'] = int(p1_fainted - p2_fainted)\n",
    "    out['tl_p1_last_hp'] = float(p1_last_hp) if not np.isnan(p1_last_hp) else 0.0\n",
    "    out['tl_p2_last_hp'] = float(p2_last_hp) if not np.isnan(p2_last_hp) else 0.0\n",
    "    out['tl_p1_last_active'] = p1_last_active\n",
    "    out['tl_p2_last_active'] = p2_last_active\n",
    "    if p1_team:\n",
    "        p1_total_hp_sum = sum(p.get('base_hp',0) for p in p1_team)\n",
    "        p1_avg_def = np.mean([p.get('base_def',0) for p in p1_team] or [0])\n",
    "        p1_avg_spd = np.mean([p.get('base_spd',0) for p in p1_team] or [0])\n",
    "        out['tl_p2_damage_vs_p1_hp_pool'] = float(p2_damage / (p1_total_hp_sum + 1e-6))\n",
    "        out['tl_p1_defensive_endurance'] = float((p1_avg_def + p1_avg_spd) / (p2_damage + 1e-6))\n",
    "    out['tl_p1_comeback_kos'] = int(p1_comeback_kos)\n",
    "    out['tl_p2_comeback_kos'] = int(p2_comeback_kos)\n",
    "    out['tl_comeback_kos_diff'] = int(p1_comeback_kos - p2_comeback_kos)\n",
    "\n",
    "    common_statuses = ['brn','par','slp','frz','psn','tox']\n",
    "    for status in common_statuses:\n",
    "        out[f'tl_p1_inflicted_{status}_count'] = int(p1_inflicted_statuses.get(status,0))\n",
    "        out[f'tl_p2_inflicted_{status}_count'] = int(p2_inflicted_statuses.get(status,0))\n",
    "        out[f'tl_inflicted_{status}_diff'] = int(p1_inflicted_statuses.get(status,0) - p2_inflicted_statuses.get(status,0))\n",
    "\n",
    "    common_move_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying','ghost','bug','poison','fighting']\n",
    "    for mt in common_move_types:\n",
    "        out[f'tl_p1_move_type_{mt}_count'] = int(p1_move_type_counts.get(mt,0))\n",
    "        out[f'tl_p2_move_type_{mt}_count'] = int(p2_move_type_counts.get(mt,0))\n",
    "        out[f'tl_move_type_{mt}_count_diff'] = int(p1_move_type_counts.get(mt,0) - p2_move_type_counts.get(mt,0))\n",
    "\n",
    "    out['tl_p1_damage_first2'] = float(p1_damage_first2)\n",
    "    out['tl_p2_damage_first2'] = float(p2_damage_first2)\n",
    "    out['tl_first2_damage_diff'] = float(p1_damage_first2 - p2_damage_first2)\n",
    "\n",
    "    # NEW: derived, normalized and late-game features\n",
    "    turns_count = max(1, len(seen_turns))\n",
    "    out['tl_turns_count'] = int(turns_count)\n",
    "    out['tl_p1_moves_rate'] = float(p1_moves / turns_count)\n",
    "    out['tl_p2_moves_rate'] = float(p2_moves / turns_count)\n",
    "    out['tl_p1_damage_per_turn'] = float(p1_damage / turns_count)\n",
    "    out['tl_p2_damage_per_turn'] = float(p2_damage / turns_count)\n",
    "    out['tl_damage_rate_diff'] = float(out['tl_p1_damage_per_turn'] - out['tl_p2_damage_per_turn'])\n",
    "\n",
    "    # last-5-turns damage window\n",
    "    if seen_turns:\n",
    "        recent_turns = sorted(seen_turns)[-5:]\n",
    "        p1_last5 = sum(p1_dmg_by_turn.get(t,0.0) for t in recent_turns)\n",
    "        p2_last5 = sum(p2_dmg_by_turn.get(t,0.0) for t in recent_turns)\n",
    "    else:\n",
    "        p1_last5 = p2_last5 = 0.0\n",
    "    out['tl_p1_damage_last5'] = float(p1_last5)\n",
    "    out['tl_p2_damage_last5'] = float(p2_last5)\n",
    "    out['tl_last5_damage_diff'] = float(p1_last5 - p2_last5)\n",
    "    # NEW: ratio danno ultimi 5 turni vs totale\n",
    "    out['tl_p1_last5_damage_ratio'] = float(p1_last5 / (p1_damage + 1e-6))\n",
    "    out['tl_p2_last5_damage_ratio'] = float(p2_last5 / (p2_damage + 1e-6))\n",
    "    out['tl_last5_damage_ratio_diff'] = float(out['tl_p1_last5_damage_ratio'] - out['tl_p2_last5_damage_ratio'])\n",
    "\n",
    "    # time-weighted damage advantage (peso crescente con il turno)\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns)\n",
    "        w = np.linspace(1.0, 2.0, num=len(ts))  # pesi crescenti\n",
    "        w = w / (w.sum() + 1e-9)\n",
    "        adv = [(p1_dmg_by_turn.get(t,0.0) - p2_dmg_by_turn.get(t,0.0)) for t in ts]\n",
    "        out['tl_weighted_damage_diff'] = float(np.dot(w, adv))\n",
    "    else:\n",
    "        out['tl_weighted_damage_diff'] = 0.0\n",
    "\n",
    "    # NEW: comeback indicator (cambio di segno dell'adv cumulativo)\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns)\n",
    "        cum = 0.0\n",
    "        signs = []\n",
    "        for t in ts:\n",
    "            cum += (p1_dmg_by_turn.get(t,0.0) - p2_dmg_by_turn.get(t,0.0))\n",
    "            s = 1 if cum > 1e-9 else (-1 if cum < -1e-9 else 0)\n",
    "            if s != 0:\n",
    "                if not signs or signs[-1] != s:\n",
    "                    signs.append(s)\n",
    "        sign_flips = max(0, len(signs) - 1)\n",
    "        comeback_flag = 1 if (len(signs) >= 2 and signs[0] != signs[-1]) else 0\n",
    "    else:\n",
    "        sign_flips = 0\n",
    "        comeback_flag = 0\n",
    "    out['tl_damage_adv_sign_flips'] = int(sign_flips)\n",
    "    out['tl_comeback_flag'] = int(comeback_flag)\n",
    "\n",
    "    # KO timing and early/late counts\n",
    "    out['tl_first_ko_turn_p1_inflicted'] = int(first_ko_turn_p1_inflicted or 0)\n",
    "    out['tl_first_ko_turn_p1_taken'] = int(first_ko_turn_p1_taken or 0)\n",
    "    out['tl_first_ko_turn_diff'] = int((first_ko_turn_p1_inflicted or 0) - (first_ko_turn_p1_taken or 0))\n",
    "    out['tl_kos_early_p1'] = int(p1_kos_early)\n",
    "    out['tl_kos_late_p1'] = int(p1_kos_late)\n",
    "    out['tl_kos_early_p2'] = int(p2_kos_early)\n",
    "    out['tl_kos_late_p2'] = int(p2_kos_late)\n",
    "\n",
    "    # normalized status rates per turn\n",
    "    for status in common_statuses:\n",
    "        c1 = p1_inflicted_statuses.get(status,0)\n",
    "        c2 = p2_inflicted_statuses.get(status,0)\n",
    "        out[f'tl_p1_inflicted_{status}_rate'] = float(c1 / turns_count)\n",
    "        out[f'tl_p2_inflicted_{status}_rate'] = float(c2 / turns_count)\n",
    "        out[f'tl_inflicted_{status}_rate_diff'] = float((c1 - c2) / turns_count)\n",
    "\n",
    "    return out\n",
    "\n",
    "def ability_features(team: list, prefix: str) -> dict:\n",
    "    immunity_abilities = {'levitate':0,'volt_absorb':0,'water_absorb':0,'flash_fire':0}\n",
    "    stat_drop_abilities = {'intimidate':0}\n",
    "    weather_abilities = {'drought':0,'drizzle':0,'sand_stream':0}\n",
    "    out = {}\n",
    "    for pokemon in team:\n",
    "        ability = (pokemon.get('ability','') or '').lower().replace(' ','_')\n",
    "        if ability in immunity_abilities:\n",
    "            immunity_abilities[ability] += 1\n",
    "        if ability in stat_drop_abilities:\n",
    "            stat_drop_abilities[ability] += 1\n",
    "        if ability in weather_abilities:\n",
    "            weather_abilities[ability] += 1\n",
    "    for ability,count in immunity_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    for ability,count in stat_drop_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    for ability,count in weather_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    out[f'{prefix}total_immunity_abilities'] = int(sum(immunity_abilities.values()))\n",
    "    out[f'{prefix}total_stat_drop_abilities'] = int(sum(stat_drop_abilities.values()))\n",
    "    return out\n",
    "\n",
    "def prepare_record_features(record: dict, max_turns: int = 30) -> dict:\n",
    "    out = {}\n",
    "    out['battle_id'] = record.get('battle_id')\n",
    "    if 'player_won' in record:\n",
    "        out['player_won'] = int(bool(record.get('player_won')))\n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    out.update(team_aggregate_features(p1_team, prefix='p1_'))\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    out.update(lead_aggregate_features(p2_lead, prefix='p2_lead_'))\n",
    "    out.update(ability_features(p1_team, prefix='p1_'))\n",
    "    p1_lead = p1_team[0] if p1_team else {}\n",
    "    out.update(lead_vs_lead_features(p1_lead, p2_lead))\n",
    "    out.update(ability_features([p2_lead], prefix='p2_lead_'))\n",
    "    out['p1_intimidate_vs_lead'] = 1 if out.get('p1_ability_intimidate_count',0) > 0 else 0\n",
    "    tl = record.get('battle_timeline', [])\n",
    "    out.update(summary_from_timeline(tl[:max_turns], p1_team))\n",
    "    out['team_hp_sum_minus_p2lead_hp'] = out.get('p1_base_hp_sum', 0) - out.get('p2_lead_base_hp', 0)\n",
    "    out['team_spa_mean_minus_p2spa'] = out.get('p1_base_spa_mean', 0) - out.get('p2_lead_base_spa', 0)\n",
    "    out['speed_advantage'] = out.get('p1_base_spe_sum', 0) - out.get('p2_lead_base_spe', 0)\n",
    "    out['n_unique_types_diff'] = out.get('p1_n_unique_types', 0) - out.get('p2_lead_n_unique_types', 1)\n",
    "    p1_moves = max(out.get('tl_p1_moves',1),1)\n",
    "    p2_moves = max(out.get('tl_p2_moves',1),1)\n",
    "    out['damage_per_turn_diff'] = (out.get('tl_p1_est_damage',0.0)/p1_moves) - (out.get('tl_p2_est_damage',0.0)/p2_moves)\n",
    "    out['last_pair'] = f\"{out.get('tl_p1_last_active','')}_VS_{out.get('tl_p2_last_active','')}\"\n",
    "    out.update(calculate_type_advantage(p1_team, p2_lead))\n",
    "    p2_lead_bulk = out.get('p2_lead_base_def',1) + out.get('p2_lead_base_spd',1)\n",
    "    out['p1_se_options_vs_lead_bulk'] = out.get('p1_super_effective_options',0) / (p2_lead_bulk + 1e-6)\n",
    "    p2_team = record.get('p2_team_details', [])\n",
    "    if p2_team:\n",
    "        out.update(team_aggregate_features(p2_team, prefix='p2_'))\n",
    "        out['team_hp_sum_diff'] = out.get('p1_base_hp_sum',0) - out.get('p2_base_hp_sum',0)\n",
    "        out['team_spa_mean_diff'] = out.get('p1_base_spa_mean',0) - out.get('p2_base_spa_mean',0)\n",
    "        out['team_spe_mean_diff'] = out.get('p1_base_spe_mean',0) - out.get('p2_base_spe_mean',0)\n",
    "        out['n_unique_types_team_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_n_unique_types',0)\n",
    "    return out\n",
    "\n",
    "def create_features_from_raw(data: list) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for b in tqdm(data, desc='FE'):\n",
    "        try:\n",
    "            feat = prepare_record_features(b, max_turns=30)\n",
    "            if 'battle_id' not in feat:\n",
    "                feat['battle_id'] = b.get('battle_id')\n",
    "            rows.append(feat)\n",
    "        except Exception as e:\n",
    "            rows.append({'battle_id': b.get('battle_id'), 'error': 1})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if 'player_won' in df.columns:\n",
    "        df['player_won'] = df['player_won'].astype(int)\n",
    "    return df.fillna(0)\n",
    "\n",
    "train_df = create_features_from_raw(train_raw)\n",
    "test_df = create_features_from_raw(test_raw)\n",
    "print('Feature shape train/test:', train_df.shape, test_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cede4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature numeriche (pre-stability): 180\n",
      "Stability filter: nessuna feature rimossa.\n",
      "Feature numeriche finali: 180\n",
      "Colonne escluse (stringhe): 5\n",
      "Late-game features rimosse (al netto whitelist): 27\n",
      "Whitelist preservate: ['tl_p2_damage_vs_p1_hp_pool', 'tl_damage_adv_sign_flips', 'tl_p2_last5_damage_ratio', 'tl_last5_damage_ratio_diff', 'tl_comeback_flag', 'tl_p1_defensive_endurance', 'tl_last5_damage_diff', 'tl_weighted_damage_diff', 'tl_p1_last5_damage_ratio']\n",
      "Drop extra (totali timeline e status diff): 18 -> esempi: ['tl_p1_est_damage', 'tl_p2_est_damage', 'tl_p1_moves', 'tl_p2_moves', 'tl_inflicted_brn_diff', 'tl_inflicted_par_diff']\n",
      "train_val size: 8000 holdout size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Preparazione X, y - FILTRO COLONNE STRINGA\n",
    "# Escludo colonne non numeriche (stringhe) che XGBoost non può usare\n",
    "exclude_cols = ['battle_id', 'player_won']\n",
    "# Identifica colonne stringa nel DataFrame\n",
    "string_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "exclude_cols.extend(string_cols)\n",
    "\n",
    "FEATURES = [c for c in train_df.columns if c not in exclude_cols]\n",
    "\n",
    "# Opzionale: escludi le NUOVE feature late-game se peggiorano accuracy\n",
    "DROP_NEW_TIMELINE_FEATURES = True  # metti False per tenerle\n",
    "late_new_static = [\n",
    "    'tl_turns_count','tl_p1_moves_rate','tl_p2_moves_rate',\n",
    "    'tl_p1_damage_per_turn','tl_p2_damage_per_turn','tl_damage_rate_diff',\n",
    "    'tl_p1_damage_last5','tl_p2_damage_last5','tl_last5_damage_diff',\n",
    "    'tl_weighted_damage_diff','tl_first_ko_turn_p1_inflicted','tl_first_ko_turn_p1_taken',\n",
    "    'tl_first_ko_turn_diff','tl_kos_early_p1','tl_kos_late_p1','tl_kos_early_p2','tl_kos_late_p2',\n",
    "    # nuove feature aggiunte sotto (verranno whitelestate)\n",
    "    'tl_p1_last5_damage_ratio','tl_p2_last5_damage_ratio','tl_last5_damage_ratio_diff',\n",
    "    'tl_damage_adv_sign_flips','tl_comeback_flag'\n",
    "]\n",
    "rate_cols = [c for c in train_df.columns if c.startswith('tl_') and c.endswith('_rate')]\n",
    "LATE_GAME_NEW_FEATURES = sorted(set(late_new_static + rate_cols))\n",
    "\n",
    "# WHITELIST: tieni sempre queste feature anche se DROP_NEW_TIMELINE_FEATURES=True\n",
    "WHITELIST_KEEP = {\n",
    "    'tl_weighted_damage_diff', 'tl_last5_damage_diff',\n",
    "    'tl_damage_adv_sign_flips', 'tl_comeback_flag',\n",
    "    'tl_p1_last5_damage_ratio', 'tl_p2_last5_damage_ratio', 'tl_last5_damage_ratio_diff',\n",
    "    'tl_p1_defensive_endurance', 'tl_p1_defensive_endurance_log',\n",
    "    'tl_p2_damage_vs_p1_hp_pool', 'tl_p2_damage_vs_p1_hp_pool_log'\n",
    "}\n",
    "if DROP_NEW_TIMELINE_FEATURES:\n",
    "    FEATURES = [c for c in FEATURES if (c not in LATE_GAME_NEW_FEATURES) or (c in WHITELIST_KEEP)]\n",
    "\n",
    "# === Drop aggiuntivo anti-overfitting: rimuovi totali timeline e differenze di status pesanti ===\n",
    "RAW_TL_TOTALS = ['tl_p1_est_damage','tl_p2_est_damage','tl_p1_moves','tl_p2_moves']\n",
    "STATUS_DIFF_COLS = [c for c in train_df.columns if c.startswith('tl_inflicted_') and c.endswith('_diff')]\n",
    "HIGH_VAR_TL = ['damage_diff', 'tl_first2_damage_diff']  # preserva endurance e weighted diff (cruciali)\n",
    "drop_now = [c for c in RAW_TL_TOTALS if c in FEATURES] + [c for c in STATUS_DIFF_COLS if c in FEATURES] + [c for c in HIGH_VAR_TL if c in FEATURES]\n",
    "FEATURES = [c for c in FEATURES if c not in set(drop_now)]\n",
    "\n",
    "print(f'Feature numeriche (pre-stability): {len(FEATURES)}')\n",
    "\n",
    "# === Stability filter (5-fold SMD) ===\n",
    "STABILITY_THRESHOLD = 0.055\n",
    "STABILITY_PROTECT = WHITELIST_KEEP | {'damage_per_turn_diff'}\n",
    "y_all = train_df['player_won'].values.astype(int)\n",
    "skf_stab = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "smd_cache = {f: [] for f in FEATURES}\n",
    "for tr_idx, va_idx in skf_stab.split(train_df[FEATURES], y_all):\n",
    "    tr_df = train_df.iloc[tr_idx][FEATURES].astype(float)\n",
    "    va_df = train_df.iloc[va_idx][FEATURES].astype(float)\n",
    "    std_tr = tr_df.std(ddof=1) + 1e-9\n",
    "    smd = (va_df.mean() - tr_df.mean()) / std_tr\n",
    "    for f, v in smd.items():\n",
    "        smd_cache[f].append(abs(float(v)))\n",
    "mean_smd = {f: (np.mean(vals) if len(vals) else 0.0) for f, vals in smd_cache.items()}\n",
    "DRIFT_HARD_DROP = sorted([f for f, v in mean_smd.items() if v >= 0.09])\n",
    "if DRIFT_HARD_DROP:\n",
    "    FEATURES = [f for f in FEATURES if f not in set(DRIFT_HARD_DROP)]\n",
    "    print(f'Drift hard drop ({len(DRIFT_HARD_DROP)}): {DRIFT_HARD_DROP[:6]}')\n",
    "\n",
    "# === Stability filter: rimuovi feature instabili (alta varianza tra fold) ===\n",
    "unstable_feats = sorted([f for f, v in mean_smd.items() if (v > STABILITY_THRESHOLD and f not in STABILITY_PROTECT)])\n",
    "if unstable_feats:\n",
    "    FEATURES = [f for f in FEATURES if f not in set(unstable_feats)]\n",
    "    print(f'Stability filter: rimosse {len(unstable_feats)} colonne sopra {STABILITY_THRESHOLD:.3f}. Esempio: {unstable_feats[:6]}')\n",
    "else:\n",
    "    print('Stability filter: nessuna feature rimossa.')\n",
    "\n",
    "print(f'Feature numeriche finali: {len(FEATURES)}')\n",
    "print(f'Colonne escluse (stringhe): {len(string_cols)}')\n",
    "if DROP_NEW_TIMELINE_FEATURES:\n",
    "    kept = set(late_new_static) | set(rate_cols)\n",
    "    dropped = [c for c in LATE_GAME_NEW_FEATURES if (c in train_df.columns and c not in WHITELIST_KEEP)]\n",
    "    print(f\"Late-game features rimosse (al netto whitelist): {len(dropped)}\")\n",
    "    print(f\"Whitelist preservate: {[c for c in WHITELIST_KEEP if c in train_df.columns]}\")\n",
    "if drop_now:\n",
    "    print(f\"Drop extra (totali timeline e status diff): {len(drop_now)} -> esempi: {drop_now[:6]}\")\n",
    "\n",
    "X = train_df[FEATURES].values\n",
    "y = y_all\n",
    "\n",
    "# Split holdout test dal train (20%)\n",
    "X_train_val, X_holdout, y_train_val, y_holdout, idx_train_val, idx_holdout = train_test_split(\n",
    "    X, y, train_df.index.values, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('train_val size:', X_train_val.shape[0], 'holdout size:', X_holdout.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38364108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time-boxed GridSearchCV (<= ~2 ore) ===\n",
      "scale_pos_weight auto≈1.00 -> grid=[1.0, 1.25]\n",
      "Warmup per stimare t_fit...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     43\u001b[39m t0 = time.time()\n\u001b[32m     44\u001b[39m gs_warm = GridSearchCV(\n\u001b[32m     45\u001b[39m     base_clf,\n\u001b[32m     46\u001b[39m     param_grid=[{k:[v] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m d.items()} \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m warm_params],\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     refit=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     52\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mgs_warm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m elapsed_warm = time.time() - t0\n\u001b[32m     55\u001b[39m fits_warm = \u001b[38;5;28mlen\u001b[39m(warm_params) * cv_inner.get_n_splits()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Grid Search time-boxed (<= ~2 ore) ===\n",
    "print(\"=== Time-boxed GridSearchCV (<= ~2 ore) ===\")\n",
    "import time, os\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "try:\n",
    "    import joblib\n",
    "    CPU_COUNT = joblib.cpu_count()\n",
    "except Exception:\n",
    "    CPU_COUNT = os.cpu_count() or 4\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Base estimator\n",
    "base_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=1, tree_method='hist')\n",
    "\n",
    "# Calcola uno scale_pos_weight automatico e cerca attorno ad esso\n",
    "pos_rate = float(y_train_val.mean())\n",
    "spw_auto = float((1.0 - pos_rate) / max(pos_rate, 1e-9))\n",
    "spw_grid = sorted({1.0, max(1.0, spw_auto*0.75), max(1.0, spw_auto), max(1.0, spw_auto*1.25)})\n",
    "print(f'scale_pos_weight auto≈{spw_auto:.2f} -> grid={spw_grid}')\n",
    "\n",
    "# Griglia COARSE (regolarizzata) — include scale_pos_weight\n",
    "grid_coarse = {\n",
    "    'n_estimators':      [300, 500, 700],\n",
    "    'max_depth':         [3, 4],\n",
    "    'min_child_weight':  [3, 5, 7],\n",
    "    'learning_rate':     [0.03, 0.05, 0.07],\n",
    "    'subsample':         [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree':  [0.7, 0.8, 0.9],\n",
    "    'gamma':             [0.1, 0.2, 0.3],\n",
    "    'reg_alpha':         [0.05, 0.1, 0.2],\n",
    "    'reg_lambda':        [2.0, 3.0, 4.0],\n",
    "    'scale_pos_weight':  spw_grid\n",
    "}\n",
    "\n",
    "# Stima tempo per-fit (warmup) — CORRETTO param_grid\n",
    "warm_params = [\n",
    "    {'n_estimators': 500, 'max_depth': 3, 'min_child_weight': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'reg_lambda': 3.0, 'scale_pos_weight': max(1.0, spw_auto)},\n",
    "    {'n_estimators': 700, 'max_depth': 4, 'min_child_weight': 5, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'reg_lambda': 3.0, 'scale_pos_weight': max(1.0, spw_auto*1.25)}\n",
    "]\n",
    "print(\"Warmup per stimare t_fit...\")\n",
    "t0 = time.time()\n",
    "gs_warm = GridSearchCV(\n",
    "    base_clf,\n",
    "    param_grid=[{k:[v] for k,v in d.items()} for d in warm_params],\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv_inner,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=False\n",
    ")\n",
    "gs_warm.fit(X_train_val, y_train_val)\n",
    "elapsed_warm = time.time() - t0\n",
    "fits_warm = len(warm_params) * cv_inner.get_n_splits()\n",
    "t_fit_per_fold = max(0.01, elapsed_warm / fits_warm)\n",
    "print(f\"Warmup: {elapsed_warm:.2f}s per {fits_warm} fit -> ~{t_fit_per_fold:.3f}s/fit\")\n",
    "\n",
    "# Budget totale ~2 ore con margine sicurezza\n",
    "TARGET_SECONDS = int(2*3600*0.9)\n",
    "speedup = max(1, min(CPU_COUNT, cv_inner.get_n_splits()))\n",
    "max_combos = int((TARGET_SECONDS * speedup) / (t_fit_per_fold * cv_inner.get_n_splits()))\n",
    "max_combos = int(max(48, min(max_combos, 2000)))\n",
    "print(f\"CPU={CPU_COUNT}, speedup~{speedup}, max_combos≈{max_combos}\")\n",
    "\n",
    "# Costruisci tutte le combinazioni e campiona fino a max_combos\n",
    "all_points = list(ParameterGrid(grid_coarse))\n",
    "total = len(all_points)\n",
    "print(f\"Candidate totali nella griglia: {total}\")\n",
    "rng = np.random.default_rng(42)\n",
    "if total > max_combos:\n",
    "    idx = rng.choice(total, size=max_combos, replace=False)\n",
    "    sampled = [all_points[i] for i in idx]\n",
    "else:\n",
    "    sampled = all_points\n",
    "print(f\"Config selezionate: {len(sampled)}\")\n",
    "\n",
    "# Converte in lista di 'micro-grid' (1 punto ciascuno) — CORRETTO\n",
    "param_grid_list = [{k:[v] for k,v in pt.items()} for pt in sampled]\n",
    "\n",
    "print(\"Esecuzione GridSearch time-boxed...\")\n",
    "t1 = time.time()\n",
    "gs = GridSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_grid=param_grid_list,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv_inner,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "gs.fit(X_train_val, y_train_val)\n",
    "elapsed = time.time() - t1\n",
    "\n",
    "results_df = pd.DataFrame(gs.cv_results_).sort_values('rank_test_score')\n",
    "csv_path = 'hp_search_results_timeboxed_grid.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "best_params = gs.best_params_\n",
    "\n",
    "print(f\"\\n✅ Salvato {csv_path} ({len(results_df)} righe)\")\n",
    "print(\"Migliori iperparametri:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"Best CV (balanced_accuracy): {gs.best_score_:.4f}\")\n",
    "print(f\"Tempo GridSearch: {elapsed/60:.1f} min (budget ~{TARGET_SECONDS/60:.0f} min)\")\n",
    "print(\"Ora puoi usare 'best_params' nelle celle successive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239a614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 14:33:24,414] A new study created in memory with name: no-name-1436204c-bbb6-468e-bbbe-5536bc1a4d17\n",
      "[I 2025-11-03 14:33:35,941] Trial 0 finished with value: 0.80975 and parameters: {'n_estimators': 600, 'learning_rate': 0.08927180304353628, 'max_depth': 5, 'min_child_weight': 7, 'gamma': 0.12481491235394922, 'subsample': 0.6467983561008608, 'colsample_bytree': 0.6174250836504598, 'colsample_bylevel': 0.9464704583099741, 'colsample_bynode': 0.8404460046972835, 'reg_alpha': 0.7080725777960455, 'reg_lambda': 0.5318033256270142, 'max_delta_step': 2, 'scale_pos_weight': 1.4994655844802531}. Best is trial 0 with value: 0.80975.\n",
      "[I 2025-11-03 14:33:44,280] Trial 1 finished with value: 0.8067499999999999 and parameters: {'n_estimators': 500, 'learning_rate': 0.015199348301309814, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.4198051453057903, 'subsample': 0.7295835055926347, 'colsample_bytree': 0.6873687420594126, 'colsample_bylevel': 0.8447411578889518, 'colsample_bynode': 0.6557975442608167, 'reg_alpha': 0.29214464853521815, 'reg_lambda': 1.498365454855079, 'max_delta_step': 1, 'scale_pos_weight': 1.4711055768358081}. Best is trial 0 with value: 0.80975.\n",
      "[I 2025-11-03 14:33:53,813] Trial 2 finished with value: 0.819 and parameters: {'n_estimators': 400, 'learning_rate': 0.032676417657817626, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.48603588152115074, 'subsample': 0.6511572371061874, 'colsample_bytree': 0.6195154778955838, 'colsample_bylevel': 0.9795542149013333, 'colsample_bynode': 0.9862528132298237, 'reg_alpha': 0.8083973481164611, 'reg_lambda': 1.2453219846912194, 'max_delta_step': 0, 'scale_pos_weight': 1.4105398159072942}. Best is trial 2 with value: 0.819.\n",
      "[I 2025-11-03 14:34:06,176] Trial 3 finished with value: 0.8145 and parameters: {'n_estimators': 700, 'learning_rate': 0.01324458134009936, 'max_depth': 4, 'min_child_weight': 2, 'gamma': 0.7274563216630257, 'subsample': 0.677633994480005, 'colsample_bytree': 0.7987566853061946, 'colsample_bylevel': 0.7246844304357644, 'colsample_bynode': 0.8080272084711243, 'reg_alpha': 0.5467102793432796, 'reg_lambda': 0.869903735564586, 'max_delta_step': 2, 'scale_pos_weight': 1.4650796940166688}. Best is trial 2 with value: 0.819.\n",
      "[I 2025-11-03 14:34:27,519] Trial 4 finished with value: 0.8098749999999999 and parameters: {'n_estimators': 1200, 'learning_rate': 0.07849235338159358, 'max_depth': 5, 'min_child_weight': 10, 'gamma': 0.0707940016415356, 'subsample': 0.6587948587257435, 'colsample_bytree': 0.6135681866731614, 'colsample_bylevel': 0.7301321323053057, 'colsample_bynode': 0.7554709158757928, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 5.986629236379358, 'max_delta_step': 1, 'scale_pos_weight': 1.1685607058124285}. Best is trial 2 with value: 0.819.\n",
      "[I 2025-11-03 14:34:46,497] Trial 5 finished with value: 0.8195 and parameters: {'n_estimators': 800, 'learning_rate': 0.013833249975219963, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.7895095492804138, 'subsample': 0.8316734307889972, 'colsample_bytree': 0.6596147044602517, 'colsample_bylevel': 0.602208846849441, 'colsample_bynode': 0.9261845713819337, 'reg_alpha': 0.7068573438476171, 'reg_lambda': 4.440482849384359, 'max_delta_step': 2, 'scale_pos_weight': 1.0444267910404543}. Best is trial 5 with value: 0.8195.\n",
      "[I 2025-11-03 14:35:00,991] Trial 6 finished with value: 0.8163750000000001 and parameters: {'n_estimators': 600, 'learning_rate': 0.013057771348997228, 'max_depth': 6, 'min_child_weight': 7, 'gamma': 0.26471841988211936, 'subsample': 0.6190675050858071, 'colsample_bytree': 0.6932946965146987, 'colsample_bylevel': 0.7300733288106989, 'colsample_bynode': 0.8918424713352255, 'reg_alpha': 0.6375574713552131, 'reg_lambda': 7.132805718188966, 'max_delta_step': 1, 'scale_pos_weight': 1.071756547562981}. Best is trial 5 with value: 0.8195.\n",
      "[I 2025-11-03 14:35:05,337] Trial 7 pruned. \n",
      "[I 2025-11-03 14:35:10,348] Trial 8 pruned. \n",
      "[I 2025-11-03 14:35:12,619] Trial 9 pruned. \n",
      "[I 2025-11-03 14:35:34,737] Trial 10 finished with value: 0.8176249999999999 and parameters: {'n_estimators': 900, 'learning_rate': 0.024681591575651834, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.5910772166667708, 'subsample': 0.857987729197811, 'colsample_bytree': 0.887931223783626, 'colsample_bylevel': 0.8430935157723661, 'colsample_bynode': 0.9134518484596068, 'reg_alpha': 0.9923626654603367, 'reg_lambda': 2.937880776788149, 'max_delta_step': 2, 'scale_pos_weight': 1.0141075205616947}. Best is trial 5 with value: 0.8195.\n",
      "[I 2025-11-03 14:35:44,518] Trial 11 finished with value: 0.8178750000000001 and parameters: {'n_estimators': 300, 'learning_rate': 0.03714902137788296, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.5643417528433443, 'subsample': 0.8260052940673948, 'colsample_bytree': 0.7937569322109723, 'colsample_bylevel': 0.9881320861304522, 'colsample_bynode': 0.9997101278830601, 'reg_alpha': 0.9905560684491923, 'reg_lambda': 1.549178256500361, 'max_delta_step': 0, 'scale_pos_weight': 1.3561281139142216}. Best is trial 5 with value: 0.8195.\n",
      "[I 2025-11-03 14:36:05,432] Trial 12 finished with value: 0.8172499999999999 and parameters: {'n_estimators': 900, 'learning_rate': 0.03331741541404792, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.7994899509132409, 'subsample': 0.7924450801299063, 'colsample_bytree': 0.6501923387962646, 'colsample_bylevel': 0.9184246529345085, 'colsample_bynode': 0.929759505859453, 'reg_alpha': 0.46140483948688765, 'reg_lambda': 1.5968070243951733, 'max_delta_step': 0, 'scale_pos_weight': 1.1111558436304507}. Best is trial 5 with value: 0.8195.\n",
      "[I 2025-11-03 14:36:19,417] Trial 13 finished with value: 0.8167500000000001 and parameters: {'n_estimators': 800, 'learning_rate': 0.022734654308688994, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.5513246583878899, 'subsample': 0.865363320386671, 'colsample_bytree': 0.7492244392210476, 'colsample_bylevel': 0.7885688360480123, 'colsample_bynode': 0.8661433738769575, 'reg_alpha': 0.7896845175879643, 'reg_lambda': 0.8123538810061028, 'max_delta_step': 1, 'scale_pos_weight': 1.5876553550636467}. Best is trial 5 with value: 0.8195.\n",
      "[I 2025-11-03 14:36:21,629] Trial 14 pruned. \n",
      "[I 2025-11-03 14:36:25,101] Trial 15 pruned. \n",
      "[I 2025-11-03 14:36:27,410] Trial 16 pruned. \n",
      "[I 2025-11-03 14:36:53,407] Trial 17 finished with value: 0.82 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01088079023686719, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.2987693351375503, 'subsample': 0.8094289920016203, 'colsample_bytree': 0.7971724699162732, 'colsample_bylevel': 0.9975371140198833, 'colsample_bynode': 0.8528955957114865, 'reg_alpha': 0.6846114912437019, 'reg_lambda': 1.0529041877721552, 'max_delta_step': 1, 'scale_pos_weight': 1.000339970379654}. Best is trial 17 with value: 0.82.\n",
      "[I 2025-11-03 14:37:18,283] Trial 18 finished with value: 0.818875 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0100980899624385, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.2766828240433545, 'subsample': 0.823595003374941, 'colsample_bytree': 0.8016055618926528, 'colsample_bylevel': 0.8519774955331508, 'colsample_bynode': 0.8387777935834964, 'reg_alpha': 0.32334076412440416, 'reg_lambda': 1.0283430605938404, 'max_delta_step': 1, 'scale_pos_weight': 1.0142808992689059}. Best is trial 17 with value: 0.82.\n",
      "[I 2025-11-03 14:37:24,100] Trial 19 pruned. \n",
      "[I 2025-11-03 14:37:42,927] Trial 20 finished with value: 0.8188749999999999 and parameters: {'n_estimators': 800, 'learning_rate': 0.016309189638605445, 'max_depth': 6, 'min_child_weight': 5, 'gamma': 0.03536466782920139, 'subsample': 0.7613531684843053, 'colsample_bytree': 0.8359009162201633, 'colsample_bylevel': 0.7639493407814485, 'colsample_bynode': 0.8074076155976588, 'reg_alpha': 0.694618158022859, 'reg_lambda': 2.0936186328751267, 'max_delta_step': 1, 'scale_pos_weight': 1.1340388951820584}. Best is trial 17 with value: 0.82.\n",
      "[I 2025-11-03 14:38:02,858] Trial 21 finished with value: 0.818 and parameters: {'n_estimators': 900, 'learning_rate': 0.02771574042977272, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.32770930957334254, 'subsample': 0.8451008687424497, 'colsample_bytree': 0.7672552954718422, 'colsample_bylevel': 0.9933273519651367, 'colsample_bynode': 0.9411434176003156, 'reg_alpha': 0.8752994353736931, 'reg_lambda': 1.001364207948549, 'max_delta_step': 0, 'scale_pos_weight': 1.001924275966548}. Best is trial 17 with value: 0.82.\n",
      "[I 2025-11-03 14:38:07,603] Trial 22 pruned. \n",
      "[I 2025-11-03 14:38:14,060] Trial 23 pruned. \n",
      "[I 2025-11-03 14:38:17,487] Trial 24 pruned. \n",
      "[I 2025-11-03 14:38:20,869] Trial 25 pruned. \n",
      "[I 2025-11-03 14:38:23,604] Trial 26 pruned. \n",
      "[I 2025-11-03 14:38:29,193] Trial 27 pruned. \n",
      "[I 2025-11-03 14:38:46,063] Trial 28 finished with value: 0.8188749999999999 and parameters: {'n_estimators': 700, 'learning_rate': 0.01534005119829623, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 0.22313999322735723, 'subsample': 0.8388726802360771, 'colsample_bytree': 0.8849069710300087, 'colsample_bylevel': 0.996899367141751, 'colsample_bynode': 0.8711142581172723, 'reg_alpha': 0.5200813513679245, 'reg_lambda': 1.8534522894642398, 'max_delta_step': 2, 'scale_pos_weight': 1.063704467763091}. Best is trial 17 with value: 0.82.\n",
      "[I 2025-11-03 14:38:48,592] Trial 29 pruned. \n",
      "[I 2025-11-03 14:38:51,603] Trial 30 pruned. \n",
      "[I 2025-11-03 14:39:15,738] Trial 31 finished with value: 0.818375 and parameters: {'n_estimators': 1000, 'learning_rate': 0.010425118609161352, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.2986364191592012, 'subsample': 0.8177233534977278, 'colsample_bytree': 0.7879685472147819, 'colsample_bylevel': 0.8671548959565435, 'colsample_bynode': 0.8437807574292961, 'reg_alpha': 0.3334593451311379, 'reg_lambda': 1.0192865911043716, 'max_delta_step': 1, 'scale_pos_weight': 1.0315286846575489}. Best is trial 17 with value: 0.82.\n",
      "[I 2025-11-03 14:39:21,038] Trial 32 pruned. \n",
      "[I 2025-11-03 14:39:44,137] Trial 33 finished with value: 0.82125 and parameters: {'n_estimators': 1000, 'learning_rate': 0.014435601114465301, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.35819430111991774, 'subsample': 0.798405275011201, 'colsample_bytree': 0.8596632597516238, 'colsample_bylevel': 0.7611715508295013, 'colsample_bynode': 0.8237508107290339, 'reg_alpha': 0.3505920401894866, 'reg_lambda': 0.9594364941397278, 'max_delta_step': 1, 'scale_pos_weight': 1.0053242149308106}. Best is trial 33 with value: 0.82125.\n",
      "[I 2025-11-03 14:40:07,446] Trial 34 finished with value: 0.8201249999999998 and parameters: {'n_estimators': 1100, 'learning_rate': 0.015874778960521134, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.44231997494319797, 'subsample': 0.6591444051926686, 'colsample_bytree': 0.864458973730278, 'colsample_bylevel': 0.6458474741501206, 'colsample_bynode': 0.7167228473518426, 'reg_alpha': 0.21527449385290204, 'reg_lambda': 0.8521650729935968, 'max_delta_step': 1, 'scale_pos_weight': 1.0397041909784726}. Best is trial 33 with value: 0.82125.\n",
      "[I 2025-11-03 14:40:30,668] Trial 35 finished with value: 0.81875 and parameters: {'n_estimators': 1100, 'learning_rate': 0.014909923758663585, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.4175438036605259, 'subsample': 0.8013704330851117, 'colsample_bytree': 0.8603770024042319, 'colsample_bylevel': 0.6444859237997373, 'colsample_bynode': 0.7044458054614302, 'reg_alpha': 0.20467434403861826, 'reg_lambda': 0.8225048027290129, 'max_delta_step': 1, 'scale_pos_weight': 1.048398052347116}. Best is trial 33 with value: 0.82125.\n",
      "[I 2025-11-03 14:40:47,671] Trial 36 finished with value: 0.819125 and parameters: {'n_estimators': 1200, 'learning_rate': 0.014302945177755228, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 0.36032105867311576, 'subsample': 0.690911040110549, 'colsample_bytree': 0.8622659812271798, 'colsample_bylevel': 0.633183850882164, 'colsample_bynode': 0.7273153908463411, 'reg_alpha': 0.13323134532161057, 'reg_lambda': 0.7140862737070811, 'max_delta_step': 1, 'scale_pos_weight': 1.1678131528292288}. Best is trial 33 with value: 0.82125.\n",
      "[I 2025-11-03 14:40:52,671] Trial 37 pruned. \n",
      "[I 2025-11-03 14:40:58,265] Trial 38 pruned. \n",
      "[I 2025-11-03 14:41:23,574] Trial 39 finished with value: 0.8192499999999999 and parameters: {'n_estimators': 1100, 'learning_rate': 0.011843040036245318, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.23990416434231968, 'subsample': 0.658218269339798, 'colsample_bytree': 0.8711460451095127, 'colsample_bylevel': 0.7527806374839894, 'colsample_bynode': 0.7394536027541903, 'reg_alpha': 0.08850415163393713, 'reg_lambda': 1.7510502380628519, 'max_delta_step': 1, 'scale_pos_weight': 1.0021494032718299}. Best is trial 33 with value: 0.82125.\n",
      "[I 2025-11-03 14:41:43,770] Trial 40 finished with value: 0.8188749999999999 and parameters: {'n_estimators': 900, 'learning_rate': 0.013509286599853492, 'max_depth': 6, 'min_child_weight': 7, 'gamma': 0.7164999397036589, 'subsample': 0.6381573148146885, 'colsample_bytree': 0.8120988210909956, 'colsample_bylevel': 0.6805797745418339, 'colsample_bynode': 0.7895591924592888, 'reg_alpha': 0.5004117316324969, 'reg_lambda': 8.296247702410101, 'max_delta_step': 2, 'scale_pos_weight': 1.0378155238731175}. Best is trial 33 with value: 0.82125.\n",
      "[I 2025-11-03 14:42:09,670] Trial 41 finished with value: 0.821875 and parameters: {'n_estimators': 1100, 'learning_rate': 0.011449485273634314, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.22974650518834772, 'subsample': 0.6728123685295924, 'colsample_bytree': 0.8675845945186168, 'colsample_bylevel': 0.7677569197976835, 'colsample_bynode': 0.7501348676778313, 'reg_alpha': 0.0563276020486331, 'reg_lambda': 1.3620078099492614, 'max_delta_step': 1, 'scale_pos_weight': 1.0135567750586636}. Best is trial 41 with value: 0.821875.\n",
      "[I 2025-11-03 14:42:14,861] Trial 42 pruned. \n",
      "[I 2025-11-03 14:42:20,276] Trial 43 pruned. \n",
      "[I 2025-11-03 14:42:26,369] Trial 44 pruned. \n",
      "[I 2025-11-03 14:42:44,955] Trial 45 finished with value: 0.820875 and parameters: {'n_estimators': 1000, 'learning_rate': 0.012791182726347768, 'max_depth': 5, 'min_child_weight': 10, 'gamma': 0.24832285053687225, 'subsample': 0.7037136603814238, 'colsample_bytree': 0.8991465245887599, 'colsample_bylevel': 0.7417015938281718, 'colsample_bynode': 0.7410237550891126, 'reg_alpha': 0.3575802881070892, 'reg_lambda': 0.9330648038252198, 'max_delta_step': 1, 'scale_pos_weight': 1.0268919291488834}. Best is trial 41 with value: 0.821875.\n",
      "[I 2025-11-03 14:43:03,528] Trial 46 finished with value: 0.820625 and parameters: {'n_estimators': 1000, 'learning_rate': 0.015716955444417882, 'max_depth': 5, 'min_child_weight': 9, 'gamma': 0.2426709911626171, 'subsample': 0.6937605998712641, 'colsample_bytree': 0.8670594604631575, 'colsample_bylevel': 0.7445279029742291, 'colsample_bynode': 0.7438738639944339, 'reg_alpha': 0.3579056164853648, 'reg_lambda': 0.622487277559278, 'max_delta_step': 1, 'scale_pos_weight': 1.0163983225727171}. Best is trial 41 with value: 0.821875.\n",
      "[I 2025-11-03 14:43:08,165] Trial 47 pruned. \n",
      "[I 2025-11-03 14:43:17,482] Trial 48 pruned. \n",
      "[I 2025-11-03 14:43:34,109] Trial 49 finished with value: 0.8200000000000001 and parameters: {'n_estimators': 900, 'learning_rate': 0.01264948986830071, 'max_depth': 5, 'min_child_weight': 9, 'gamma': 0.16059478637653626, 'subsample': 0.6706673493578146, 'colsample_bytree': 0.8534093177747129, 'colsample_bylevel': 0.7098846212535361, 'colsample_bynode': 0.6532350897419049, 'reg_alpha': 0.2936886592752231, 'reg_lambda': 0.7723738262866379, 'max_delta_step': 1, 'scale_pos_weight': 1.1840387300591808}. Best is trial 41 with value: 0.821875.\n",
      "[I 2025-11-03 14:43:37,940] Trial 50 pruned. \n",
      "[I 2025-11-03 14:43:41,879] Trial 51 pruned. \n",
      "[I 2025-11-03 14:43:59,784] Trial 52 finished with value: 0.822125 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01532482343357218, 'max_depth': 5, 'min_child_weight': 9, 'gamma': 0.18252755739135762, 'subsample': 0.6640032778095043, 'colsample_bytree': 0.8538605954817601, 'colsample_bylevel': 0.6961759954975156, 'colsample_bynode': 0.6207124327278246, 'reg_alpha': 0.38452984067709783, 'reg_lambda': 0.7643461135590525, 'max_delta_step': 1, 'scale_pos_weight': 1.0802518928123983}. Best is trial 52 with value: 0.822125.\n",
      "[I 2025-11-03 14:44:04,343] Trial 53 pruned. \n",
      "[I 2025-11-03 14:44:22,177] Trial 54 finished with value: 0.820625 and parameters: {'n_estimators': 1000, 'learning_rate': 0.015561669254940355, 'max_depth': 5, 'min_child_weight': 9, 'gamma': 0.07880413842821585, 'subsample': 0.6456117934517905, 'colsample_bytree': 0.8623286927043519, 'colsample_bylevel': 0.6781128716364876, 'colsample_bynode': 0.632052528297781, 'reg_alpha': 0.45772672174109186, 'reg_lambda': 0.7582960412953373, 'max_delta_step': 1, 'scale_pos_weight': 1.031889953835293}. Best is trial 52 with value: 0.822125.\n",
      "[I 2025-11-03 14:44:40,062] Trial 55 finished with value: 0.8213750000000001 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0194692509757907, 'max_depth': 5, 'min_child_weight': 8, 'gamma': 0.06058938170917785, 'subsample': 0.6429518995704715, 'colsample_bytree': 0.8351583614939742, 'colsample_bylevel': 0.6742674369942573, 'colsample_bynode': 0.6191922062196892, 'reg_alpha': 0.4563983944572536, 'reg_lambda': 0.7853706900010979, 'max_delta_step': 1, 'scale_pos_weight': 1.020508037869641}. Best is trial 52 with value: 0.822125.\n",
      "[I 2025-11-03 14:44:56,091] Trial 56 finished with value: 0.8213750000000001 and parameters: {'n_estimators': 1000, 'learning_rate': 0.026195308046892112, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.02761662749628427, 'subsample': 0.6196838491948596, 'colsample_bytree': 0.8328644364709644, 'colsample_bylevel': 0.8084112765642779, 'colsample_bynode': 0.6319568370339964, 'reg_alpha': 0.423843138024973, 'reg_lambda': 0.9690871976373716, 'max_delta_step': 1, 'scale_pos_weight': 1.0104490504435797}. Best is trial 52 with value: 0.822125.\n",
      "[I 2025-11-03 14:45:10,598] Trial 57 finished with value: 0.820875 and parameters: {'n_estimators': 900, 'learning_rate': 0.024172228161142704, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.015649405010016743, 'subsample': 0.6237881747697555, 'colsample_bytree': 0.834314849891336, 'colsample_bylevel': 0.796741631439769, 'colsample_bynode': 0.6328970416354087, 'reg_alpha': 0.4251504609730074, 'reg_lambda': 0.9609232132207908, 'max_delta_step': 1, 'scale_pos_weight': 1.0009632817363872}. Best is trial 52 with value: 0.822125.\n",
      "[I 2025-11-03 14:45:13,946] Trial 58 pruned. \n",
      "[I 2025-11-03 14:45:25,336] Trial 59 pruned. \n",
      "[I 2025-11-03 14:45:29,165] Trial 60 pruned. \n",
      "[I 2025-11-03 14:45:44,133] Trial 61 finished with value: 0.822875 and parameters: {'n_estimators': 900, 'learning_rate': 0.02633182572847021, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.005503790007509533, 'subsample': 0.6219040790854771, 'colsample_bytree': 0.8347115678250765, 'colsample_bylevel': 0.7972740127212694, 'colsample_bynode': 0.6341480500949653, 'reg_alpha': 0.41151197767773867, 'reg_lambda': 0.9573531506162529, 'max_delta_step': 1, 'scale_pos_weight': 1.0030482351916117}. Best is trial 61 with value: 0.822875.\n",
      "[I 2025-11-03 14:45:58,581] Trial 62 finished with value: 0.82225 and parameters: {'n_estimators': 900, 'learning_rate': 0.026853132377666455, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.04854456259278969, 'subsample': 0.6177795726607435, 'colsample_bytree': 0.8432385929099652, 'colsample_bylevel': 0.7826367529288646, 'colsample_bynode': 0.6324837913707607, 'reg_alpha': 0.5180615384205287, 'reg_lambda': 0.77281135420835, 'max_delta_step': 1, 'scale_pos_weight': 1.019626545890763}. Best is trial 61 with value: 0.822875.\n",
      "[I 2025-11-03 14:46:11,706] Trial 63 finished with value: 0.8233750000000001 and parameters: {'n_estimators': 800, 'learning_rate': 0.026903035419902337, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.039871447930199935, 'subsample': 0.6092684563246151, 'colsample_bytree': 0.8384119779272207, 'colsample_bylevel': 0.808324436329465, 'colsample_bynode': 0.6346001385909943, 'reg_alpha': 0.5173888577259714, 'reg_lambda': 0.7395028456377437, 'max_delta_step': 1, 'scale_pos_weight': 1.011137218440395}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:46:24,788] Trial 64 finished with value: 0.8194999999999999 and parameters: {'n_estimators': 800, 'learning_rate': 0.028583202419872156, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.043882868697508, 'subsample': 0.612010732484576, 'colsample_bytree': 0.8424277421678574, 'colsample_bylevel': 0.8436679141973981, 'colsample_bynode': 0.6332916816661367, 'reg_alpha': 0.5866065016192481, 'reg_lambda': 0.7602403485840944, 'max_delta_step': 1, 'scale_pos_weight': 1.0529765495714025}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:46:28,033] Trial 65 pruned. \n",
      "[I 2025-11-03 14:46:42,598] Trial 66 finished with value: 0.82175 and parameters: {'n_estimators': 900, 'learning_rate': 0.02599136115459465, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.025775864149318508, 'subsample': 0.6296723652016782, 'colsample_bytree': 0.8073089010054734, 'colsample_bylevel': 0.792570704387619, 'colsample_bynode': 0.624450030298109, 'reg_alpha': 0.6469256269868119, 'reg_lambda': 0.7070596839185695, 'max_delta_step': 0, 'scale_pos_weight': 1.0260631128884097}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:46:45,606] Trial 67 pruned. \n",
      "[I 2025-11-03 14:46:49,193] Trial 68 pruned. \n",
      "[I 2025-11-03 14:46:52,469] Trial 69 pruned. \n",
      "[I 2025-11-03 14:46:56,011] Trial 70 pruned. \n",
      "[I 2025-11-03 14:46:59,534] Trial 71 pruned. \n",
      "[I 2025-11-03 14:47:02,807] Trial 72 pruned. \n",
      "[I 2025-11-03 14:47:16,152] Trial 73 finished with value: 0.82225 and parameters: {'n_estimators': 800, 'learning_rate': 0.030095027584514086, 'max_depth': 4, 'min_child_weight': 7, 'gamma': 0.06436526353615417, 'subsample': 0.6115812889073406, 'colsample_bytree': 0.8558476753958486, 'colsample_bylevel': 0.7923751460541835, 'colsample_bynode': 0.600051886767161, 'reg_alpha': 0.3953582663137445, 'reg_lambda': 1.2318957378156115, 'max_delta_step': 2, 'scale_pos_weight': 1.0540495235664327}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:47:19,148] Trial 74 pruned. \n",
      "[I 2025-11-03 14:47:32,167] Trial 75 finished with value: 0.8231249999999999 and parameters: {'n_estimators': 800, 'learning_rate': 0.030226214584253692, 'max_depth': 4, 'min_child_weight': 7, 'gamma': 0.14180053484544775, 'subsample': 0.6514256341804038, 'colsample_bytree': 0.8550134380275001, 'colsample_bylevel': 0.6605757578259119, 'colsample_bynode': 0.6902724686064343, 'reg_alpha': 0.6010151043020487, 'reg_lambda': 2.2933770519141525, 'max_delta_step': 2, 'scale_pos_weight': 1.0846277428019055}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:47:35,511] Trial 76 pruned. \n",
      "[I 2025-11-03 14:47:48,483] Trial 77 finished with value: 0.82075 and parameters: {'n_estimators': 800, 'learning_rate': 0.023563442083629465, 'max_depth': 4, 'min_child_weight': 7, 'gamma': 0.11734820714463493, 'subsample': 0.6319860237040852, 'colsample_bytree': 0.8557426140544007, 'colsample_bylevel': 0.6557992252521027, 'colsample_bynode': 0.6582523213058261, 'reg_alpha': 0.7289878723907552, 'reg_lambda': 1.6577513539994668, 'max_delta_step': 2, 'scale_pos_weight': 1.0710104298450567}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:47:51,518] Trial 78 pruned. \n",
      "[I 2025-11-03 14:48:03,089] Trial 79 finished with value: 0.8231249999999999 and parameters: {'n_estimators': 800, 'learning_rate': 0.03897128037335753, 'max_depth': 3, 'min_child_weight': 7, 'gamma': 0.20949620381910417, 'subsample': 0.6051408929685854, 'colsample_bytree': 0.6978994343412416, 'colsample_bylevel': 0.8363628095591015, 'colsample_bynode': 0.6453840511589449, 'reg_alpha': 0.5993383733490183, 'reg_lambda': 2.037482788637421, 'max_delta_step': 2, 'scale_pos_weight': 1.262729664502447}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:48:05,558] Trial 80 pruned. \n",
      "[I 2025-11-03 14:48:17,358] Trial 81 finished with value: 0.82075 and parameters: {'n_estimators': 800, 'learning_rate': 0.032485878181042746, 'max_depth': 3, 'min_child_weight': 7, 'gamma': 0.17788663506053992, 'subsample': 0.6235623540799089, 'colsample_bytree': 0.7593923588364084, 'colsample_bylevel': 0.8557035071863784, 'colsample_bynode': 0.6699942061146401, 'reg_alpha': 0.6096051525002073, 'reg_lambda': 2.091481726687118, 'max_delta_step': 2, 'scale_pos_weight': 1.0630819823545017}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:48:20,315] Trial 82 pruned. \n",
      "[I 2025-11-03 14:48:23,857] Trial 83 pruned. \n",
      "[I 2025-11-03 14:48:26,796] Trial 84 pruned. \n",
      "[I 2025-11-03 14:48:30,007] Trial 85 pruned. \n",
      "[I 2025-11-03 14:48:33,532] Trial 86 pruned. \n",
      "[I 2025-11-03 14:48:36,597] Trial 87 pruned. \n",
      "[I 2025-11-03 14:48:40,129] Trial 88 pruned. \n",
      "[I 2025-11-03 14:48:45,223] Trial 89 pruned. \n",
      "[I 2025-11-03 14:48:48,535] Trial 90 pruned. \n",
      "[I 2025-11-03 14:48:54,771] Trial 91 pruned. \n",
      "[I 2025-11-03 14:48:58,292] Trial 92 pruned. \n",
      "[I 2025-11-03 14:49:12,673] Trial 93 finished with value: 0.821625 and parameters: {'n_estimators': 900, 'learning_rate': 0.024528191142884473, 'max_depth': 4, 'min_child_weight': 9, 'gamma': 0.07174458049434199, 'subsample': 0.6268496935854821, 'colsample_bytree': 0.878865301302216, 'colsample_bylevel': 0.7058262765855163, 'colsample_bynode': 0.6384498798928122, 'reg_alpha': 0.3811602690808067, 'reg_lambda': 0.935968780176735, 'max_delta_step': 1, 'scale_pos_weight': 1.0602031036227766}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:49:16,243] Trial 94 pruned. \n",
      "[I 2025-11-03 14:49:30,701] Trial 95 finished with value: 0.8223750000000001 and parameters: {'n_estimators': 900, 'learning_rate': 0.027022917721085532, 'max_depth': 4, 'min_child_weight': 9, 'gamma': 0.12333204150621102, 'subsample': 0.6359307721137791, 'colsample_bytree': 0.8782461784219558, 'colsample_bylevel': 0.6881010118362776, 'colsample_bynode': 0.6545490729308291, 'reg_alpha': 0.7710447582984057, 'reg_lambda': 1.6019645148270591, 'max_delta_step': 2, 'scale_pos_weight': 1.0381783898248436}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:49:33,904] Trial 96 pruned. \n",
      "[I 2025-11-03 14:49:37,469] Trial 97 pruned. \n",
      "[I 2025-11-03 14:49:47,071] Trial 98 pruned. \n",
      "[I 2025-11-03 14:49:50,012] Trial 99 pruned. \n",
      "[I 2025-11-03 14:49:53,573] Trial 100 pruned. \n",
      "[I 2025-11-03 14:50:08,008] Trial 101 finished with value: 0.8223750000000001 and parameters: {'n_estimators': 900, 'learning_rate': 0.02453939901930726, 'max_depth': 4, 'min_child_weight': 10, 'gamma': 0.046572145358053624, 'subsample': 0.638241470883443, 'colsample_bytree': 0.8761666496005301, 'colsample_bylevel': 0.6930406122096597, 'colsample_bynode': 0.6407169437852445, 'reg_alpha': 0.5669279199474923, 'reg_lambda': 1.1408397519594957, 'max_delta_step': 1, 'scale_pos_weight': 1.0692156744689874}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:50:11,807] Trial 102 pruned. \n",
      "[I 2025-11-03 14:50:26,641] Trial 103 finished with value: 0.82075 and parameters: {'n_estimators': 900, 'learning_rate': 0.02836252273166805, 'max_depth': 4, 'min_child_weight': 10, 'gamma': 0.10611673321771065, 'subsample': 0.6377884973596067, 'colsample_bytree': 0.8925453299786993, 'colsample_bylevel': 0.6950489271991109, 'colsample_bynode': 0.6534311449021057, 'reg_alpha': 0.5670212022485144, 'reg_lambda': 1.107245151893084, 'max_delta_step': 1, 'scale_pos_weight': 1.042051815356376}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:50:41,146] Trial 104 finished with value: 0.820375 and parameters: {'n_estimators': 900, 'learning_rate': 0.026669479678368642, 'max_depth': 4, 'min_child_weight': 10, 'gamma': 0.042746949898715844, 'subsample': 0.6163003110077644, 'colsample_bytree': 0.8549028349395397, 'colsample_bylevel': 0.6834300529478222, 'colsample_bynode': 0.631243310839964, 'reg_alpha': 0.6132028914332536, 'reg_lambda': 1.3551700712072208, 'max_delta_step': 1, 'scale_pos_weight': 1.024395369507918}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:50:46,883] Trial 105 pruned. \n",
      "[I 2025-11-03 14:51:04,240] Trial 106 finished with value: 0.822125 and parameters: {'n_estimators': 1100, 'learning_rate': 0.024184502022347027, 'max_depth': 4, 'min_child_weight': 9, 'gamma': 0.018059471567310786, 'subsample': 0.6298237236299038, 'colsample_bytree': 0.8134516571696235, 'colsample_bylevel': 0.8010372554048267, 'colsample_bynode': 0.6129374275514587, 'reg_alpha': 0.5938265762029903, 'reg_lambda': 1.0165135775059164, 'max_delta_step': 1, 'scale_pos_weight': 1.0132553261163957}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:51:08,361] Trial 107 pruned. \n",
      "[I 2025-11-03 14:51:24,362] Trial 108 finished with value: 0.8216249999999998 and parameters: {'n_estimators': 1000, 'learning_rate': 0.024499384109814632, 'max_depth': 4, 'min_child_weight': 10, 'gamma': 0.22457554496741727, 'subsample': 0.6359130033417544, 'colsample_bytree': 0.8729522158256398, 'colsample_bylevel': 0.8248700022256157, 'colsample_bynode': 0.6062090924956152, 'reg_alpha': 0.9179761484377642, 'reg_lambda': 1.0190807299360416, 'max_delta_step': 1, 'scale_pos_weight': 1.0004240743584298}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:51:27,854] Trial 109 pruned. \n",
      "[I 2025-11-03 14:51:35,283] Trial 110 pruned. \n",
      "[I 2025-11-03 14:51:39,397] Trial 111 pruned. \n",
      "[I 2025-11-03 14:51:43,791] Trial 112 pruned. \n",
      "[I 2025-11-03 14:51:58,272] Trial 113 finished with value: 0.8219999999999998 and parameters: {'n_estimators': 900, 'learning_rate': 0.027839543745580314, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.040934218381680404, 'subsample': 0.6407421564432201, 'colsample_bytree': 0.7779474239420167, 'colsample_bylevel': 0.8389599556836981, 'colsample_bynode': 0.6364378975372237, 'reg_alpha': 0.25978937082925224, 'reg_lambda': 0.8393719119598931, 'max_delta_step': 1, 'scale_pos_weight': 1.0570814051464754}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:52:11,493] Trial 114 finished with value: 0.82325 and parameters: {'n_estimators': 800, 'learning_rate': 0.027144019453356767, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.04623143935256948, 'subsample': 0.6412883117932909, 'colsample_bytree': 0.7765699225072813, 'colsample_bylevel': 0.8429991046460433, 'colsample_bynode': 0.6367893485016191, 'reg_alpha': 0.05163619640931697, 'reg_lambda': 1.0029327081153112, 'max_delta_step': 1, 'scale_pos_weight': 1.1184867969085954}. Best is trial 63 with value: 0.8233750000000001.\n",
      "[I 2025-11-03 14:52:14,887] Trial 115 pruned. \n",
      "[I 2025-11-03 14:52:18,186] Trial 116 pruned. \n",
      "[I 2025-11-03 14:52:21,486] Trial 117 pruned. \n",
      "[I 2025-11-03 14:52:24,979] Trial 118 pruned. \n",
      "[I 2025-11-03 14:52:27,981] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced_accuracy: 0.8234\n",
      "Best params:\n",
      "  n_estimators: 800\n",
      "  learning_rate: 0.026903035419902337\n",
      "  max_depth: 4\n",
      "  min_child_weight: 8\n",
      "  gamma: 0.039871447930199935\n",
      "  subsample: 0.6092684563246151\n",
      "  colsample_bytree: 0.8384119779272207\n",
      "  colsample_bylevel: 0.808324436329465\n",
      "  colsample_bynode: 0.6346001385909943\n",
      "  reg_alpha: 0.5173888577259714\n",
      "  reg_lambda: 0.7395028456377437\n",
      "  max_delta_step: 1\n",
      "  scale_pos_weight: 1.011137218440395\n",
      "✅ Salvato optuna_trials_xgb.csv\n",
      "\n",
      "best_params pronti per la 10-Fold CV:\n",
      "{'n_estimators': 800, 'learning_rate': 0.026903035419902337, 'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.039871447930199935, 'subsample': 0.6092684563246151, 'colsample_bytree': 0.8384119779272207, 'colsample_bylevel': 0.808324436329465, 'colsample_bynode': 0.6346001385909943, 'reg_alpha': 0.5173888577259714, 'reg_lambda': 0.7395028456377437, 'max_delta_step': 1, 'scale_pos_weight': 1.011137218440395, 'booster': 'gbtree'}\n"
     ]
    }
   ],
   "source": [
    "# === Optuna Study per selezione iperparametri XGBoost (balanced_accuracy) ===\n",
    "# Se Optuna non è installato: togli il commento alla riga sotto in Jupyter\n",
    "# %pip install -q optuna\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Usa lo stesso split interno del GridSearch\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Calibra il range di scale_pos_weight attorno al valore automatico\n",
    "pos_rate = float(y_train_val.mean())\n",
    "spw_auto = float((1.0 - pos_rate) / max(pos_rate, 1e-9))\n",
    "spw_low = max(1.0, spw_auto * 0.6)\n",
    "spw_high = min(10.0, spw_auto * 1.6)\n",
    "\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "\n",
    "def _predict_proba_best(clf, X):\n",
    "    # Compat con diverse versioni XGBoost/SKLearn wrapper\n",
    "    best_iter = getattr(clf, \"best_iteration\", None)\n",
    "    try:\n",
    "        if best_iter is not None:\n",
    "            return clf.predict_proba(X, iteration_range=(0, int(best_iter)+1))[:, 1]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        booster = clf.get_booster()\n",
    "        best_ntree_limit = getattr(booster, \"best_ntree_limit\", None)\n",
    "        if best_ntree_limit is not None:\n",
    "            return clf.predict_proba(X, ntree_limit=int(best_ntree_limit))[:, 1]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return clf.predict_proba(X)[:, 1]\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1200, step=100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.10, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 6),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 2, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 0.8),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.6, 1.0),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 10.0, log=True),\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 2),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", spw_low, spw_high),\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for fold_idx, (tr_idx, va_idx) in enumerate(cv_inner.split(X_train_val, y_train_val), start=1):\n",
    "        X_tr, X_va = X_train_val[tr_idx], X_train_val[va_idx]\n",
    "        y_tr, y_va = y_train_val[tr_idx], y_train_val[va_idx]\n",
    "\n",
    "        clf = XGBClassifier(\n",
    "            **params,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=1\n",
    "        )\n",
    "\n",
    "        # Early stopping su fold\n",
    "        try:\n",
    "            clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], early_stopping_rounds=EARLY_STOPPING_ROUNDS, verbose=False)\n",
    "        except TypeError:\n",
    "            clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "\n",
    "        proba = _predict_proba_best(clf, X_va)\n",
    "        preds = (proba >= 0.5).astype(int)\n",
    "        score = balanced_accuracy_score(y_va, preds)\n",
    "        scores.append(score)\n",
    "\n",
    "        # Pruning\n",
    "        trial.report(float(np.mean(scores)), step=fold_idx)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "N_TRIALS = 120    # aumenta/riduci in base al tempo a disposizione\n",
    "TIMEOUT = None    # in secondi; ad es. 7200 per ~2h\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT, gc_after_trial=True)\n",
    "\n",
    "print(f\"Best balanced_accuracy: {study.best_value:.4f}\")\n",
    "print(\"Best params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Esporta risultati\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv(\"optuna_trials_xgb.csv\", index=False)\n",
    "print(\"✅ Salvato optuna_trials_xgb.csv\")\n",
    "\n",
    "# Prepara best_params per le celle successive (CV/holdout/submission)\n",
    "best_params = dict(study.best_params)\n",
    "best_params.update({\n",
    "    \"booster\": \"gbtree\",\n",
    "    # Valori sicuri che non cerchiamo con Optuna, ma che il tuo codice usa\n",
    "    # (lasciare invariati se non li vuoi forzare)\n",
    "})\n",
    "print(\"\\nbest_params pronti per la 10-Fold CV:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab0d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10-Fold Cross-Validation (9 train + 1 validation) ===\n",
      "Parametri utilizzati: {'booster': 'gbtree', 'tree_method': 'hist', 'max_bin': 256, 'learning_rate': 0.035, 'n_estimators': 900, 'max_depth': 3, 'min_child_weight': 9, 'gamma': 0.5, 'subsample': 0.7, 'colsample_bytree': 0.7, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.8, 'reg_alpha': 0.4, 'reg_lambda': 10.0, 'max_delta_step': 1}\n",
      "\n",
      "Fold 1: no ES, train=7200, val=800, acc_val=81.62%, acc_val_opt=82.12% @thr=0.623, acc_train=86.56%, gap=4.93%\n",
      "Fold 2: no ES, train=7200, val=800, acc_val=81.88%, acc_val_opt=82.12% @thr=0.504, acc_train=86.44%, gap=4.57%\n",
      "Fold 3: no ES, train=7200, val=800, acc_val=82.12%, acc_val_opt=82.75% @thr=0.396, acc_train=86.64%, gap=4.51%\n",
      "Fold 4: no ES, train=7200, val=800, acc_val=84.50%, acc_val_opt=84.88% @thr=0.459, acc_train=86.04%, gap=1.54%\n",
      "Fold 5: no ES, train=7200, val=800, acc_val=82.88%, acc_val_opt=83.25% @thr=0.600, acc_train=86.58%, gap=3.71%\n",
      "Fold 6: no ES, train=7200, val=800, acc_val=80.25%, acc_val_opt=81.25% @thr=0.447, acc_train=86.74%, gap=6.49%\n",
      "Fold 7: no ES, train=7200, val=800, acc_val=83.38%, acc_val_opt=83.62% @thr=0.514, acc_train=86.32%, gap=2.94%\n",
      "Fold 8: no ES, train=7200, val=800, acc_val=82.88%, acc_val_opt=83.25% @thr=0.418, acc_train=86.53%, gap=3.65%\n",
      "Fold 9: no ES, train=7200, val=800, acc_val=82.25%, acc_val_opt=82.62% @thr=0.529, acc_train=86.40%, gap=4.15%\n",
      "Fold 10: no ES, train=7200, val=800, acc_val=80.88%, acc_val_opt=80.88% @thr=0.500, acc_train=86.42%, gap=5.54%\n",
      "\n",
      "============================================================\n",
      "Risultati Cross-Validation\n",
      "============================================================\n",
      "  Fold 1: val_acc=81.62%, val_acc_opt=82.12% @thr=0.623, train_acc=86.56%, gap=4.93%\n",
      "  Fold 2: val_acc=81.88%, val_acc_opt=82.12% @thr=0.504, train_acc=86.44%, gap=4.57%\n",
      "  Fold 3: val_acc=82.12%, val_acc_opt=82.75% @thr=0.396, train_acc=86.64%, gap=4.51%\n",
      "  Fold 4: val_acc=84.50%, val_acc_opt=84.88% @thr=0.459, train_acc=86.04%, gap=1.54%\n",
      "  Fold 5: val_acc=82.88%, val_acc_opt=83.25% @thr=0.600, train_acc=86.58%, gap=3.71%\n",
      "  Fold 6: val_acc=80.25%, val_acc_opt=81.25% @thr=0.447, train_acc=86.74%, gap=6.49%\n",
      "  Fold 7: val_acc=83.38%, val_acc_opt=83.62% @thr=0.514, train_acc=86.32%, gap=2.94%\n",
      "  Fold 8: val_acc=82.88%, val_acc_opt=83.25% @thr=0.418, train_acc=86.53%, gap=3.65%\n",
      "  Fold 9: val_acc=82.25%, val_acc_opt=82.62% @thr=0.529, train_acc=86.40%, gap=4.15%\n",
      "  Fold 10: val_acc=80.88%, val_acc_opt=80.88% @thr=0.500, train_acc=86.42%, gap=5.54%\n",
      "\n",
      "Mean CV accuracy (0.5): 82.26%\n",
      "Mean CV accuracy (opt thr): 82.67%\n",
      "Mean train accuracy: 86.47%\n",
      "Mean gap (train - val): 4.20%\n",
      "Std CV accuracy:  1.16%\n",
      "Min/Max val acc:  80.25% / 84.50%\n",
      "\n",
      "Peggiore fold: #6 con acc_val=80.25% | acc_val_opt=81.25% | acc_train=86.74% | gap=6.49%\n"
     ]
    }
   ],
   "source": [
    "# === 10-Fold Cross-Validation con iperparametri FISSI ===\n",
    "# IMPORTANTE: Assegna qui i migliori iperparametri trovati dalla cella precedente\n",
    "# Oppure lascia questi di default (conservativi per ridurre overfitting)\n",
    "\n",
    "best_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'max_bin': 256,          # istogrammi più grossolani = meno varianza e più veloce\n",
    "    'learning_rate': 0.035,  # leggermente più alto con meno alberi\n",
    "    'n_estimators': 900,     # meno alberi per ridurre overfitting\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 9,   # nodi con più peso => meno overfit\n",
    "    'gamma': 0.5,            # penalizza split deboli\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bynode': 0.7,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'reg_alpha': 0.4,        # L1\n",
    "    'reg_lambda': 10.0,      # L2 più alta\n",
    "    'max_delta_step': 1\n",
    "}\n",
    "\n",
    "print(\"=== 10-Fold Cross-Validation (9 train + 1 validation) ===\")\n",
    "print(f\"Parametri utilizzati: {best_params}\\n\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb  # per callback EarlyStopping se disponibile\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_accuracies = []\n",
    "folds_info = []\n",
    "train_accuracies = []\n",
    "train_val_gaps = []\n",
    "outer_accuracies_opt = []\n",
    "\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "AUTO_BALANCE_POS_WEIGHT = True\n",
    "if AUTO_BALANCE_POS_WEIGHT:\n",
    "    pos_rate = float(y_train_val.mean())\n",
    "    spw = (1.0 - pos_rate) / (pos_rate + 1e-9)\n",
    "    if spw > 1.0:\n",
    "        best_params = dict(best_params)\n",
    "        best_params['scale_pos_weight'] = float(min(max(spw, 1.0), 10.0))\n",
    "        print(f\"Auto scale_pos_weight: {best_params['scale_pos_weight']:.3f}\")\n",
    "\n",
    "def best_threshold_for_accuracy(y_true, proba, n_grid=201):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    proba = np.asarray(proba).astype(float)\n",
    "    grid = np.unique(np.quantile(proba, np.linspace(0, 1, n_grid)))\n",
    "    best_thr, best_acc = 0.5, 0.0\n",
    "    for t in grid:\n",
    "        acc = ( ((proba >= t).astype(int) == y_true).mean() )\n",
    "        if (acc > best_acc) or (abs(acc - best_acc) < 1e-12 and abs(t - 0.5) < abs(best_thr - 0.5)):\n",
    "            best_acc, best_thr = float(acc), float(t)\n",
    "    return best_thr, best_acc\n",
    "\n",
    "def _fit_with_es(clf, X_tr, y_tr, X_val, y_val):\n",
    "    \"\"\"Fit con EarlyStopping via callback se supportato; fallback senza ES.\"\"\"\n",
    "    try:\n",
    "        cb = getattr(xgb.callback, 'EarlyStopping', None)\n",
    "        if cb is not None:\n",
    "            clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[cb(rounds=EARLY_STOPPING_ROUNDS, save_best=True, maximize=False)], verbose=False)\n",
    "            return True\n",
    "    except TypeError:\n",
    "        pass\n",
    "    clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    return False\n",
    "\n",
    "def _predict_proba_best(clf, X, best_iter=None, best_ntree_limit=None):\n",
    "    \"\"\"Version-safe predict_proba using either iteration_range (new) or ntree_limit (old).\"\"\"\n",
    "    try:\n",
    "        if best_iter is not None:\n",
    "            return clf.predict_proba(X, iteration_range=(0, int(best_iter)+1))[:, 1]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        if best_ntree_limit is not None:\n",
    "            return clf.predict_proba(X, ntree_limit=int(best_ntree_limit))[:, 1]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return clf.predict_proba(X)[:, 1]\n",
    "\n",
    "fold_idx = 0\n",
    "for train_idx, val_idx in skf.split(X_train_val, y_train_val):\n",
    "    fold_idx += 1\n",
    "    X_tr, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_tr, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "    clf = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    used_es = _fit_with_es(clf, X_tr, y_tr, X_val, y_val)\n",
    "\n",
    "    best_iter = getattr(clf, 'best_iteration', None)\n",
    "    try:\n",
    "        booster = clf.get_booster()\n",
    "    except Exception:\n",
    "        booster = None\n",
    "    best_ntree_limit = getattr(booster, 'best_ntree_limit', None) if booster is not None else None\n",
    "\n",
    "    y_val_proba = _predict_proba_best(clf, X_val, best_iter, best_ntree_limit)\n",
    "    y_pred = (y_val_proba >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    outer_accuracies.append(acc)\n",
    "\n",
    "    y_tr_proba = _predict_proba_best(clf, X_tr, best_iter, best_ntree_limit)\n",
    "    y_tr_pred = (y_tr_proba >= 0.5).astype(int)\n",
    "    tr_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "    gap = float(tr_acc - acc)\n",
    "    train_accuracies.append(tr_acc)\n",
    "    train_val_gaps.append(gap)\n",
    "\n",
    "    thr_acc, acc_opt = best_threshold_for_accuracy(y_val, y_val_proba, n_grid=301)\n",
    "    outer_accuracies_opt.append(acc_opt)\n",
    "\n",
    "    val_index_global = idx_train_val[val_idx]\n",
    "    train_index_global = idx_train_val[train_idx]\n",
    "\n",
    "    folds_info.append({\n",
    "        'fold': fold_idx,\n",
    "        'acc': float(acc),\n",
    "        'train_acc': float(tr_acc),\n",
    "        'gap_train_minus_val': float(gap),\n",
    "        'acc_opt': float(acc_opt),\n",
    "        'thr_acc': float(thr_acc),\n",
    "        'best_iteration': int(best_iter) if best_iter is not None else None,\n",
    "        'train_idx': train_idx,\n",
    "        'val_idx': val_idx,\n",
    "        'train_index_global': train_index_global,\n",
    "        'val_index_global': val_index_global,\n",
    "        'y_true': y_val.astype(int),\n",
    "        'y_pred': y_pred.astype(int),\n",
    "        'y_proba': y_val_proba.astype(float)\n",
    "    })\n",
    "\n",
    "    es_tag = 'with ES' if used_es else 'no ES'\n",
    "    print(f'Fold {fold_idx}: {es_tag}, train={len(y_tr)}, val={len(y_val)}, acc_val={acc*100:.2f}%, acc_val_opt={acc_opt*100:.2f}% @thr={thr_acc:.3f}, acc_train={tr_acc*100:.2f}%, gap={(gap)*100:.2f}%')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Risultati Cross-Validation')\n",
    "print('='*60)\n",
    "for i, a in enumerate(outer_accuracies, 1):\n",
    "    print(f'  Fold {i}: val_acc={a*100:.2f}%, val_acc_opt={outer_accuracies_opt[i-1]*100:.2f}% @thr={folds_info[i-1][\"thr_acc\"]:.3f}, train_acc={train_accuracies[i-1]*100:.2f}%, gap={train_val_gaps[i-1]*100:.2f}%')\n",
    "print(f'\\nMean CV accuracy (0.5): {np.mean(outer_accuracies)*100:.2f}%')\n",
    "print(f'Mean CV accuracy (opt thr): {np.mean(outer_accuracies_opt)*100:.2f}%')\n",
    "print(f'Mean train accuracy: {np.mean(train_accuracies)*100:.2f}%')\n",
    "print(f'Mean gap (train - val): {np.mean(train_val_gaps)*100:.2f}%')\n",
    "print(f'Std CV accuracy:  {np.std(outer_accuracies)*100:.2f}%')\n",
    "print(f'Min/Max val acc:  {np.min(outer_accuracies)*100:.2f}% / {np.max(outer_accuracies)*100:.2f}%')\n",
    "\n",
    "WORST_FOLD_IDX = int(np.argmin(outer_accuracies))\n",
    "WORST_FOLD_NUM = int(folds_info[WORST_FOLD_IDX]['fold'])\n",
    "print(f\"\\nPeggiore fold: #{WORST_FOLD_NUM} con acc_val={outer_accuracies[WORST_FOLD_IDX]*100:.2f}% | acc_val_opt={outer_accuracies_opt[WORST_FOLD_IDX]*100:.2f}% | acc_train={train_accuracies[WORST_FOLD_IDX]*100:.2f}% | gap={train_val_gaps[WORST_FOLD_IDX]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b87173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission rapida post-CV ===\n",
      "✅ File di submission salvato in submission.csv\n",
      "   battle_id  player_won\n",
      "0          0           0\n",
      "1          1           1\n",
      "2          2           1\n",
      "3          3           1\n",
      "4          4           1\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Submission rapida post-CV ===\")\n",
    "cv_submission_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "cv_submission_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "test_aligned = test_df.reindex(columns=FEATURES, fill_value=0)\n",
    "X_test_matrix = test_aligned.astype(float).to_numpy()\n",
    "test_predictions = cv_submission_model.predict(X_test_matrix).astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': test_predictions.astype(np.int64)\n",
    "})\n",
    "\n",
    "submission_path = 'submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"✅ File di submission salvato in {submission_path}\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
