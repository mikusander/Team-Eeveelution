{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b7eeca",
   "metadata": {},
   "source": [
    "# Pokémon battles — XGBoost with 10-fold outer CV + Grid Search\n",
    "Notebook breve che esegue: feature engineering, split train/val/test, 10-fold outer CV con GridSearchCV interno, valutazione per fold, valutazione su holdout e generazione submission.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aebef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati...\n",
      "Train records: 10000, Test records: 5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Percorsi (modificare se necessario) ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "train_file_path = 'train.jsonl'\n",
    "test_file_path = 'test.jsonl'\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "print('Caricamento dati...')\n",
    "train_raw = load_jsonl(train_file_path)\n",
    "test_raw = load_jsonl(test_file_path)\n",
    "print(f'Train records: {len(train_raw)}, Test records: {len(test_raw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e15c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FE: 100%|██████████| 10000/10000 [00:05<00:00, 1948.17it/s]\n",
      "FE: 100%|██████████| 5000/5000 [00:02<00:00, 1883.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape train/test: (10000, 232) (5000, 231)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "      <th>p1_base_hp_sum</th>\n",
       "      <th>p1_base_hp_mean</th>\n",
       "      <th>p1_base_hp_max</th>\n",
       "      <th>p1_base_hp_min</th>\n",
       "      <th>p1_base_hp_std</th>\n",
       "      <th>p1_base_atk_sum</th>\n",
       "      <th>p1_base_atk_mean</th>\n",
       "      <th>p1_base_atk_max</th>\n",
       "      <th>...</th>\n",
       "      <th>team_hp_sum_minus_p2lead_hp</th>\n",
       "      <th>team_spa_mean_minus_p2spa</th>\n",
       "      <th>speed_advantage</th>\n",
       "      <th>n_unique_types_diff</th>\n",
       "      <th>damage_per_turn_diff</th>\n",
       "      <th>last_pair</th>\n",
       "      <th>p1_vs_lead_avg_effectiveness</th>\n",
       "      <th>p1_vs_lead_max_effectiveness</th>\n",
       "      <th>p1_super_effective_options</th>\n",
       "      <th>p1_se_options_vs_lead_bulk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>115.833333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.367179</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.070393</td>\n",
       "      <td>starmie_VS_snorlax</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.204534</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.012174</td>\n",
       "      <td>tauros_VS_alakazam</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>124.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.382753</td>\n",
       "      <td>505.0</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>495.0</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>snorlax_VS_gengar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65.362239</td>\n",
       "      <td>465.0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>655.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>345.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.014574</td>\n",
       "      <td>snorlax_VS_zapdos</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>685.0</td>\n",
       "      <td>114.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.794107</td>\n",
       "      <td>455.0</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.0</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>tauros_VS_chansey</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won  p1_base_hp_sum  p1_base_hp_mean  p1_base_hp_max  \\\n",
       "0          0           1           695.0       115.833333           250.0   \n",
       "1          1           1           740.0       123.333333           250.0   \n",
       "2          2           1           745.0       124.166667           250.0   \n",
       "3          3           1           730.0       121.666667           250.0   \n",
       "4          4           1           685.0       114.166667           250.0   \n",
       "\n",
       "   p1_base_hp_min  p1_base_hp_std  p1_base_atk_sum  p1_base_atk_mean  \\\n",
       "0            55.0       69.367179            435.0         72.500000   \n",
       "1            65.0       64.204534            435.0         72.500000   \n",
       "2            60.0       64.382753            505.0         84.166667   \n",
       "3            60.0       65.362239            465.0         77.500000   \n",
       "4            50.0       70.794107            455.0         75.833333   \n",
       "\n",
       "   p1_base_atk_max  ...  team_hp_sum_minus_p2lead_hp  \\\n",
       "0            110.0  ...                        635.0   \n",
       "1            110.0  ...                        685.0   \n",
       "2            130.0  ...                        495.0   \n",
       "3            110.0  ...                        655.0   \n",
       "4            110.0  ...                        625.0   \n",
       "\n",
       "   team_spa_mean_minus_p2spa  speed_advantage  n_unique_types_diff  \\\n",
       "0                   0.000000            365.0                    3   \n",
       "1                 -45.000000            250.0                    4   \n",
       "2                 -15.000000            345.0                    6   \n",
       "3                  33.333333            345.0                    6   \n",
       "4                  -2.500000            320.0                    4   \n",
       "\n",
       "   damage_per_turn_diff           last_pair  p1_vs_lead_avg_effectiveness  \\\n",
       "0             -0.070393  starmie_VS_snorlax                      1.083333   \n",
       "1             -0.012174  tauros_VS_alakazam                      1.000000   \n",
       "2             -0.000690   snorlax_VS_gengar                      1.000000   \n",
       "3             -0.014574   snorlax_VS_zapdos                      1.000000   \n",
       "4              0.006923   tauros_VS_chansey                      1.083333   \n",
       "\n",
       "   p1_vs_lead_max_effectiveness  p1_super_effective_options  \\\n",
       "0                           2.0                           1   \n",
       "1                           1.0                           0   \n",
       "2                           1.0                           0   \n",
       "3                           1.0                           0   \n",
       "4                           2.0                           1   \n",
       "\n",
       "   p1_se_options_vs_lead_bulk  \n",
       "0                    0.005405  \n",
       "1                    0.000000  \n",
       "2                    0.000000  \n",
       "3                    0.000000  \n",
       "4                    0.005405  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# === TYPE CHART (Gen 1) ===\n",
    "TYPE_CHART = {\n",
    "    'normal': {'rock': 0.5, 'ghost': 0},\n",
    "    'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ice': 2, 'bug': 2, 'rock': 0.5, 'dragon': 0.5},\n",
    "    'water': {'fire': 2, 'water': 0.5, 'grass': 0.5, 'ground': 2, 'rock': 2, 'dragon': 0.5},\n",
    "    'grass': {'fire': 0.5, 'water': 2, 'grass': 0.5, 'poison': 0.5, 'ground': 2, 'flying': 0.5, 'bug': 0.5, 'rock': 2, 'dragon': 0.5},\n",
    "    'electric': {'water': 2, 'grass': 0.5, 'electric': 0.5, 'ground': 0, 'flying': 2, 'dragon': 0.5},\n",
    "    'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ground': 2, 'flying': 2, 'dragon': 2},\n",
    "    'fighting': {'normal': 2, 'ice': 2, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2, 'ghost': 0},\n",
    "    'poison': {'grass': 2, 'poison': 0.5, 'ground': 0.5, 'bug': 2, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground': {'fire': 2, 'grass': 0.5, 'electric': 2, 'poison': 2, 'flying': 0, 'bug': 0.5, 'rock': 2},\n",
    "    'flying': {'grass': 2, 'electric': 0.5, 'fighting': 2, 'bug': 2, 'rock': 0.5},\n",
    "    'psychic': {'fighting': 2, 'poison': 2, 'psychic': 0.5, 'ghost': 0},\n",
    "    'bug': {'fire': 0.5, 'grass': 2, 'fighting': 0.5, 'poison': 2, 'flying': 0.5, 'psychic': 2, 'ghost': 0.5},\n",
    "    'rock': {'fire': 2, 'ice': 2, 'fighting': 0.5, 'ground': 0.5, 'flying': 2, 'bug': 2},\n",
    "    'ghost': {'normal': 0, 'psychic': 0, 'ghost': 2},\n",
    "    'dragon': {'dragon': 2}\n",
    "}\n",
    "\n",
    "def get_effectiveness(attack_type: str, defense_types: list) -> float:\n",
    "    if not attack_type or not defense_types:\n",
    "        return 1.0\n",
    "    eff = 1.0\n",
    "    for d in defense_types:\n",
    "        eff *= TYPE_CHART.get(attack_type, {}).get(d, 1.0)\n",
    "    return eff\n",
    "\n",
    "def calculate_type_advantage(team1: list, team2_lead: dict) -> dict:\n",
    "    out = {'p1_vs_lead_avg_effectiveness': 0.0, 'p1_vs_lead_max_effectiveness': 0.0, 'p1_super_effective_options': 0}\n",
    "    if not team1 or not team2_lead:\n",
    "        return out\n",
    "    lead_types = [t.lower() for t in team2_lead.get('types', [])]\n",
    "    if not lead_types:\n",
    "        return out\n",
    "    effs = []\n",
    "    for p in team1:\n",
    "        p_types = [t.lower() for t in p.get('types', [])]\n",
    "        max_eff = 0.0\n",
    "        for pt in p_types:\n",
    "            max_eff = max(max_eff, get_effectiveness(pt, lead_types))\n",
    "        effs.append(max_eff)\n",
    "    if not effs:\n",
    "        return out\n",
    "    out['p1_vs_lead_avg_effectiveness'] = float(np.mean(effs))\n",
    "    out['p1_vs_lead_max_effectiveness'] = float(np.max(effs))\n",
    "    out['p1_super_effective_options'] = int(sum(1 for e in effs if e >= 2))\n",
    "    return out\n",
    "\n",
    "def _entropy(counter: Counter) -> float:\n",
    "    total = sum(counter.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    ent = 0.0\n",
    "    for v in counter.values():\n",
    "        p = v / total\n",
    "        if p > 0:\n",
    "            ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "\n",
    "def team_aggregate_features(team: list, prefix: str = 'p1_') -> dict:\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    out = {}\n",
    "    vals = {s: [] for s in stats}\n",
    "    levels = []\n",
    "    types_counter = Counter()\n",
    "    names = []\n",
    "    for p in team:\n",
    "        names.append(p.get('name',''))\n",
    "        for s in stats:\n",
    "            vals[s].append(p.get(s, 0))\n",
    "        levels.append(p.get('level', 0))\n",
    "        for t in p.get('types', []):\n",
    "            types_counter[t.lower()] += 1\n",
    "    for s in stats:\n",
    "        arr = np.array(vals[s], dtype=float)\n",
    "        out[f'{prefix}{s}_sum'] = float(arr.sum())\n",
    "        out[f'{prefix}{s}_mean'] = float(arr.mean())\n",
    "        out[f'{prefix}{s}_max'] = float(arr.max())\n",
    "        out[f'{prefix}{s}_min'] = float(arr.min())\n",
    "        out[f'{prefix}{s}_std'] = float(arr.std())\n",
    "    level_arr = np.array(levels, dtype=float)\n",
    "    out[f'{prefix}level_mean'] = float(level_arr.mean()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}level_sum'] = float(level_arr.sum()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}n_unique_types'] = int(len(types_counter))\n",
    "    common_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']\n",
    "    for t in common_types:\n",
    "        out[f'{prefix}type_{t}_count'] = int(types_counter.get(t, 0))\n",
    "    out[f'{prefix}lead_name'] = names[0] if names else ''\n",
    "    out[f'{prefix}n_unique_names'] = int(len(set(names)))\n",
    "    out[f'{prefix}type_entropy'] = float(_entropy(types_counter))\n",
    "    spe_arr = np.array(vals['base_spe'], dtype=float)\n",
    "    out[f'{prefix}spe_p25'] = float(np.percentile(spe_arr, 25)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p50'] = float(np.percentile(spe_arr, 50)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p75'] = float(np.percentile(spe_arr, 75)) if spe_arr.size else 0.0\n",
    "    return out\n",
    "\n",
    "def lead_vs_lead_features(p1_lead: dict, p2_lead: dict) -> dict:\n",
    "    out = {}\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    for s in stats:\n",
    "        out[f'lead_diff_{s}'] = float(p1_lead.get(s,0) - p2_lead.get(s,0))\n",
    "    out['lead_speed_advantage'] = float(p1_lead.get('base_spe',0) - p2_lead.get('base_spe',0))\n",
    "    p1_types = [t.lower() for t in p1_lead.get('types', [])]\n",
    "    p2_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    max_eff = 0.0\n",
    "    for pt in p1_types:\n",
    "        max_eff = max(max_eff, get_effectiveness(pt, p2_types))\n",
    "    out['lead_p1_vs_p2_effectiveness'] = float(max_eff)\n",
    "    return out\n",
    "\n",
    "def lead_aggregate_features(pokemon: dict, prefix: str = 'p2_lead_') -> dict:\n",
    "    out = {}\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    for s in stats:\n",
    "        out[f'{prefix}{s}'] = float(pokemon.get(s,0))\n",
    "    out[f'{prefix}level'] = int(pokemon.get('level',0))\n",
    "    types = [x.lower() for x in pokemon.get('types', [])]\n",
    "    common_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']\n",
    "    for t in common_types:\n",
    "        out[f'{prefix}type_{t}'] = int(t in types)\n",
    "    out[f'{prefix}name'] = pokemon.get('name','')\n",
    "    out[f'{prefix}n_unique_types'] = int(len(set(types)))\n",
    "    return out\n",
    "\n",
    "def summary_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline:\n",
    "        return {'tl_p1_moves':0,'tl_p2_moves':0,'tl_p1_est_damage':0.0,'tl_p2_est_damage':0.0,'damage_diff':0.0}\n",
    "    p1_moves = p2_moves = 0\n",
    "    p1_damage = p2_damage = 0.0\n",
    "    p1_last_active = p2_last_active = ''\n",
    "    p1_last_hp = p2_last_hp = np.nan\n",
    "    p1_fainted = p2_fainted = 0\n",
    "    p1_fainted_names = set()\n",
    "    p2_fainted_names = set()\n",
    "    last_p1_hp = {}\n",
    "    last_p2_hp = {}\n",
    "    p1_comeback_kos = 0\n",
    "    p2_comeback_kos = 0\n",
    "    p1_inflicted_statuses = Counter()\n",
    "    p2_inflicted_statuses = Counter()\n",
    "    p1_pokemon_statuses = {}\n",
    "    p2_pokemon_statuses = {}\n",
    "    p1_move_type_counts = Counter()\n",
    "    p2_move_type_counts = Counter()\n",
    "    p1_damage_first2 = 0.0\n",
    "    p2_damage_first2 = 0.0\n",
    "\n",
    "    # NEW: per-turn damage accumulation, KO timing and early/late KO counters\n",
    "    p1_dmg_by_turn = {}  # damage inflitto da p1 (contro p2) per turno\n",
    "    p2_dmg_by_turn = {}  # damage inflitto da p2 (contro p1) per turno\n",
    "    seen_turns = set()\n",
    "    first_ko_turn_p1_taken = None   # primo KO subìto da p1 (p1_fainted++)\n",
    "    first_ko_turn_p1_inflicted = None  # primo KO inflitto da p1 (p2_fainted++)\n",
    "    early_threshold = 10\n",
    "    p1_kos_early = p1_kos_late = 0\n",
    "    p2_kos_early = p2_kos_late = 0\n",
    "\n",
    "    for turn in timeline[:30]:\n",
    "        prev_p1_fainted, prev_p2_fainted = p1_fainted, p2_fainted\n",
    "        p1_state = turn.get('p1_pokemon_state',{}) or {}\n",
    "        p2_state = turn.get('p2_pokemon_state',{}) or {}\n",
    "        tnum = turn.get('turn', None)\n",
    "        if tnum is None:\n",
    "            # fallback: usa lunghezza dei turni visti + 1\n",
    "            tnum = (len(seen_turns) + 1)\n",
    "        seen_turns.add(tnum)\n",
    "\n",
    "        if p1_state.get('name'):\n",
    "            p1_last_active = p1_state.get('name')\n",
    "        if p2_state.get('name'):\n",
    "            p2_last_active = p2_state.get('name')\n",
    "\n",
    "        if p1_state.get('fainted') and p1_state.get('name') not in p1_fainted_names:\n",
    "            p1_fainted += 1\n",
    "            p1_fainted_names.add(p1_state.get('name'))\n",
    "            if first_ko_turn_p1_taken is None:\n",
    "                first_ko_turn_p1_taken = tnum\n",
    "            if tnum <= early_threshold: p2_kos_early += 1\n",
    "            else: p2_kos_late += 1\n",
    "        if p2_state.get('fainted') and p2_state.get('name') not in p2_fainted_names:\n",
    "            p2_fainted += 1\n",
    "            p2_fainted_names.add(p2_state.get('name'))\n",
    "            if first_ko_turn_p1_inflicted is None:\n",
    "                first_ko_turn_p1_inflicted = tnum\n",
    "            if tnum <= early_threshold: p1_kos_early += 1\n",
    "            else: p1_kos_late += 1\n",
    "\n",
    "        p2_name, p2_hp = p2_state.get('name'), p2_state.get('hp_pct')\n",
    "        if p2_name and p2_hp is not None:\n",
    "            prev_hp = last_p2_hp.get(p2_name)\n",
    "            if prev_hp is not None:\n",
    "                delta = max(0.0, prev_hp - p2_hp)\n",
    "                p1_damage += delta\n",
    "                p1_dmg_by_turn[tnum] = p1_dmg_by_turn.get(tnum, 0.0) + delta\n",
    "                if turn.get('turn',999) <= 2:\n",
    "                    p1_damage_first2 += delta\n",
    "            last_p2_hp[p2_name] = p2_hp\n",
    "\n",
    "        p1_name, p1_hp = p1_state.get('name'), p1_state.get('hp_pct')\n",
    "        if p1_name and p1_hp is not None:\n",
    "            prev_hp = last_p1_hp.get(p1_name)\n",
    "            if prev_hp is not None:\n",
    "                delta = max(0.0, prev_hp - p1_hp)\n",
    "                p2_damage += delta\n",
    "                p2_dmg_by_turn[tnum] = p2_dmg_by_turn.get(tnum, 0.0) + delta\n",
    "                if turn.get('turn',999) <= 2:\n",
    "                    p2_damage_first2 += delta\n",
    "            last_p1_hp[p1_name] = p1_hp\n",
    "\n",
    "        damage_diff_so_far = p1_damage - p2_damage\n",
    "        if p2_fainted > prev_p2_fainted and damage_diff_so_far < -1.0:\n",
    "            p1_comeback_kos += 1\n",
    "        if p1_fainted > prev_p1_fainted and damage_diff_so_far > 1.0:\n",
    "            p2_comeback_kos += 1\n",
    "\n",
    "        p2_status = p2_state.get('status')\n",
    "        if p2_name and p2_status and p2_pokemon_statuses.get(p2_name) != p2_status:\n",
    "            p1_inflicted_statuses[p2_status] += 1\n",
    "            p2_pokemon_statuses[p2_name] = p2_status\n",
    "        p1_status = p1_state.get('status')\n",
    "        if p1_name and p1_status and p1_pokemon_statuses.get(p1_name) != p1_status:\n",
    "            p2_inflicted_statuses[p1_status] += 1\n",
    "            p1_pokemon_statuses[p1_name] = p1_status\n",
    "\n",
    "        p1_move = turn.get('p1_move_details') or {}\n",
    "        p2_move = turn.get('p2_move_details') or {}\n",
    "        if p1_move and p1_move.get('type'):\n",
    "            p1_move_type_counts[(p1_move.get('type') or '').lower()] += 1\n",
    "        if p2_move and p2_move.get('type'):\n",
    "            p2_move_type_counts[(p2_move.get('type') or '').lower()] += 1\n",
    "        if turn.get('p1_move_details'):\n",
    "            p1_moves += 1\n",
    "        if turn.get('p2_move_details'):\n",
    "            p2_moves += 1\n",
    "        p1_last_hp = p1_state.get('hp_pct', np.nan)\n",
    "        p2_last_hp = p2_state.get('hp_pct', np.nan)\n",
    "\n",
    "    # ...existing code computing out[...] baseline metrics...\n",
    "    out['tl_p1_moves'] = int(p1_moves)\n",
    "    out['tl_p2_moves'] = int(p2_moves)\n",
    "    out['tl_p1_est_damage'] = float(p1_damage)\n",
    "    out['tl_p2_est_damage'] = float(p2_damage)\n",
    "    out['damage_diff'] = float(p1_damage - p2_damage)\n",
    "    out['fainted_diff'] = int(p1_fainted - p2_fainted)\n",
    "    out['tl_p1_last_hp'] = float(p1_last_hp) if not np.isnan(p1_last_hp) else 0.0\n",
    "    out['tl_p2_last_hp'] = float(p2_last_hp) if not np.isnan(p2_last_hp) else 0.0\n",
    "    out['tl_p1_last_active'] = p1_last_active\n",
    "    out['tl_p2_last_active'] = p2_last_active\n",
    "    if p1_team:\n",
    "        p1_total_hp_sum = sum(p.get('base_hp',0) for p in p1_team)\n",
    "        p1_avg_def = np.mean([p.get('base_def',0) for p in p1_team] or [0])\n",
    "        p1_avg_spd = np.mean([p.get('base_spd',0) for p in p1_team] or [0])\n",
    "        out['tl_p2_damage_vs_p1_hp_pool'] = float(p2_damage / (p1_total_hp_sum + 1e-6))\n",
    "        out['tl_p1_defensive_endurance'] = float((p1_avg_def + p1_avg_spd) / (p2_damage + 1e-6))\n",
    "    out['tl_p1_comeback_kos'] = int(p1_comeback_kos)\n",
    "    out['tl_p2_comeback_kos'] = int(p2_comeback_kos)\n",
    "    out['tl_comeback_kos_diff'] = int(p1_comeback_kos - p2_comeback_kos)\n",
    "\n",
    "    common_statuses = ['brn','par','slp','frz','psn','tox']\n",
    "    for status in common_statuses:\n",
    "        out[f'tl_p1_inflicted_{status}_count'] = int(p1_inflicted_statuses.get(status,0))\n",
    "        out[f'tl_p2_inflicted_{status}_count'] = int(p2_inflicted_statuses.get(status,0))\n",
    "        out[f'tl_inflicted_{status}_diff'] = int(p1_inflicted_statuses.get(status,0) - p2_inflicted_statuses.get(status,0))\n",
    "\n",
    "    common_move_types = ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying','ghost','bug','poison','fighting']\n",
    "    for mt in common_move_types:\n",
    "        out[f'tl_p1_move_type_{mt}_count'] = int(p1_move_type_counts.get(mt,0))\n",
    "        out[f'tl_p2_move_type_{mt}_count'] = int(p2_move_type_counts.get(mt,0))\n",
    "        out[f'tl_move_type_{mt}_count_diff'] = int(p1_move_type_counts.get(mt,0) - p2_move_type_counts.get(mt,0))\n",
    "\n",
    "    out['tl_p1_damage_first2'] = float(p1_damage_first2)\n",
    "    out['tl_p2_damage_first2'] = float(p2_damage_first2)\n",
    "    out['tl_first2_damage_diff'] = float(p1_damage_first2 - p2_damage_first2)\n",
    "\n",
    "    # NEW: derived, normalized and late-game features\n",
    "    turns_count = max(1, len(seen_turns))\n",
    "    out['tl_turns_count'] = int(turns_count)\n",
    "    out['tl_p1_moves_rate'] = float(p1_moves / turns_count)\n",
    "    out['tl_p2_moves_rate'] = float(p2_moves / turns_count)\n",
    "    out['tl_p1_damage_per_turn'] = float(p1_damage / turns_count)\n",
    "    out['tl_p2_damage_per_turn'] = float(p2_damage / turns_count)\n",
    "    out['tl_damage_rate_diff'] = float(out['tl_p1_damage_per_turn'] - out['tl_p2_damage_per_turn'])\n",
    "\n",
    "    # last-5-turns damage window\n",
    "    if seen_turns:\n",
    "        recent_turns = sorted(seen_turns)[-5:]\n",
    "        p1_last5 = sum(p1_dmg_by_turn.get(t,0.0) for t in recent_turns)\n",
    "        p2_last5 = sum(p2_dmg_by_turn.get(t,0.0) for t in recent_turns)\n",
    "    else:\n",
    "        p1_last5 = p2_last5 = 0.0\n",
    "    out['tl_p1_damage_last5'] = float(p1_last5)\n",
    "    out['tl_p2_damage_last5'] = float(p2_last5)\n",
    "    out['tl_last5_damage_diff'] = float(p1_last5 - p2_last5)\n",
    "    # NEW: ratio danno ultimi 5 turni vs totale\n",
    "    out['tl_p1_last5_damage_ratio'] = float(p1_last5 / (p1_damage + 1e-6))\n",
    "    out['tl_p2_last5_damage_ratio'] = float(p2_last5 / (p2_damage + 1e-6))\n",
    "    out['tl_last5_damage_ratio_diff'] = float(out['tl_p1_last5_damage_ratio'] - out['tl_p2_last5_damage_ratio'])\n",
    "\n",
    "    # time-weighted damage advantage (peso crescente con il turno)\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns)\n",
    "        w = np.linspace(1.0, 2.0, num=len(ts))  # pesi crescenti\n",
    "        w = w / (w.sum() + 1e-9)\n",
    "        adv = [(p1_dmg_by_turn.get(t,0.0) - p2_dmg_by_turn.get(t,0.0)) for t in ts]\n",
    "        out['tl_weighted_damage_diff'] = float(np.dot(w, adv))\n",
    "    else:\n",
    "        out['tl_weighted_damage_diff'] = 0.0\n",
    "\n",
    "    # NEW: comeback indicator (cambio di segno dell'adv cumulativo)\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns)\n",
    "        cum = 0.0\n",
    "        signs = []\n",
    "        for t in ts:\n",
    "            cum += (p1_dmg_by_turn.get(t,0.0) - p2_dmg_by_turn.get(t,0.0))\n",
    "            s = 1 if cum > 1e-9 else (-1 if cum < -1e-9 else 0)\n",
    "            if s != 0:\n",
    "                if not signs or signs[-1] != s:\n",
    "                    signs.append(s)\n",
    "        sign_flips = max(0, len(signs) - 1)\n",
    "        comeback_flag = 1 if (len(signs) >= 2 and signs[0] != signs[-1]) else 0\n",
    "    else:\n",
    "        sign_flips = 0\n",
    "        comeback_flag = 0\n",
    "    out['tl_damage_adv_sign_flips'] = int(sign_flips)\n",
    "    out['tl_comeback_flag'] = int(comeback_flag)\n",
    "\n",
    "    # KO timing and early/late counts\n",
    "    out['tl_first_ko_turn_p1_inflicted'] = int(first_ko_turn_p1_inflicted or 0)\n",
    "    out['tl_first_ko_turn_p1_taken'] = int(first_ko_turn_p1_taken or 0)\n",
    "    out['tl_first_ko_turn_diff'] = int((first_ko_turn_p1_inflicted or 0) - (first_ko_turn_p1_taken or 0))\n",
    "    out['tl_kos_early_p1'] = int(p1_kos_early)\n",
    "    out['tl_kos_late_p1'] = int(p1_kos_late)\n",
    "    out['tl_kos_early_p2'] = int(p2_kos_early)\n",
    "    out['tl_kos_late_p2'] = int(p2_kos_late)\n",
    "\n",
    "    # normalized status rates per turn\n",
    "    for status in common_statuses:\n",
    "        c1 = p1_inflicted_statuses.get(status,0)\n",
    "        c2 = p2_inflicted_statuses.get(status,0)\n",
    "        out[f'tl_p1_inflicted_{status}_rate'] = float(c1 / turns_count)\n",
    "        out[f'tl_p2_inflicted_{status}_rate'] = float(c2 / turns_count)\n",
    "        out[f'tl_inflicted_{status}_rate_diff'] = float((c1 - c2) / turns_count)\n",
    "\n",
    "    return out\n",
    "\n",
    "def ability_features(team: list, prefix: str) -> dict:\n",
    "    immunity_abilities = {'levitate':0,'volt_absorb':0,'water_absorb':0,'flash_fire':0}\n",
    "    stat_drop_abilities = {'intimidate':0}\n",
    "    weather_abilities = {'drought':0,'drizzle':0,'sand_stream':0}\n",
    "    out = {}\n",
    "    for pokemon in team:\n",
    "        ability = (pokemon.get('ability','') or '').lower().replace(' ','_')\n",
    "        if ability in immunity_abilities:\n",
    "            immunity_abilities[ability] += 1\n",
    "        if ability in stat_drop_abilities:\n",
    "            stat_drop_abilities[ability] += 1\n",
    "        if ability in weather_abilities:\n",
    "            weather_abilities[ability] += 1\n",
    "    for ability,count in immunity_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    for ability,count in stat_drop_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    for ability,count in weather_abilities.items():\n",
    "        out[f'{prefix}ability_{ability}_count'] = int(count)\n",
    "    out[f'{prefix}total_immunity_abilities'] = int(sum(immunity_abilities.values()))\n",
    "    out[f'{prefix}total_stat_drop_abilities'] = int(sum(stat_drop_abilities.values()))\n",
    "    return out\n",
    "\n",
    "def prepare_record_features(record: dict, max_turns: int = 30) -> dict:\n",
    "    out = {}\n",
    "    out['battle_id'] = record.get('battle_id')\n",
    "    if 'player_won' in record:\n",
    "        out['player_won'] = int(bool(record.get('player_won')))\n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    out.update(team_aggregate_features(p1_team, prefix='p1_'))\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    out.update(lead_aggregate_features(p2_lead, prefix='p2_lead_'))\n",
    "    out.update(ability_features(p1_team, prefix='p1_'))\n",
    "    p1_lead = p1_team[0] if p1_team else {}\n",
    "    out.update(lead_vs_lead_features(p1_lead, p2_lead))\n",
    "    out.update(ability_features([p2_lead], prefix='p2_lead_'))\n",
    "    out['p1_intimidate_vs_lead'] = 1 if out.get('p1_ability_intimidate_count',0) > 0 else 0\n",
    "    tl = record.get('battle_timeline', [])\n",
    "    out.update(summary_from_timeline(tl[:max_turns], p1_team))\n",
    "    out['team_hp_sum_minus_p2lead_hp'] = out.get('p1_base_hp_sum', 0) - out.get('p2_lead_base_hp', 0)\n",
    "    out['team_spa_mean_minus_p2spa'] = out.get('p1_base_spa_mean', 0) - out.get('p2_lead_base_spa', 0)\n",
    "    out['speed_advantage'] = out.get('p1_base_spe_sum', 0) - out.get('p2_lead_base_spe', 0)\n",
    "    out['n_unique_types_diff'] = out.get('p1_n_unique_types', 0) - out.get('p2_lead_n_unique_types', 1)\n",
    "    p1_moves = max(out.get('tl_p1_moves',1),1)\n",
    "    p2_moves = max(out.get('tl_p2_moves',1),1)\n",
    "    out['damage_per_turn_diff'] = (out.get('tl_p1_est_damage',0.0)/p1_moves) - (out.get('tl_p2_est_damage',0.0)/p2_moves)\n",
    "    out['last_pair'] = f\"{out.get('tl_p1_last_active','')}_VS_{out.get('tl_p2_last_active','')}\"\n",
    "    out.update(calculate_type_advantage(p1_team, p2_lead))\n",
    "    p2_lead_bulk = out.get('p2_lead_base_def',1) + out.get('p2_lead_base_spd',1)\n",
    "    out['p1_se_options_vs_lead_bulk'] = out.get('p1_super_effective_options',0) / (p2_lead_bulk + 1e-6)\n",
    "    p2_team = record.get('p2_team_details', [])\n",
    "    if p2_team:\n",
    "        out.update(team_aggregate_features(p2_team, prefix='p2_'))\n",
    "        out['team_hp_sum_diff'] = out.get('p1_base_hp_sum',0) - out.get('p2_base_hp_sum',0)\n",
    "        out['team_spa_mean_diff'] = out.get('p1_base_spa_mean',0) - out.get('p2_base_spa_mean',0)\n",
    "        out['team_spe_mean_diff'] = out.get('p1_base_spe_mean',0) - out.get('p2_base_spe_mean',0)\n",
    "        out['n_unique_types_team_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_n_unique_types',0)\n",
    "    return out\n",
    "\n",
    "def create_features_from_raw(data: list) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for b in tqdm(data, desc='FE'):\n",
    "        try:\n",
    "            feat = prepare_record_features(b, max_turns=30)\n",
    "            if 'battle_id' not in feat:\n",
    "                feat['battle_id'] = b.get('battle_id')\n",
    "            rows.append(feat)\n",
    "        except Exception as e:\n",
    "            rows.append({'battle_id': b.get('battle_id'), 'error': 1})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if 'player_won' in df.columns:\n",
    "        df['player_won'] = df['player_won'].astype(int)\n",
    "    return df.fillna(0)\n",
    "\n",
    "train_df = create_features_from_raw(train_raw)\n",
    "test_df = create_features_from_raw(test_raw)\n",
    "print('Feature shape train/test:', train_df.shape, test_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cede4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature numeriche (pre-stability): 180\n",
      "Stability filter: nessuna feature rimossa.\n",
      "Feature numeriche finali: 180\n",
      "Colonne escluse (stringhe): 5\n",
      "Late-game features rimosse (al netto whitelist): 27\n",
      "Whitelist preservate: ['tl_comeback_flag', 'tl_p2_damage_vs_p1_hp_pool', 'tl_last5_damage_ratio_diff', 'tl_damage_adv_sign_flips', 'tl_weighted_damage_diff', 'tl_p1_last5_damage_ratio', 'tl_p1_defensive_endurance', 'tl_last5_damage_diff', 'tl_p2_last5_damage_ratio']\n",
      "Drop extra (totali timeline e status diff): 18 -> esempi: ['tl_p1_est_damage', 'tl_p2_est_damage', 'tl_p1_moves', 'tl_p2_moves', 'tl_inflicted_brn_diff', 'tl_inflicted_par_diff']\n",
      "train_val size: 8000 holdout size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Preparazione X, y - FILTRO COLONNE STRINGA\n",
    "# Escludo colonne non numeriche (stringhe) che XGBoost non può usare\n",
    "exclude_cols = ['battle_id', 'player_won']\n",
    "# Identifica colonne stringa nel DataFrame\n",
    "string_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "exclude_cols.extend(string_cols)\n",
    "\n",
    "FEATURES = [c for c in train_df.columns if c not in exclude_cols]\n",
    "\n",
    "# Opzionale: escludi le NUOVE feature late-game se peggiorano accuracy\n",
    "DROP_NEW_TIMELINE_FEATURES = True  # metti False per tenerle\n",
    "late_new_static = [\n",
    "    'tl_turns_count','tl_p1_moves_rate','tl_p2_moves_rate',\n",
    "    'tl_p1_damage_per_turn','tl_p2_damage_per_turn','tl_damage_rate_diff',\n",
    "    'tl_p1_damage_last5','tl_p2_damage_last5','tl_last5_damage_diff',\n",
    "    'tl_weighted_damage_diff','tl_first_ko_turn_p1_inflicted','tl_first_ko_turn_p1_taken',\n",
    "    'tl_first_ko_turn_diff','tl_kos_early_p1','tl_kos_late_p1','tl_kos_early_p2','tl_kos_late_p2',\n",
    "    # nuove feature aggiunte sotto (verranno whitelestate)\n",
    "    'tl_p1_last5_damage_ratio','tl_p2_last5_damage_ratio','tl_last5_damage_ratio_diff',\n",
    "    'tl_damage_adv_sign_flips','tl_comeback_flag'\n",
    "]\n",
    "rate_cols = [c for c in train_df.columns if c.startswith('tl_') and c.endswith('_rate')]\n",
    "LATE_GAME_NEW_FEATURES = sorted(set(late_new_static + rate_cols))\n",
    "\n",
    "# WHITELIST: tieni sempre queste feature anche se DROP_NEW_TIMELINE_FEATURES=True\n",
    "WHITELIST_KEEP = {\n",
    "    'tl_weighted_damage_diff', 'tl_last5_damage_diff',\n",
    "    'tl_damage_adv_sign_flips', 'tl_comeback_flag',\n",
    "    'tl_p1_last5_damage_ratio', 'tl_p2_last5_damage_ratio', 'tl_last5_damage_ratio_diff',\n",
    "    'tl_p1_defensive_endurance', 'tl_p1_defensive_endurance_log',\n",
    "    'tl_p2_damage_vs_p1_hp_pool', 'tl_p2_damage_vs_p1_hp_pool_log'\n",
    "}\n",
    "if DROP_NEW_TIMELINE_FEATURES:\n",
    "    FEATURES = [c for c in FEATURES if (c not in LATE_GAME_NEW_FEATURES) or (c in WHITELIST_KEEP)]\n",
    "\n",
    "# === Drop aggiuntivo anti-overfitting: rimuovi totali timeline e differenze di status pesanti ===\n",
    "RAW_TL_TOTALS = ['tl_p1_est_damage','tl_p2_est_damage','tl_p1_moves','tl_p2_moves']\n",
    "STATUS_DIFF_COLS = [c for c in train_df.columns if c.startswith('tl_inflicted_') and c.endswith('_diff')]\n",
    "HIGH_VAR_TL = ['damage_diff', 'tl_first2_damage_diff']  # preserva endurance e weighted diff (cruciali)\n",
    "drop_now = [c for c in RAW_TL_TOTALS if c in FEATURES] + [c for c in STATUS_DIFF_COLS if c in FEATURES] + [c for c in HIGH_VAR_TL if c in FEATURES]\n",
    "FEATURES = [c for c in FEATURES if c not in set(drop_now)]\n",
    "\n",
    "print(f'Feature numeriche (pre-stability): {len(FEATURES)}')\n",
    "\n",
    "# === Stability filter (5-fold SMD) ===\n",
    "STABILITY_THRESHOLD = 0.055\n",
    "STABILITY_PROTECT = WHITELIST_KEEP | {'damage_per_turn_diff'}\n",
    "y_all = train_df['player_won'].values.astype(int)\n",
    "skf_stab = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "smd_cache = {f: [] for f in FEATURES}\n",
    "for tr_idx, va_idx in skf_stab.split(train_df[FEATURES], y_all):\n",
    "    tr_df = train_df.iloc[tr_idx][FEATURES].astype(float)\n",
    "    va_df = train_df.iloc[va_idx][FEATURES].astype(float)\n",
    "    std_tr = tr_df.std(ddof=1) + 1e-9\n",
    "    smd = (va_df.mean() - tr_df.mean()) / std_tr\n",
    "    for f, v in smd.items():\n",
    "        smd_cache[f].append(abs(float(v)))\n",
    "mean_smd = {f: (np.mean(vals) if len(vals) else 0.0) for f, vals in smd_cache.items()}\n",
    "DRIFT_HARD_DROP = sorted([f for f, v in mean_smd.items() if v >= 0.09])\n",
    "if DRIFT_HARD_DROP:\n",
    "    FEATURES = [f for f in FEATURES if f not in set(DRIFT_HARD_DROP)]\n",
    "    print(f'Drift hard drop ({len(DRIFT_HARD_DROP)}): {DRIFT_HARD_DROP[:6]}')\n",
    "\n",
    "# === Stability filter: rimuovi feature instabili (alta varianza tra fold) ===\n",
    "unstable_feats = sorted([f for f, v in mean_smd.items() if (v > STABILITY_THRESHOLD and f not in STABILITY_PROTECT)])\n",
    "if unstable_feats:\n",
    "    FEATURES = [f for f in FEATURES if f not in set(unstable_feats)]\n",
    "    print(f'Stability filter: rimosse {len(unstable_feats)} colonne sopra {STABILITY_THRESHOLD:.3f}. Esempio: {unstable_feats[:6]}')\n",
    "else:\n",
    "    print('Stability filter: nessuna feature rimossa.')\n",
    "\n",
    "print(f'Feature numeriche finali: {len(FEATURES)}')\n",
    "print(f'Colonne escluse (stringhe): {len(string_cols)}')\n",
    "if DROP_NEW_TIMELINE_FEATURES:\n",
    "    kept = set(late_new_static) | set(rate_cols)\n",
    "    dropped = [c for c in LATE_GAME_NEW_FEATURES if (c in train_df.columns and c not in WHITELIST_KEEP)]\n",
    "    print(f\"Late-game features rimosse (al netto whitelist): {len(dropped)}\")\n",
    "    print(f\"Whitelist preservate: {[c for c in WHITELIST_KEEP if c in train_df.columns]}\")\n",
    "if drop_now:\n",
    "    print(f\"Drop extra (totali timeline e status diff): {len(drop_now)} -> esempi: {drop_now[:6]}\")\n",
    "\n",
    "X = train_df[FEATURES].values\n",
    "y = y_all\n",
    "\n",
    "# Split holdout test dal train (20%)\n",
    "X_train_val, X_holdout, y_train_val, y_holdout, idx_train_val, idx_holdout = train_test_split(\n",
    "    X, y, train_df.index.values, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('train_val size:', X_train_val.shape[0], 'holdout size:', X_holdout.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38364108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time-boxed GridSearchCV (<= ~2 ore) ===\n",
      "scale_pos_weight auto≈1.00 -> grid=[1.0, 1.25]\n",
      "Warmup per stimare t_fit...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     43\u001b[39m t0 = time.time()\n\u001b[32m     44\u001b[39m gs_warm = GridSearchCV(\n\u001b[32m     45\u001b[39m     base_clf,\n\u001b[32m     46\u001b[39m     param_grid=[{k:[v] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m d.items()} \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m warm_params],\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     refit=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     52\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mgs_warm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m elapsed_warm = time.time() - t0\n\u001b[32m     55\u001b[39m fits_warm = \u001b[38;5;28mlen\u001b[39m(warm_params) * cv_inner.get_n_splits()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Grid Search time-boxed (<= ~2 ore) ===\n",
    "print(\"=== Time-boxed GridSearchCV (<= ~2 ore) ===\")\n",
    "import time, os\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "try:\n",
    "    import joblib\n",
    "    CPU_COUNT = joblib.cpu_count()\n",
    "except Exception:\n",
    "    CPU_COUNT = os.cpu_count() or 4\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Base estimator\n",
    "base_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=1, tree_method='hist')\n",
    "\n",
    "# Calcola uno scale_pos_weight automatico e cerca attorno ad esso\n",
    "pos_rate = float(y_train_val.mean())\n",
    "spw_auto = float((1.0 - pos_rate) / max(pos_rate, 1e-9))\n",
    "spw_grid = sorted({1.0, max(1.0, spw_auto*0.75), max(1.0, spw_auto), max(1.0, spw_auto*1.25)})\n",
    "print(f'scale_pos_weight auto≈{spw_auto:.2f} -> grid={spw_grid}')\n",
    "\n",
    "# Griglia COARSE (regolarizzata) — include scale_pos_weight\n",
    "grid_coarse = {\n",
    "    'n_estimators':      [300, 500, 700],\n",
    "    'max_depth':         [3, 4],\n",
    "    'min_child_weight':  [3, 5, 7],\n",
    "    'learning_rate':     [0.03, 0.05, 0.07],\n",
    "    'subsample':         [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree':  [0.7, 0.8, 0.9],\n",
    "    'gamma':             [0.1, 0.2, 0.3],\n",
    "    'reg_alpha':         [0.05, 0.1, 0.2],\n",
    "    'reg_lambda':        [2.0, 3.0, 4.0],\n",
    "    'scale_pos_weight':  spw_grid\n",
    "}\n",
    "\n",
    "# Stima tempo per-fit (warmup) — CORRETTO param_grid\n",
    "warm_params = [\n",
    "    {'n_estimators': 500, 'max_depth': 3, 'min_child_weight': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'reg_lambda': 3.0, 'scale_pos_weight': max(1.0, spw_auto)},\n",
    "    {'n_estimators': 700, 'max_depth': 4, 'min_child_weight': 5, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'reg_lambda': 3.0, 'scale_pos_weight': max(1.0, spw_auto*1.25)}\n",
    "]\n",
    "print(\"Warmup per stimare t_fit...\")\n",
    "t0 = time.time()\n",
    "gs_warm = GridSearchCV(\n",
    "    base_clf,\n",
    "    param_grid=[{k:[v] for k,v in d.items()} for d in warm_params],\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv_inner,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=False\n",
    ")\n",
    "gs_warm.fit(X_train_val, y_train_val)\n",
    "elapsed_warm = time.time() - t0\n",
    "fits_warm = len(warm_params) * cv_inner.get_n_splits()\n",
    "t_fit_per_fold = max(0.01, elapsed_warm / fits_warm)\n",
    "print(f\"Warmup: {elapsed_warm:.2f}s per {fits_warm} fit -> ~{t_fit_per_fold:.3f}s/fit\")\n",
    "\n",
    "# Budget totale ~2 ore con margine sicurezza\n",
    "TARGET_SECONDS = int(2*3600*0.9)\n",
    "speedup = max(1, min(CPU_COUNT, cv_inner.get_n_splits()))\n",
    "max_combos = int((TARGET_SECONDS * speedup) / (t_fit_per_fold * cv_inner.get_n_splits()))\n",
    "max_combos = int(max(48, min(max_combos, 2000)))\n",
    "print(f\"CPU={CPU_COUNT}, speedup~{speedup}, max_combos≈{max_combos}\")\n",
    "\n",
    "# Costruisci tutte le combinazioni e campiona fino a max_combos\n",
    "all_points = list(ParameterGrid(grid_coarse))\n",
    "total = len(all_points)\n",
    "print(f\"Candidate totali nella griglia: {total}\")\n",
    "rng = np.random.default_rng(42)\n",
    "if total > max_combos:\n",
    "    idx = rng.choice(total, size=max_combos, replace=False)\n",
    "    sampled = [all_points[i] for i in idx]\n",
    "else:\n",
    "    sampled = all_points\n",
    "print(f\"Config selezionate: {len(sampled)}\")\n",
    "\n",
    "# Converte in lista di 'micro-grid' (1 punto ciascuno) — CORRETTO\n",
    "param_grid_list = [{k:[v] for k,v in pt.items()} for pt in sampled]\n",
    "\n",
    "print(\"Esecuzione GridSearch time-boxed...\")\n",
    "t1 = time.time()\n",
    "gs = GridSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_grid=param_grid_list,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv_inner,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "gs.fit(X_train_val, y_train_val)\n",
    "elapsed = time.time() - t1\n",
    "\n",
    "results_df = pd.DataFrame(gs.cv_results_).sort_values('rank_test_score')\n",
    "csv_path = 'hp_search_results_timeboxed_grid.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "best_params = gs.best_params_\n",
    "\n",
    "print(f\"\\n✅ Salvato {csv_path} ({len(results_df)} righe)\")\n",
    "print(\"Migliori iperparametri:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"Best CV (balanced_accuracy): {gs.best_score_:.4f}\")\n",
    "print(f\"Tempo GridSearch: {elapsed/60:.1f} min (budget ~{TARGET_SECONDS/60:.0f} min)\")\n",
    "print(\"Ora puoi usare 'best_params' nelle celle successive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab0d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10-Fold Cross-Validation (9 train + 1 validation) ===\n",
      "Parametri utilizzati: {'booster': 'gbtree', 'learning_rate': 0.03, 'n_estimators': 1250, 'max_depth': 3, 'min_child_weight': 8, 'gamma': 0.6, 'subsample': 0.6, 'colsample_bytree': 0.6, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.6, 'reg_alpha': 0.4, 'reg_lambda': 8.5, 'max_delta_step': 1, 'scale_pos_weight': 1.0}\n",
      "\n",
      "Fold 1: no ES, train=7200, val=800, acc_val=80.50%, acc_val_opt=81.62% @thr=0.542, acc_train=86.97%, gap=6.47%\n",
      "Fold 2: no ES, train=7200, val=800, acc_val=81.38%, acc_val_opt=82.25% @thr=0.453, acc_train=87.06%, gap=5.68%\n",
      "Fold 3: no ES, train=7200, val=800, acc_val=81.62%, acc_val_opt=82.38% @thr=0.436, acc_train=86.86%, gap=5.24%\n",
      "Fold 4: no ES, train=7200, val=800, acc_val=84.38%, acc_val_opt=84.88% @thr=0.494, acc_train=86.44%, gap=2.07%\n",
      "Fold 5: no ES, train=7200, val=800, acc_val=82.38%, acc_val_opt=83.12% @thr=0.539, acc_train=86.60%, gap=4.22%\n",
      "Fold 6: no ES, train=7200, val=800, acc_val=80.62%, acc_val_opt=81.62% @thr=0.459, acc_train=87.29%, gap=6.67%\n",
      "Fold 7: no ES, train=7200, val=800, acc_val=83.12%, acc_val_opt=83.88% @thr=0.470, acc_train=86.74%, gap=3.61%\n",
      "Fold 8: no ES, train=7200, val=800, acc_val=82.75%, acc_val_opt=83.12% @thr=0.487, acc_train=86.89%, gap=4.14%\n",
      "Fold 9: no ES, train=7200, val=800, acc_val=82.75%, acc_val_opt=82.88% @thr=0.469, acc_train=86.85%, gap=4.10%\n",
      "Fold 10: no ES, train=7200, val=800, acc_val=80.62%, acc_val_opt=80.88% @thr=0.496, acc_train=86.76%, gap=6.14%\n",
      "\n",
      "============================================================\n",
      "Risultati Cross-Validation\n",
      "============================================================\n",
      "  Fold 1: val_acc=80.50%, val_acc_opt=81.62% @thr=0.542, train_acc=86.97%, gap=6.47%\n",
      "  Fold 2: val_acc=81.38%, val_acc_opt=82.25% @thr=0.453, train_acc=87.06%, gap=5.68%\n",
      "  Fold 3: val_acc=81.62%, val_acc_opt=82.38% @thr=0.436, train_acc=86.86%, gap=5.24%\n",
      "  Fold 4: val_acc=84.38%, val_acc_opt=84.88% @thr=0.494, train_acc=86.44%, gap=2.07%\n",
      "  Fold 5: val_acc=82.38%, val_acc_opt=83.12% @thr=0.539, train_acc=86.60%, gap=4.22%\n",
      "  Fold 6: val_acc=80.62%, val_acc_opt=81.62% @thr=0.459, train_acc=87.29%, gap=6.67%\n",
      "  Fold 7: val_acc=83.12%, val_acc_opt=83.88% @thr=0.470, train_acc=86.74%, gap=3.61%\n",
      "  Fold 8: val_acc=82.75%, val_acc_opt=83.12% @thr=0.487, train_acc=86.89%, gap=4.14%\n",
      "  Fold 9: val_acc=82.75%, val_acc_opt=82.88% @thr=0.469, train_acc=86.85%, gap=4.10%\n",
      "  Fold 10: val_acc=80.62%, val_acc_opt=80.88% @thr=0.496, train_acc=86.76%, gap=6.14%\n",
      "\n",
      "Mean CV accuracy (0.5): 82.01%\n",
      "Mean CV accuracy (opt thr): 82.66%\n",
      "Mean train accuracy: 86.85%\n",
      "Mean gap (train - val): 4.83%\n",
      "Std CV accuracy:  1.21%\n",
      "Min/Max val acc:  80.50% / 84.38%\n",
      "\n",
      "Peggiore fold: #1 con acc_val=80.50% | acc_val_opt=81.62% | acc_train=86.97% | gap=6.47%\n"
     ]
    }
   ],
   "source": [
    "# === 10-Fold Cross-Validation con iperparametri FISSI ===\n",
    "# IMPORTANTE: Assegna qui i migliori iperparametri trovati dalla cella precedente\n",
    "# Oppure lascia questi di default (conservativi per ridurre overfitting)\n",
    "\n",
    "best_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'learning_rate': 0.03,\n",
    "    'n_estimators': 1250,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 8,\n",
    "    'gamma': 0.6,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'colsample_bynode': 0.6,\n",
    "    'colsample_bylevel': 0.6,\n",
    "    'reg_alpha': 0.4,\n",
    "    'reg_lambda': 8.5,\n",
    "    'max_delta_step': 1,\n",
    "    'scale_pos_weight': 1.0\n",
    "}\n",
    "\n",
    "print(\"=== 10-Fold Cross-Validation (9 train + 1 validation) ===\")\n",
    "print(f\"Parametri utilizzati: {best_params}\\n\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb  # per callback EarlyStopping se disponibile\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_accuracies = []\n",
    "folds_info = []\n",
    "train_accuracies = []\n",
    "train_val_gaps = []\n",
    "outer_accuracies_opt = []\n",
    "\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "AUTO_BALANCE_POS_WEIGHT = True\n",
    "if AUTO_BALANCE_POS_WEIGHT:\n",
    "    pos_rate = float(y_train_val.mean())\n",
    "    spw = (1.0 - pos_rate) / (pos_rate + 1e-9)\n",
    "    if spw > 1.0:\n",
    "        best_params = dict(best_params)\n",
    "        best_params['scale_pos_weight'] = float(min(max(spw, 1.0), 10.0))\n",
    "        print(f\"Auto scale_pos_weight: {best_params['scale_pos_weight']:.3f}\")\n",
    "\n",
    "def best_threshold_for_accuracy(y_true, proba, n_grid=201):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    proba = np.asarray(proba).astype(float)\n",
    "    grid = np.unique(np.quantile(proba, np.linspace(0, 1, n_grid)))\n",
    "    best_thr, best_acc = 0.5, 0.0\n",
    "    for t in grid:\n",
    "        acc = ( ((proba >= t).astype(int) == y_true).mean() )\n",
    "        if (acc > best_acc) or (abs(acc - best_acc) < 1e-12 and abs(t - 0.5) < abs(best_thr - 0.5)):\n",
    "            best_acc, best_thr = float(acc), float(t)\n",
    "    return best_thr, best_acc\n",
    "\n",
    "def _fit_with_es(clf, X_tr, y_tr, X_val, y_val):\n",
    "    \"\"\"Fit con EarlyStopping via callback se supportato; fallback senza ES.\"\"\"\n",
    "    try:\n",
    "        cb = getattr(xgb.callback, 'EarlyStopping', None)\n",
    "        if cb is not None:\n",
    "            clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[cb(rounds=EARLY_STOPPING_ROUNDS, save_best=True, maximize=False)], verbose=False)\n",
    "            return True\n",
    "    except TypeError:\n",
    "        pass\n",
    "    clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    return False\n",
    "\n",
    "def _predict_proba_best(clf, X, best_iter=None, best_ntree_limit=None):\n",
    "    \"\"\"Version-safe predict_proba using either iteration_range (new) or ntree_limit (old).\"\"\"\n",
    "    try:\n",
    "        if best_iter is not None:\n",
    "            return clf.predict_proba(X, iteration_range=(0, int(best_iter)+1))[:, 1]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    try:\n",
    "        if best_ntree_limit is not None:\n",
    "            return clf.predict_proba(X, ntree_limit=int(best_ntree_limit))[:, 1]\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return clf.predict_proba(X)[:, 1]\n",
    "\n",
    "fold_idx = 0\n",
    "for train_idx, val_idx in skf.split(X_train_val, y_train_val):\n",
    "    fold_idx += 1\n",
    "    X_tr, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_tr, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "    clf = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    used_es = _fit_with_es(clf, X_tr, y_tr, X_val, y_val)\n",
    "\n",
    "    best_iter = getattr(clf, 'best_iteration', None)\n",
    "    try:\n",
    "        booster = clf.get_booster()\n",
    "    except Exception:\n",
    "        booster = None\n",
    "    best_ntree_limit = getattr(booster, 'best_ntree_limit', None) if booster is not None else None\n",
    "\n",
    "    y_val_proba = _predict_proba_best(clf, X_val, best_iter, best_ntree_limit)\n",
    "    y_pred = (y_val_proba >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    outer_accuracies.append(acc)\n",
    "\n",
    "    y_tr_proba = _predict_proba_best(clf, X_tr, best_iter, best_ntree_limit)\n",
    "    y_tr_pred = (y_tr_proba >= 0.5).astype(int)\n",
    "    tr_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "    gap = float(tr_acc - acc)\n",
    "    train_accuracies.append(tr_acc)\n",
    "    train_val_gaps.append(gap)\n",
    "\n",
    "    thr_acc, acc_opt = best_threshold_for_accuracy(y_val, y_val_proba, n_grid=301)\n",
    "    outer_accuracies_opt.append(acc_opt)\n",
    "\n",
    "    val_index_global = idx_train_val[val_idx]\n",
    "    train_index_global = idx_train_val[train_idx]\n",
    "\n",
    "    folds_info.append({\n",
    "        'fold': fold_idx,\n",
    "        'acc': float(acc),\n",
    "        'train_acc': float(tr_acc),\n",
    "        'gap_train_minus_val': float(gap),\n",
    "        'acc_opt': float(acc_opt),\n",
    "        'thr_acc': float(thr_acc),\n",
    "        'best_iteration': int(best_iter) if best_iter is not None else None,\n",
    "        'train_idx': train_idx,\n",
    "        'val_idx': val_idx,\n",
    "        'train_index_global': train_index_global,\n",
    "        'val_index_global': val_index_global,\n",
    "        'y_true': y_val.astype(int),\n",
    "        'y_pred': y_pred.astype(int),\n",
    "        'y_proba': y_val_proba.astype(float)\n",
    "    })\n",
    "\n",
    "    es_tag = 'with ES' if used_es else 'no ES'\n",
    "    print(f'Fold {fold_idx}: {es_tag}, train={len(y_tr)}, val={len(y_val)}, acc_val={acc*100:.2f}%, acc_val_opt={acc_opt*100:.2f}% @thr={thr_acc:.3f}, acc_train={tr_acc*100:.2f}%, gap={(gap)*100:.2f}%')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Risultati Cross-Validation')\n",
    "print('='*60)\n",
    "for i, a in enumerate(outer_accuracies, 1):\n",
    "    print(f'  Fold {i}: val_acc={a*100:.2f}%, val_acc_opt={outer_accuracies_opt[i-1]*100:.2f}% @thr={folds_info[i-1][\"thr_acc\"]:.3f}, train_acc={train_accuracies[i-1]*100:.2f}%, gap={train_val_gaps[i-1]*100:.2f}%')\n",
    "print(f'\\nMean CV accuracy (0.5): {np.mean(outer_accuracies)*100:.2f}%')\n",
    "print(f'Mean CV accuracy (opt thr): {np.mean(outer_accuracies_opt)*100:.2f}%')\n",
    "print(f'Mean train accuracy: {np.mean(train_accuracies)*100:.2f}%')\n",
    "print(f'Mean gap (train - val): {np.mean(train_val_gaps)*100:.2f}%')\n",
    "print(f'Std CV accuracy:  {np.std(outer_accuracies)*100:.2f}%')\n",
    "print(f'Min/Max val acc:  {np.min(outer_accuracies)*100:.2f}% / {np.max(outer_accuracies)*100:.2f}%')\n",
    "\n",
    "WORST_FOLD_IDX = int(np.argmin(outer_accuracies))\n",
    "WORST_FOLD_NUM = int(folds_info[WORST_FOLD_IDX]['fold'])\n",
    "print(f\"\\nPeggiore fold: #{WORST_FOLD_NUM} con acc_val={outer_accuracies[WORST_FOLD_IDX]*100:.2f}% | acc_val_opt={outer_accuracies_opt[WORST_FOLD_IDX]*100:.2f}% | acc_train={train_accuracies[WORST_FOLD_IDX]*100:.2f}% | gap={train_val_gaps[WORST_FOLD_IDX]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b87173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission rapida post-CV ===\n",
      "✅ File di submission salvato in submission.csv\n",
      "   battle_id  player_won\n",
      "0          0           0\n",
      "1          1           1\n",
      "2          2           1\n",
      "3          3           1\n",
      "4          4           1\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Submission rapida post-CV ===\")\n",
    "cv_submission_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "cv_submission_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "test_aligned = test_df.reindex(columns=FEATURES, fill_value=0)\n",
    "X_test_matrix = test_aligned.astype(float).to_numpy()\n",
    "test_predictions = cv_submission_model.predict(X_test_matrix).astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': test_predictions.astype(np.int64)\n",
    "})\n",
    "\n",
    "submission_path = 'submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"✅ File di submission salvato in {submission_path}\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a65edd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analisi Fold peggiore #10 ===\n",
      "Pos rate overall: 0.500 | train: 0.500 | val: 0.500\n",
      "Confusion Matrix (val fold):\n",
      " [[324  76]\n",
      " [ 80 320]]\n",
      "\n",
      "Classification report (val fold):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8020    0.8100    0.8060       400\n",
      "           1     0.8081    0.8000    0.8040       400\n",
      "\n",
      "    accuracy                         0.8050       800\n",
      "   macro avg     0.8050    0.8050    0.8050       800\n",
      "weighted avg     0.8050    0.8050    0.8050       800\n",
      "\n",
      "Errori nel fold: 156 su 800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_global</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>proba_win</th>\n",
       "      <th>margin</th>\n",
       "      <th>battle_id</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962260</td>\n",
       "      <td>0.462260</td>\n",
       "      <td>8714</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958642</td>\n",
       "      <td>0.458642</td>\n",
       "      <td>8179</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>3027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049702</td>\n",
       "      <td>0.450298</td>\n",
       "      <td>3027</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3751</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053464</td>\n",
       "      <td>0.446536</td>\n",
       "      <td>3751</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057462</td>\n",
       "      <td>0.442538</td>\n",
       "      <td>3927</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8567</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942072</td>\n",
       "      <td>0.442072</td>\n",
       "      <td>8567</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>4883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>0.439484</td>\n",
       "      <td>4883</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>775</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061714</td>\n",
       "      <td>0.438286</td>\n",
       "      <td>775</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>0.433723</td>\n",
       "      <td>2316</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>9917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931143</td>\n",
       "      <td>0.431143</td>\n",
       "      <td>9917</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8364</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923392</td>\n",
       "      <td>0.423392</td>\n",
       "      <td>8364</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079593</td>\n",
       "      <td>0.420407</td>\n",
       "      <td>853</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916818</td>\n",
       "      <td>0.416818</td>\n",
       "      <td>9944</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084371</td>\n",
       "      <td>0.415629</td>\n",
       "      <td>1405</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>9890</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911276</td>\n",
       "      <td>0.411276</td>\n",
       "      <td>9890</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.408308</td>\n",
       "      <td>2071</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>8249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907525</td>\n",
       "      <td>0.407525</td>\n",
       "      <td>8249</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>5020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906646</td>\n",
       "      <td>0.406646</td>\n",
       "      <td>5020</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>7941</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902391</td>\n",
       "      <td>0.402391</td>\n",
       "      <td>7941</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108476</td>\n",
       "      <td>0.391524</td>\n",
       "      <td>1577</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index_global  y_true  y_pred  proba_win    margin  battle_id error_type\n",
       "260          8714       0       1   0.962260  0.462260       8714         FP\n",
       "151          8179       0       1   0.958642  0.458642       8179         FP\n",
       "746          3027       1       0   0.049702  0.450298       3027         FN\n",
       "174          3751       1       0   0.053464  0.446536       3751         FN\n",
       "687          3927       1       0   0.057462  0.442538       3927         FN\n",
       "37           8567       0       1   0.942072  0.442072       8567         FP\n",
       "635          4883       1       0   0.060516  0.439484       4883         FN\n",
       "623           775       1       0   0.061714  0.438286        775         FN\n",
       "574          2316       1       0   0.066277  0.433723       2316         FN\n",
       "655          9917       0       1   0.931143  0.431143       9917         FP\n",
       "424          8364       0       1   0.923392  0.423392       8364         FP\n",
       "210           853       1       0   0.079593  0.420407        853         FN\n",
       "191          9944       0       1   0.916818  0.416818       9944         FP\n",
       "304          1405       1       0   0.084371  0.415629       1405         FN\n",
       "751          9890       0       1   0.911276  0.411276       9890         FP\n",
       "430          2071       1       0   0.091692  0.408308       2071         FN\n",
       "238          8249       0       1   0.907525  0.407525       8249         FP\n",
       "728          5020       0       1   0.906646  0.406646       5020         FP\n",
       "450          7941       0       1   0.902391  0.402391       7941         FP\n",
       "141          1577       1       0   0.108476  0.391524       1577         FN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Salvato cv_worst_fold_errors.csv\n",
      "\n",
      "Top 15 feature con maggior shift (|Δmean|/std_train):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>abs_std_mean_diff</th>\n",
       "      <th>mean_val</th>\n",
       "      <th>mean_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1_spe_p25</td>\n",
       "      <td>0.106932</td>\n",
       "      <td>51.912500</td>\n",
       "      <td>50.891319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2_lead_base_hp</td>\n",
       "      <td>0.083775</td>\n",
       "      <td>65.847500</td>\n",
       "      <td>68.352917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1_base_spe_sum</td>\n",
       "      <td>0.083259</td>\n",
       "      <td>458.293750</td>\n",
       "      <td>454.225694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1_base_spe_mean</td>\n",
       "      <td>0.083259</td>\n",
       "      <td>76.382292</td>\n",
       "      <td>75.704282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1_spe_p50</td>\n",
       "      <td>0.082487</td>\n",
       "      <td>75.525000</td>\n",
       "      <td>74.124306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p1_base_spe_std</td>\n",
       "      <td>0.080225</td>\n",
       "      <td>32.503840</td>\n",
       "      <td>32.763007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p1_type_ice_count</td>\n",
       "      <td>0.078566</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.514167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tl_p2_move_type_ghost_count</td>\n",
       "      <td>0.078509</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.227917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p1_base_spe_min</td>\n",
       "      <td>0.077357</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>31.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tl_p1_move_type_fighting_count</td>\n",
       "      <td>0.070302</td>\n",
       "      <td>1.127500</td>\n",
       "      <td>1.298611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p1_type_water_count</td>\n",
       "      <td>0.066740</td>\n",
       "      <td>0.773750</td>\n",
       "      <td>0.812361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tl_p1_move_type_grass_count</td>\n",
       "      <td>0.063715</td>\n",
       "      <td>1.185000</td>\n",
       "      <td>1.304583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>p1_base_spd_min</td>\n",
       "      <td>0.062966</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>58.803472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>p1_base_spa_min</td>\n",
       "      <td>0.062966</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>58.803472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p1_type_flying_count</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.346111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  abs_std_mean_diff    mean_val  mean_train\n",
       "0                       p1_spe_p25           0.106932   51.912500   50.891319\n",
       "1                  p2_lead_base_hp           0.083775   65.847500   68.352917\n",
       "2                  p1_base_spe_sum           0.083259  458.293750  454.225694\n",
       "3                 p1_base_spe_mean           0.083259   76.382292   75.704282\n",
       "4                       p1_spe_p50           0.082487   75.525000   74.124306\n",
       "5                  p1_base_spe_std           0.080225   32.503840   32.763007\n",
       "6                p1_type_ice_count           0.078566    0.562500    0.514167\n",
       "7      tl_p2_move_type_ghost_count           0.078509    0.302500    0.227917\n",
       "8                  p1_base_spe_min           0.077357   32.400000   31.972222\n",
       "9   tl_p1_move_type_fighting_count           0.070302    1.127500    1.298611\n",
       "10             p1_type_water_count           0.066740    0.773750    0.812361\n",
       "11     tl_p1_move_type_grass_count           0.063715    1.185000    1.304583\n",
       "12                 p1_base_spd_min           0.062966   59.375000   58.803472\n",
       "13                 p1_base_spa_min           0.062966   59.375000   58.803472\n",
       "14            p1_type_flying_count           0.062338    0.378750    0.346111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Salvato cv_worst_fold_feature_shift.csv\n",
      "\n",
      "Top 20 feature importances (clf_worst):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tl_weighted_damage_diff</td>\n",
       "      <td>0.078942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tl_p1_defensive_endurance</td>\n",
       "      <td>0.074173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tl_p2_inflicted_frz_count</td>\n",
       "      <td>0.029711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tl_p1_inflicted_slp_count</td>\n",
       "      <td>0.026844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tl_p1_inflicted_frz_count</td>\n",
       "      <td>0.022014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tl_p1_inflicted_par_count</td>\n",
       "      <td>0.020547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tl_p2_inflicted_slp_count</td>\n",
       "      <td>0.018085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tl_last5_damage_diff</td>\n",
       "      <td>0.016894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tl_p1_move_type_poison_count</td>\n",
       "      <td>0.015723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>damage_per_turn_diff</td>\n",
       "      <td>0.014919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tl_p2_inflicted_par_count</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>p2_lead_type_psychic</td>\n",
       "      <td>0.013317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tl_p1_move_type_fire_count</td>\n",
       "      <td>0.012223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tl_p2_last_hp</td>\n",
       "      <td>0.010335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tl_move_type_fighting_count_diff</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>lead_speed_advantage</td>\n",
       "      <td>0.009419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tl_p2_damage_vs_p1_hp_pool</td>\n",
       "      <td>0.009257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1_base_hp_max</td>\n",
       "      <td>0.008923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>p2_lead_type_water</td>\n",
       "      <td>0.008915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tl_move_type_psychic_count_diff</td>\n",
       "      <td>0.008811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance\n",
       "168           tl_weighted_damage_diff    0.078942\n",
       "101         tl_p1_defensive_endurance    0.074173\n",
       "112         tl_p2_inflicted_frz_count    0.029711\n",
       "109         tl_p1_inflicted_slp_count    0.026844\n",
       "111         tl_p1_inflicted_frz_count    0.022014\n",
       "107         tl_p1_inflicted_par_count    0.020547\n",
       "110         tl_p2_inflicted_slp_count    0.018085\n",
       "164              tl_last5_damage_diff    0.016894\n",
       "156      tl_p1_move_type_poison_count    0.015723\n",
       "175              damage_per_turn_diff    0.014919\n",
       "108         tl_p2_inflicted_par_count    0.014593\n",
       "61               p2_lead_type_psychic    0.013317\n",
       "120        tl_p1_move_type_fire_count    0.012223\n",
       "99                      tl_p2_last_hp    0.010335\n",
       "161  tl_move_type_fighting_count_diff    0.009800\n",
       "84               lead_speed_advantage    0.009419\n",
       "100        tl_p2_damage_vs_p1_hp_pool    0.009257\n",
       "2                      p1_base_hp_max    0.008923\n",
       "58                 p2_lead_type_water    0.008915\n",
       "134   tl_move_type_psychic_count_diff    0.008811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Salvato cv_worst_fold_feature_importances.csv\n",
      "\n",
      "Suggerimenti di lettura:\n",
      "- Controlla se il fold ha class balance diverso (pos_rate) -> possibile causa di drop.\n",
      "- Esamina cv_worst_fold_errors.csv per vedere FP/FN e margini.\n",
      "- Controlla le feature con forte shift (cv_worst_fold_feature_shift.csv).\n",
      "- Confronta le top importances con le feature shiftate: possibile covariate shift.\n"
     ]
    }
   ],
   "source": [
    "# === Diagnostica del fold peggiore: class balance, errori, feature shift, importances ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "wf = folds_info[WORST_FOLD_IDX]\n",
    "fold_num = wf['fold']\n",
    "y_true = wf['y_true']\n",
    "y_pred = wf['y_pred']\n",
    "y_proba = wf['y_proba']\n",
    "val_idx = wf['val_idx']\n",
    "tr_idx = wf['train_idx']\n",
    "val_index_global = wf['val_index_global']\n",
    "train_index_global = wf['train_index_global']\n",
    "\n",
    "print(f\"=== Analisi Fold peggiore #{fold_num} ===\")\n",
    "\n",
    "# 1) Class balance\n",
    "overall_pos = float(y_train_val.mean())\n",
    "train_pos = float(y_train_val[tr_idx].mean())\n",
    "val_pos = float(y_train_val[val_idx].mean())\n",
    "print(f\"Pos rate overall: {overall_pos:.3f} | train: {train_pos:.3f} | val: {val_pos:.3f}\")\n",
    "\n",
    "# 2) Confusion matrix e report\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix (val fold):\\n\", cm)\n",
    "print(\"\\nClassification report (val fold):\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# 3) Error table con battle_id (se disponibile) e margine dalla soglia\n",
    "THR_CV = 0.5\n",
    "errors_mask = (y_true != y_pred)\n",
    "errors_df = pd.DataFrame({\n",
    "    'index_global': val_index_global,\n",
    "    'y_true': y_true,\n",
    "    'y_pred': y_pred,\n",
    "    'proba_win': y_proba,\n",
    "    'margin': np.abs(y_proba - THR_CV)\n",
    "})\n",
    "if 'battle_id' in train_df.columns:\n",
    "    errors_df['battle_id'] = train_df.loc[errors_df['index_global'], 'battle_id'].values\n",
    "errors_df['error_type'] = np.where((errors_df['y_true']==0)&(errors_df['y_pred']==1), 'FP', np.where((errors_df['y_true']==1)&(errors_df['y_pred']==0), 'FN', 'OK'))\n",
    "errors_only = errors_df[errors_mask].sort_values('margin', ascending=False)\n",
    "print(f\"Errori nel fold: {len(errors_only)} su {len(y_true)}\")\n",
    "display(errors_only.head(20))\n",
    "errors_only.to_csv('cv_worst_fold_errors.csv', index=False)\n",
    "print(\"✅ Salvato cv_worst_fold_errors.csv\")\n",
    "\n",
    "# 4) Feature shift train vs val (mean/std diff) per questo fold\n",
    "val_feats = pd.DataFrame(X_train_val[val_idx], columns=FEATURES)\n",
    "trn_feats = pd.DataFrame(X_train_val[tr_idx], columns=FEATURES)\n",
    "mean_diff = val_feats.mean() - trn_feats.mean()\n",
    "std_train = trn_feats.std(ddof=1) + 1e-9\n",
    "smd = (mean_diff / std_train).abs().sort_values(ascending=False)  # standardized mean diff\n",
    "shift_df = pd.DataFrame({\n",
    "    'feature': smd.index,\n",
    "    'abs_std_mean_diff': smd.values,\n",
    "    'mean_val': val_feats.mean().loc[smd.index].values,\n",
    "    'mean_train': trn_feats.mean().loc[smd.index].values\n",
    "})\n",
    "print(\"\\nTop 15 feature con maggior shift (|Δmean|/std_train):\")\n",
    "display(shift_df.head(15))\n",
    "shift_df.to_csv('cv_worst_fold_feature_shift.csv', index=False)\n",
    "print(\"✅ Salvato cv_worst_fold_feature_shift.csv\")\n",
    "\n",
    "# 5) Feature importances del modello ritrainato su questo fold\n",
    "clf_worst = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "clf_worst.fit(X_train_val[tr_idx], y_train_val[tr_idx], verbose=False)\n",
    "imp = getattr(clf_worst, 'feature_importances_', None)\n",
    "if imp is not None and len(imp)==len(FEATURES):\n",
    "    imp_df = pd.DataFrame({'feature': FEATURES, 'importance': imp}).sort_values('importance', ascending=False)\n",
    "    print(\"\\nTop 20 feature importances (clf_worst):\")\n",
    "    display(imp_df.head(20))\n",
    "    imp_df.to_csv('cv_worst_fold_feature_importances.csv', index=False)\n",
    "    print(\"✅ Salvato cv_worst_fold_feature_importances.csv\")\n",
    "else:\n",
    "    print(\"Feature importances non disponibili per questo stimatore.\")\n",
    "\n",
    "print(\"\\nSuggerimenti di lettura:\")\n",
    "print(\"- Controlla se il fold ha class balance diverso (pos_rate) -> possibile causa di drop.\")\n",
    "print(\"- Esamina cv_worst_fold_errors.csv per vedere FP/FN e margini.\")\n",
    "print(\"- Controlla le feature con forte shift (cv_worst_fold_feature_shift.csv).\")\n",
    "print(\"- Confronta le top importances con le feature shiftate: possibile covariate shift.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f8ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training finale su train_val completo ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Esegui prima la cella di stacking per definire STACKING_INFO.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mSTACKING_INFO\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'STACKING_INFO' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m     STACKING_INFO\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEsegui prima la cella di stacking per definire STACKING_INFO.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m ridge_model = STACKING_INFO[\u001b[33m'\u001b[39m\u001b[33mridge_model_train\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     23\u001b[39m ridge_train_proba = ridge_model.predict_proba(X_train_val)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[31mRuntimeError\u001b[39m: Esegui prima la cella di stacking per definire STACKING_INFO."
     ]
    }
   ],
   "source": [
    "# Valutazione finale sul holdout set (no early stopping, usa best_params selezionati)\n",
    "print(\"=== Training finale su train_val completo ===\")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Abilita calibrazione delle probabilità\n",
    "USE_CALIBRATION = True\n",
    "CALIB_METHOD = 'isotonic' if X_train_val.shape[0] >= 5000 else 'sigmoid'\n",
    "\n",
    "# Modello base + wrapper calibrato (CV interna per evitare bias)\n",
    "base_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "final_model = CalibratedClassifierCV(base_model, method=CALIB_METHOD, cv=5) if USE_CALIBRATION else base_model\n",
    "final_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "xgb_train_proba = final_model.predict_proba(X_train_val)[:, 1]\n",
    "xgb_hold_proba = final_model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "try:\n",
    "    STACKING_INFO\n",
    "except NameError:\n",
    "    raise RuntimeError('Esegui prima la cella di stacking per definire STACKING_INFO.')\n",
    "ridge_model = STACKING_INFO['ridge_model_train']\n",
    "ridge_train_proba = ridge_model.predict_proba(X_train_val)[:, 1]\n",
    "ridge_hold_proba = ridge_model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "train_stack = np.column_stack([xgb_train_proba, ridge_train_proba, np.abs(xgb_train_proba - ridge_train_proba)])\n",
    "hold_stack = np.column_stack([xgb_hold_proba, ridge_hold_proba, np.abs(xgb_hold_proba - ridge_hold_proba)])\n",
    "\n",
    "meta_model = STACKING_INFO['meta_model']\n",
    "TRAIN_PROBA_FOR_METRICS = meta_model.predict_proba(train_stack)[:, 1]\n",
    "HOLD_PROBA_FOR_METRICS = meta_model.predict_proba(hold_stack)[:, 1]\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_holdout, HOLD_PROBA_FOR_METRICS)\n",
    "j = tpr - fpr\n",
    "best_idx = int(np.nanargmax(j)) if len(j) > 0 else 0\n",
    "best_thr_roc = float(thr[best_idx]) if len(thr) > 0 else 0.5\n",
    "\n",
    "prec, rec, thr_pr = precision_recall_curve(y_holdout, HOLD_PROBA_FOR_METRICS)\n",
    "f1_series = (2 * prec * rec) / (prec + rec + 1e-9)\n",
    "best_idx_f1 = int(np.nanargmax(f1_series[1:])) if len(thr_pr) > 0 else 0\n",
    "best_thr_f1 = float(thr_pr[best_idx_f1]) if len(thr_pr) > 0 else best_thr_roc\n",
    "\n",
    "best_thr_acc, best_acc_acc = best_threshold_for_accuracy(y_holdout, HOLD_PROBA_FOR_METRICS, n_grid=1201)\n",
    "\n",
    "THRESHOLD_STRATEGY = 'accuracy'\n",
    "cand = {'youden': best_thr_roc, 'f1': best_thr_f1, 'accuracy': best_thr_acc}\n",
    "DECISION_THRESHOLD = float(np.clip(cand.get(THRESHOLD_STRATEGY, best_thr_acc), 0.05, 0.95))\n",
    "THR = DECISION_THRESHOLD\n",
    "\n",
    "base_acc = accuracy_score(y_holdout, (HOLD_PROBA_FOR_METRICS >= 0.5).astype(int))\n",
    "acc_roc = accuracy_score(y_holdout, (HOLD_PROBA_FOR_METRICS >= best_thr_roc).astype(int))\n",
    "acc_f1 = accuracy_score(y_holdout, (HOLD_PROBA_FOR_METRICS >= best_thr_f1).astype(int))\n",
    "acc_acc = accuracy_score(y_holdout, (HOLD_PROBA_FOR_METRICS >= best_thr_acc).astype(int))\n",
    "brier = brier_score_loss(y_holdout.astype(int), HOLD_PROBA_FOR_METRICS.astype(float))\n",
    "\n",
    "y_hold_pred = (HOLD_PROBA_FOR_METRICS >= THR).astype(int)\n",
    "hold_acc = accuracy_score(y_holdout, y_hold_pred)\n",
    "train_acc_final = accuracy_score(y_train_val, (TRAIN_PROBA_FOR_METRICS >= THR).astype(int))\n",
    "\n",
    "print(f\"Optimized thresholds -> ROC-Youden: {best_thr_roc:.3f} (acc={acc_roc*100:.2f}%) | F1-opt: {best_thr_f1:.3f} (acc={acc_f1*100:.2f}%) | Acc-opt: {best_thr_acc:.3f} (acc={acc_acc*100:.2f}%) | chosen: {THR:.3f}\")\n",
    "print(f'Baseline acc @0.5: {base_acc*100:.2f}% | Optimized acc @{THR:.3f}: {hold_acc*100:.2f}%')\n",
    "print(f'Calibration: method={CALIB_METHOD if USE_CALIBRATION else \"none\"} | Brier score={brier:.4f}')\n",
    "print(f'Gap finale (train - holdout) @{THR:.3f}: {(train_acc_final - hold_acc)*100:.2f}%')\n",
    "print(f'Parametri usati: {best_params}')\n",
    "\n",
    "y_hold_proba = HOLD_PROBA_FOR_METRICS\n",
    "y_hold_pred = (HOLD_PROBA_FOR_METRICS >= THR).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eac3e3",
   "metadata": {},
   "source": [
    "## Analisi errori di predizione (holdout)\n",
    "\n",
    "- Crea una tabella con predizioni errate sullo holdout\n",
    "- Evidenzia FP/FN, probabilità, margine dalla soglia\n",
    "- Salva su CSV e helper per ispezionare una partita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b41d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale holdout: 2000\n",
      "Errori totali: 352 | FP: 165 | FN: 187\n",
      "\n",
      "Top 20 errori più confidenti (lontani dalla soglia):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>proba_win</th>\n",
       "      <th>error_type</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>5992</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979384</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.479384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025429</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.474571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348</th>\n",
       "      <td>6348</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.472914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>8874</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971186</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.471186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>9202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.465157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>3617</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.463326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>7891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962728</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.462728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9592</th>\n",
       "      <td>9592</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.462175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>4567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043167</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.456833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1378</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046658</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.453342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050450</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.449550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>5616</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946645</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.446645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>5784</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946279</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.446279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>3553</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054910</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.445090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>3220</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056943</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.443057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>2841</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058077</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.441923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060143</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.439857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8342</th>\n",
       "      <td>8342</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.938309</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.438309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>3618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063197</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.436803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      battle_id  y_true  y_pred  proba_win error_type    margin\n",
       "5992       5992       0       1   0.979384         FP  0.479384\n",
       "1409       1409       1       0   0.025429         FN  0.474571\n",
       "6348       6348       0       1   0.972914         FP  0.472914\n",
       "8874       8874       0       1   0.971186         FP  0.471186\n",
       "9202       9202       0       1   0.965600         FP  0.465600\n",
       "1001       1001       1       0   0.034843         FN  0.465157\n",
       "3617       3617       1       0   0.036674         FN  0.463326\n",
       "7891       7891       0       1   0.962728         FP  0.462728\n",
       "9592       9592       0       1   0.962175         FP  0.462175\n",
       "4567       4567       1       0   0.043167         FN  0.456833\n",
       "1378       1378       1       0   0.046658         FN  0.453342\n",
       "1248       1248       1       0   0.050450         FN  0.449550\n",
       "5616       5616       0       1   0.946645         FP  0.446645\n",
       "5784       5784       0       1   0.946279         FP  0.446279\n",
       "3553       3553       1       0   0.054910         FN  0.445090\n",
       "3220       3220       1       0   0.056943         FN  0.443057\n",
       "2841       2841       1       0   0.058077         FN  0.441923\n",
       "1371       1371       1       0   0.060143         FN  0.439857\n",
       "8342       8342       0       1   0.938309         FP  0.438309\n",
       "3618       3618       1       0   0.063197         FN  0.436803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 errori borderline (vicini alla soglia):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>proba_win</th>\n",
       "      <th>error_type</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>7701</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508868</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.008868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>8054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510952</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.010952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>9949</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511908</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.011908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>2984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487583</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486674</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.013326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>6757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517144</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.017144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>3870</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.018413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>4239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480624</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.019376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>2240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479783</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.020217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>6944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520821</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.020821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>6217</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521706</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.021706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>3867</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476597</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.023403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>7219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524137</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.024137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>7294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524409</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.024409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>4427</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474476</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.025524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6759</th>\n",
       "      <td>6759</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527605</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.027605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>7675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528754</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.028754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>6865</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529917</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.029917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>9735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530013</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.030013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>2810</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469091</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.030909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      battle_id  y_true  y_pred  proba_win error_type    margin\n",
       "7701       7701       0       1   0.508868         FP  0.008868\n",
       "8054       8054       0       1   0.510952         FP  0.010952\n",
       "9949       9949       0       1   0.511908         FP  0.011908\n",
       "2984       2984       1       0   0.487583         FN  0.012417\n",
       "4561       4561       1       0   0.486674         FN  0.013326\n",
       "6757       6757       0       1   0.517144         FP  0.017144\n",
       "3870       3870       1       0   0.481587         FN  0.018413\n",
       "4239       4239       1       0   0.480624         FN  0.019376\n",
       "2240       2240       1       0   0.479783         FN  0.020217\n",
       "6944       6944       0       1   0.520821         FP  0.020821\n",
       "6217       6217       0       1   0.521706         FP  0.021706\n",
       "3867       3867       1       0   0.476597         FN  0.023403\n",
       "7219       7219       0       1   0.524137         FP  0.024137\n",
       "7294       7294       0       1   0.524409         FP  0.024409\n",
       "4427       4427       1       0   0.474476         FN  0.025524\n",
       "6759       6759       0       1   0.527605         FP  0.027605\n",
       "7675       7675       0       1   0.528754         FP  0.028754\n",
       "6865       6865       0       1   0.529917         FP  0.029917\n",
       "9735       9735       0       1   0.530013         FP  0.030013\n",
       "2810       2810       1       0   0.469091         FN  0.030909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Salvato 'errors_holdout.csv' con tutte le predizioni errate dello holdout\n",
      "\n",
      "Esempio ispezione prima partita con errore confidente:\n",
      "battle_id: 5992 | player_won: False\n",
      "p1 size: 6 | p2 size: 0\n",
      "p1 lead: alakazam ['notype', 'psychic'] lvl 100\n",
      "p2 lead: zapdos ['electric', 'flying'] lvl 100\n",
      "timeline turns (shown): 30\n",
      "{'turn': 1, 'p1_move': 'thunderwave', 'p2_move': None}\n",
      "{'turn': 2, 'p1_move': 'psychic', 'p2_move': None}\n"
     ]
    }
   ],
   "source": [
    "# Trova le partite sbagliate sullo holdout e ispezionale\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Probabilità e soglia (riusa se già calcolate)\n",
    "try:\n",
    "    proba = y_hold_proba\n",
    "except NameError:\n",
    "    proba = final_model.predict_proba(X_holdout)[:, 1]\n",
    "try:\n",
    "    THR = DECISION_THRESHOLD\n",
    "except NameError:\n",
    "    THR = 0.5\n",
    "\n",
    "# Costruisci DataFrame holdout con info utili\n",
    "holdout_idx = pd.Index(idx_holdout)\n",
    "holdout_meta = train_df.loc[holdout_idx, ['battle_id']].copy() if 'battle_id' in train_df.columns else pd.DataFrame(index=holdout_idx)\n",
    "holdout_df = pd.DataFrame({\n",
    "    'y_true': y_holdout.astype(int),\n",
    "    'y_pred': y_hold_pred.astype(int),\n",
    "    'proba_win': proba.astype(float),\n",
    "}, index=holdout_idx)\n",
    "holdout_df = holdout_meta.join(holdout_df)\n",
    "holdout_df['error'] = (holdout_df['y_true'] != holdout_df['y_pred']).astype(int)\n",
    "holdout_df['error_type'] = np.where(\n",
    "    (holdout_df['y_true'] == 0) & (holdout_df['y_pred'] == 1), 'FP',\n",
    "    np.where(holdout_df['y_true'] == 1, 'FN', 'OK')\n",
    ")\n",
    "\n",
    "# Salva errori su CSV\n",
    "errors_csv = 'holdout_errors.csv'\n",
    "holdout_df[holdout_df['error'] == 1].to_csv(errors_csv, index=False)\n",
    "print(f\"✅ Errori di predizione salvati in '{errors_csv}'\")\n",
    "\n",
    "# Esempio di ispezione di una partita con errori\n",
    "inspect_battle_id = None\n",
    "if inspect_battle_id is not None:\n",
    "    from IPython.display import display\n",
    "    battle_row = holdout_df[holdout_df['battle_id'] == inspect_battle_id]\n",
    "    if not battle_row.empty:\n",
    "        display(battle_row)\n",
    "    else:\n",
    "        print(f\"Nessuna partita trovata con battle_id={inspect_battle_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
