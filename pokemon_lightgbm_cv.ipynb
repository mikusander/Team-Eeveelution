{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e90af5",
   "metadata": {},
   "source": [
    "# PokÃ©mon battles â€” LightGBM with 10-fold CV\n",
    "Notebook che implementa LightGBM con: feature engineering completo, 10-fold CV, Optuna hyperparameter tuning, e submission finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52572bf2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99172c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati...\n",
      "Train records: 10000, Test records: 5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Percorsi ---\n",
    "train_file_path = 'train.jsonl'\n",
    "test_file_path = 'test.jsonl'\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "print('Caricamento dati...')\n",
    "train_raw = load_jsonl(train_file_path)\n",
    "test_raw = load_jsonl(test_file_path)\n",
    "print(f'Train records: {len(train_raw)}, Test records: {len(test_raw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f8a7b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b032f7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a00ef3f6396481f9671698fccbe2d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FE Complete:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab76ab48c554052841463b178f5f56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FE Complete:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape train/test: (10000, 296) (5000, 295)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "      <th>p1_base_hp_sum</th>\n",
       "      <th>p1_base_hp_mean</th>\n",
       "      <th>p1_base_hp_max</th>\n",
       "      <th>p1_base_hp_min</th>\n",
       "      <th>p1_base_hp_std</th>\n",
       "      <th>p1_base_atk_sum</th>\n",
       "      <th>p1_base_atk_mean</th>\n",
       "      <th>p1_base_atk_max</th>\n",
       "      <th>...</th>\n",
       "      <th>tl_info_advantage</th>\n",
       "      <th>tl_p2_avg_reveal_turn</th>\n",
       "      <th>tl_p1_immune_switches</th>\n",
       "      <th>tl_p2_forced_switches</th>\n",
       "      <th>tl_turns_with_hp_lead</th>\n",
       "      <th>tl_hp_diff_turn_10</th>\n",
       "      <th>tl_hp_diff_turn_20</th>\n",
       "      <th>tl_hp_diff_end</th>\n",
       "      <th>tl_heal_diff</th>\n",
       "      <th>tl_freeze_adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>115.833333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.367179</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.58891</td>\n",
       "      <td>-0.201018</td>\n",
       "      <td>0.279549</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.204534</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>124.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.382753</td>\n",
       "      <td>505.0</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65.362239</td>\n",
       "      <td>465.0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>685.0</td>\n",
       "      <td>114.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.794107</td>\n",
       "      <td>455.0</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.03000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won  p1_base_hp_sum  p1_base_hp_mean  p1_base_hp_max  \\\n",
       "0          0           1           695.0       115.833333           250.0   \n",
       "1          1           1           740.0       123.333333           250.0   \n",
       "2          2           1           745.0       124.166667           250.0   \n",
       "3          3           1           730.0       121.666667           250.0   \n",
       "4          4           1           685.0       114.166667           250.0   \n",
       "\n",
       "   p1_base_hp_min  p1_base_hp_std  p1_base_atk_sum  p1_base_atk_mean  \\\n",
       "0            55.0       69.367179            435.0         72.500000   \n",
       "1            65.0       64.204534            435.0         72.500000   \n",
       "2            60.0       64.382753            505.0         84.166667   \n",
       "3            60.0       65.362239            465.0         77.500000   \n",
       "4            50.0       70.794107            455.0         75.833333   \n",
       "\n",
       "   p1_base_atk_max  ...  tl_info_advantage  tl_p2_avg_reveal_turn  \\\n",
       "0            110.0  ...                  0               8.500000   \n",
       "1            110.0  ...                  0               9.666667   \n",
       "2            130.0  ...                  1               9.750000   \n",
       "3            110.0  ...                 -1               5.750000   \n",
       "4            110.0  ...                  0              15.200000   \n",
       "\n",
       "   tl_p1_immune_switches  tl_p2_forced_switches  tl_turns_with_hp_lead  \\\n",
       "0                      0                      3                     12   \n",
       "1                      0                      6                     15   \n",
       "2                      0                      2                     13   \n",
       "3                      0                      2                     10   \n",
       "4                      0                      5                     13   \n",
       "\n",
       "   tl_hp_diff_turn_10  tl_hp_diff_turn_20  tl_hp_diff_end  tl_heal_diff  \\\n",
       "0            -0.58891           -0.201018        0.279549             0   \n",
       "1             0.28000            0.600000       -0.320000             0   \n",
       "2             0.00000            0.240000       -0.240000            -1   \n",
       "3             0.13000            0.540000       -0.060000             2   \n",
       "4            -0.03000           -0.180000        0.320000            -1   \n",
       "\n",
       "   tl_freeze_adv  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 296 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. COSTANTI & FUNZIONI BASE\n",
    "# ==============================================================================\n",
    "\n",
    "TYPE_CHART = {\n",
    "    'normal': {'rock': 0.5, 'ghost': 0},\n",
    "    'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ice': 2, 'bug': 2, 'rock': 0.5, 'dragon': 0.5},\n",
    "    'water': {'fire': 2, 'water': 0.5, 'grass': 0.5, 'ground': 2, 'rock': 2, 'dragon': 0.5},\n",
    "    'grass': {'fire': 0.5, 'water': 2, 'grass': 0.5, 'poison': 0.5, 'ground': 2, 'flying': 0.5, 'bug': 0.5, 'rock': 2, 'dragon': 0.5},\n",
    "    'electric': {'water': 2, 'grass': 0.5, 'electric': 0.5, 'ground': 0, 'flying': 2, 'dragon': 0.5},\n",
    "    'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ground': 2, 'flying': 2, 'dragon': 2},\n",
    "    'fighting': {'normal': 2, 'ice': 2, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2, 'ghost': 0},\n",
    "    'poison': {'grass': 2, 'poison': 0.5, 'ground': 0.5, 'bug': 2, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground': {'fire': 2, 'grass': 0.5, 'electric': 2, 'poison': 2, 'flying': 0, 'bug': 0.5, 'rock': 2},\n",
    "    'flying': {'grass': 2, 'electric': 0.5, 'fighting': 2, 'bug': 2, 'rock': 0.5},\n",
    "    'psychic': {'fighting': 2, 'poison': 2, 'psychic': 0.5, 'ghost': 0},\n",
    "    'bug': {'fire': 0.5, 'grass': 2, 'fighting': 0.5, 'poison': 2, 'flying': 0.5, 'psychic': 2, 'ghost': 0.5},\n",
    "    'rock': {'fire': 2, 'ice': 2, 'fighting': 0.5, 'ground': 0.5, 'flying': 2, 'bug': 2},\n",
    "    'ghost': {'normal': 0, 'psychic': 0, 'ghost': 2},\n",
    "    'dragon': {'dragon': 2}\n",
    "}\n",
    "\n",
    "def get_effectiveness(attack_type: str, defense_types: list) -> float:\n",
    "    if not attack_type or not defense_types: return 1.0\n",
    "    eff = 1.0\n",
    "    for d in defense_types: eff *= TYPE_CHART.get(attack_type, {}).get(d, 1.0)\n",
    "    return eff\n",
    "\n",
    "def _entropy(counter: Counter) -> float:\n",
    "    total = sum(counter.values())\n",
    "    if total == 0: return 0.0\n",
    "    ent = 0.0\n",
    "    for v in counter.values():\n",
    "        p = v / total\n",
    "        if p > 0: ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ESTRATTORI FEATURE ORIGINALI (CONSERVATI)\n",
    "# ==============================================================================\n",
    "\n",
    "def calculate_type_advantage(team1: list, team2_lead: dict) -> dict:\n",
    "    out = {'p1_vs_lead_avg_effectiveness': 0.0, 'p1_vs_lead_max_effectiveness': 0.0, 'p1_super_effective_options': 0}\n",
    "    if not team1 or not team2_lead: return out\n",
    "    lead_types = [t.lower() for t in team2_lead.get('types', [])]\n",
    "    if not lead_types: return out\n",
    "    effs = []\n",
    "    for p in team1:\n",
    "        p_types = [t.lower() for t in p.get('types', [])]\n",
    "        max_eff = 0.0\n",
    "        for pt in p_types: max_eff = max(max_eff, get_effectiveness(pt, lead_types))\n",
    "        effs.append(max_eff)\n",
    "    if not effs: return out\n",
    "    out['p1_vs_lead_avg_effectiveness'] = float(np.mean(effs))\n",
    "    out['p1_vs_lead_max_effectiveness'] = float(np.max(effs))\n",
    "    out['p1_super_effective_options'] = int(sum(1 for e in effs if e >= 2))\n",
    "    return out\n",
    "\n",
    "def team_aggregate_features(team: list, prefix: str = 'p1_') -> dict:\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    out = {}\n",
    "    vals = {s: [] for s in stats}\n",
    "    levels = []; types_counter = Counter(); names = []\n",
    "    for p in team:\n",
    "        names.append(p.get('name',''))\n",
    "        for s in stats: vals[s].append(p.get(s, 0))\n",
    "        levels.append(p.get('level', 0))\n",
    "        for t in p.get('types', []): types_counter[t.lower()] += 1\n",
    "    for s in stats:\n",
    "        arr = np.array(vals[s], dtype=float)\n",
    "        out[f'{prefix}{s}_sum'] = float(arr.sum())\n",
    "        out[f'{prefix}{s}_mean'] = float(arr.mean())\n",
    "        out[f'{prefix}{s}_max'] = float(arr.max())\n",
    "        out[f'{prefix}{s}_min'] = float(arr.min())\n",
    "        out[f'{prefix}{s}_std'] = float(arr.std())\n",
    "    level_arr = np.array(levels, dtype=float)\n",
    "    out[f'{prefix}level_mean'] = float(level_arr.mean()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}level_sum'] = float(level_arr.sum()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}n_unique_types'] = int(len(types_counter))\n",
    "    for t in ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']:\n",
    "        out[f'{prefix}type_{t}_count'] = int(types_counter.get(t, 0))\n",
    "    out[f'{prefix}lead_name'] = names[0] if names else ''\n",
    "    out[f'{prefix}n_unique_names'] = int(len(set(names)))\n",
    "    out[f'{prefix}type_entropy'] = float(_entropy(types_counter))\n",
    "    spe_arr = np.array(vals['base_spe'], dtype=float)\n",
    "    out[f'{prefix}spe_p25'] = float(np.percentile(spe_arr, 25)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p50'] = float(np.percentile(spe_arr, 50)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p75'] = float(np.percentile(spe_arr, 75)) if spe_arr.size else 0.0\n",
    "    return out\n",
    "\n",
    "def lead_vs_lead_features(p1_lead: dict, p2_lead: dict) -> dict:\n",
    "    out = {}\n",
    "    for s in ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']:\n",
    "        out[f'lead_diff_{s}'] = float(p1_lead.get(s,0) - p2_lead.get(s,0))\n",
    "    out['lead_speed_advantage'] = float(p1_lead.get('base_spe',0) - p2_lead.get('base_spe',0))\n",
    "    p1_types = [t.lower() for t in p1_lead.get('types', [])]\n",
    "    p2_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    max_eff = 0.0\n",
    "    for pt in p1_types: max_eff = max(max_eff, get_effectiveness(pt, p2_types))\n",
    "    out['lead_p1_vs_p2_effectiveness'] = float(max_eff)\n",
    "    return out\n",
    "\n",
    "def lead_aggregate_features(pokemon: dict, prefix: str = 'p2_lead_') -> dict:\n",
    "    out = {}\n",
    "    for s in ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']:\n",
    "        out[f'{prefix}{s}'] = float(pokemon.get(s,0))\n",
    "    out[f'{prefix}level'] = int(pokemon.get('level',0))\n",
    "    types = [x.lower() for x in pokemon.get('types', [])]\n",
    "    for t in ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']:\n",
    "        out[f'{prefix}type_{t}'] = int(t in types)\n",
    "    out[f'{prefix}name'] = pokemon.get('name','')\n",
    "    out[f'{prefix}n_unique_types'] = int(len(set(types)))\n",
    "    return out\n",
    "\n",
    "def quick_boost_features_v2(record: dict) -> dict:\n",
    "    out = {}\n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    timeline = record.get('battle_timeline', [])\n",
    "    if not p1_team: return out\n",
    "    \n",
    "    p2_lead_spe = p2_lead.get('base_spe', 0)\n",
    "    out['p1_faster_than_lead_count'] = sum(1 for p in p1_team if p.get('base_spe', 0) > p2_lead_spe)\n",
    "    out['p1_slower_than_lead_count'] = sum(1 for p in p1_team if p.get('base_spe', 0) <= p2_lead_spe)\n",
    "    out['p1_speed_control_ratio'] = out['p1_faster_than_lead_count'] / max(1, len(p1_team))\n",
    "    \n",
    "    p1_avg_bulk = np.mean([p.get('base_hp', 0)*(p.get('base_def', 0)+p.get('base_spd', 0)) for p in p1_team])\n",
    "    p2_lead_bulk = p2_lead.get('base_hp', 1)*(p2_lead.get('base_def', 1)+p2_lead.get('base_spd', 1))\n",
    "    out['p1_avg_bulk_vs_lead'] = p1_avg_bulk / max(p2_lead_bulk, 1)\n",
    "    \n",
    "    p1_total_atk = sum(p.get('base_atk', 0) + p.get('base_spa', 0) for p in p1_team)\n",
    "    p2_lead_offense = p2_lead.get('base_atk', 0) + p2_lead.get('base_spa', 0)\n",
    "    out['p1_total_offense'] = p1_total_atk\n",
    "    out['p1_offense_advantage'] = p1_total_atk / max(p2_lead_offense, 1)\n",
    "    \n",
    "    p2_lead_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    if p2_lead_types:\n",
    "        cov = []\n",
    "        for p in p1_team:\n",
    "            p_types = [t.lower() for t in p.get('types', [])]\n",
    "            cov.append(max([get_effectiveness(pt, p2_lead_types) for pt in p_types] or [1.0]))\n",
    "        out['p1_avg_effectiveness_vs_lead'] = float(np.mean(cov))\n",
    "        out['p1_max_effectiveness_vs_lead'] = float(np.max(cov))\n",
    "        out['p1_se_count_vs_lead'] = sum(1 for s in cov if s >= 2.0)\n",
    "        out['p1_weak_count_vs_lead'] = sum(1 for s in cov if s <= 0.5)\n",
    "        \n",
    "    if timeline:\n",
    "        first_p1_ko = False; first_p2_ko = False\n",
    "        for turn in timeline[:30]:\n",
    "            if not first_p2_ko and turn.get('p2_pokemon_state', {}).get('fainted'):\n",
    "                first_p1_ko = True; out['p1_first_blood'] = 1; out['p1_first_blood_turn'] = turn.get('turn', 0); break\n",
    "            if not first_p1_ko and turn.get('p1_pokemon_state', {}).get('fainted'):\n",
    "                first_p2_ko = True; out['p1_first_blood'] = 0; out['p1_first_blood_turn'] = turn.get('turn', 0); break\n",
    "        if not first_p1_ko and not first_p2_ko:\n",
    "            out['p1_first_blood'] = -1; out['p1_first_blood_turn'] = 0\n",
    "            \n",
    "    p1_avg_level = np.mean([p.get('level', 50) for p in p1_team])\n",
    "    out['p1_avg_level_advantage'] = p1_avg_level - p2_lead.get('level', 50)\n",
    "    \n",
    "    p1_prods = [(p.get('base_hp',1)*p.get('base_atk',1)*p.get('base_def',1)*p.get('base_spa',1)*p.get('base_spd',1)*p.get('base_spe',1)) for p in p1_team]\n",
    "    out['p1_avg_stat_product'] = float(np.mean(p1_prods))\n",
    "    out['p1_max_stat_product'] = float(np.max(p1_prods))\n",
    "    p2_prod = p2_lead.get('base_hp',1)*p2_lead.get('base_atk',1)*p2_lead.get('base_def',1)*p2_lead.get('base_spa',1)*p2_lead.get('base_spd',1)*p2_lead.get('base_spe',1)\n",
    "    out['p1_stat_product_advantage'] = out['p1_avg_stat_product'] / max(p2_prod, 1)\n",
    "    return out\n",
    "\n",
    "def summary_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline: return {'tl_p1_moves':0,'tl_p2_moves':0,'tl_p1_est_damage':0.0,'tl_p2_est_damage':0.0,'damage_diff':0.0}\n",
    "    p1_moves = p2_moves = 0; p1_damage = p2_damage = 0.0\n",
    "    p1_last_active = p2_last_active = ''; p1_fainted = p2_fainted = 0\n",
    "    p1_fainted_names = set(); p2_fainted_names = set()\n",
    "    last_p1_hp = {}; last_p2_hp = {}\n",
    "    p1_comeback_kos = p2_comeback_kos = 0\n",
    "    p1_statuses = Counter(); p2_statuses = Counter()\n",
    "    p1_poke_statuses = {}; p2_poke_statuses = {}\n",
    "    p1_move_types = Counter(); p2_move_types = Counter()\n",
    "    p1_dmg_first2 = p2_dmg_first2 = 0.0\n",
    "    p1_dmg_by_turn = {}; p2_dmg_by_turn = {}; seen_turns = set()\n",
    "    first_ko_p1_taken = None; first_ko_p1_inflicted = None\n",
    "    p1_kos_early = p1_kos_late = p2_kos_early = p2_kos_late = 0\n",
    "\n",
    "    for turn in timeline[:30]:\n",
    "        prev_p1_f, prev_p2_f = p1_fainted, p2_fainted\n",
    "        p1s = turn.get('p1_pokemon_state',{}) or {}; p2s = turn.get('p2_pokemon_state',{}) or {}\n",
    "        tnum = turn.get('turn', len(seen_turns) + 1); seen_turns.add(tnum)\n",
    "\n",
    "        if p1s.get('name'): p1_last_active = p1s.get('name')\n",
    "        if p2s.get('name'): p2_last_active = p2s.get('name')\n",
    "\n",
    "        if p1s.get('fainted') and p1s.get('name') not in p1_fainted_names:\n",
    "            p1_fainted += 1; p1_fainted_names.add(p1s.get('name'))\n",
    "            if first_ko_p1_taken is None: first_ko_p1_taken = tnum\n",
    "            if tnum <= 10: p2_kos_early += 1\n",
    "            else: p2_kos_late += 1\n",
    "        if p2s.get('fainted') and p2s.get('name') not in p2_fainted_names:\n",
    "            p2_fainted += 1; p2_fainted_names.add(p2s.get('name'))\n",
    "            if first_ko_p1_inflicted is None: first_ko_p1_inflicted = tnum\n",
    "            if tnum <= 10: p1_kos_early += 1\n",
    "            else: p1_kos_late += 1\n",
    "\n",
    "        if p2s.get('name') and p2s.get('hp_pct') is not None:\n",
    "            prev = last_p2_hp.get(p2s['name'])\n",
    "            if prev is not None:\n",
    "                delta = max(0.0, prev - p2s['hp_pct'])\n",
    "                p1_damage += delta; p1_dmg_by_turn[tnum] = p1_dmg_by_turn.get(tnum,0.0)+delta\n",
    "                if tnum <= 2: p1_dmg_first2 += delta\n",
    "            last_p2_hp[p2s['name']] = p2s['hp_pct']\n",
    "\n",
    "        if p1s.get('name') and p1s.get('hp_pct') is not None:\n",
    "            prev = last_p1_hp.get(p1s['name'])\n",
    "            if prev is not None:\n",
    "                delta = max(0.0, prev - p1s['hp_pct'])\n",
    "                p2_damage += delta; p2_dmg_by_turn[tnum] = p2_dmg_by_turn.get(tnum,0.0)+delta\n",
    "                if tnum <= 2: p2_dmg_first2 += delta\n",
    "            last_p1_hp[p1s['name']] = p1s['hp_pct']\n",
    "\n",
    "        dmg_diff = p1_damage - p2_damage\n",
    "        if p2_fainted > prev_p2_f and dmg_diff < -1.0: p1_comeback_kos += 1\n",
    "        if p1_fainted > prev_p1_f and dmg_diff > 1.0: p2_comeback_kos += 1\n",
    "\n",
    "        if p2s.get('name') and p2s.get('status') and p2_poke_statuses.get(p2s['name']) != p2s['status']:\n",
    "            p1_statuses[p2s['status']] += 1; p2_poke_statuses[p2s['name']] = p2s['status']\n",
    "        if p1s.get('name') and p1s.get('status') and p1_poke_statuses.get(p1s['name']) != p1s['status']:\n",
    "            p2_statuses[p1s['status']] += 1; p1_poke_statuses[p1s['name']] = p1s['status']\n",
    "\n",
    "        if turn.get('p1_move_details'):\n",
    "            p1_moves += 1; mtype = (turn['p1_move_details'].get('type') or '').lower()\n",
    "            if mtype: p1_move_types[mtype] += 1\n",
    "        if turn.get('p2_move_details'):\n",
    "            p2_moves += 1; mtype = (turn['p2_move_details'].get('type') or '').lower()\n",
    "            if mtype: p2_move_types[mtype] += 1\n",
    "\n",
    "    out['tl_p1_moves'] = p1_moves; out['tl_p2_moves'] = p2_moves\n",
    "    out['tl_p1_est_damage'] = float(p1_damage); out['tl_p2_est_damage'] = float(p2_damage)\n",
    "    out['tl_p1_fainted'] = p1_fainted; out['tl_p2_fainted'] = p2_fainted\n",
    "    turns = max(1, len(seen_turns))\n",
    "    out['tl_p1_fainted_rate'] = p1_fainted/turns; out['tl_p2_fainted_rate'] = p2_fainted/turns\n",
    "    out['damage_diff'] = float(p1_damage - p2_damage); out['fainted_diff'] = int(p1_fainted - p2_fainted)\n",
    "    out['tl_p1_last_hp'] = float(last_p1_hp.get(p1_last_active, 0) if p1_last_active else 0)\n",
    "    out['tl_p2_last_hp'] = float(last_p2_hp.get(p2_last_active, 0) if p2_last_active else 0)\n",
    "    out['tl_p1_last_active'] = p1_last_active; out['tl_p2_last_active'] = p2_last_active\n",
    "    \n",
    "    if p1_team:\n",
    "        p1_hp_sum = sum(p.get('base_hp',0) for p in p1_team)\n",
    "        p1_def_avg = np.mean([p.get('base_def',0)+p.get('base_spd',0) for p in p1_team])\n",
    "        out['tl_p2_damage_vs_p1_hp_pool'] = p2_damage / (p1_hp_sum + 1e-6)\n",
    "        out['tl_p1_defensive_endurance'] = p1_def_avg / (p2_damage + 1e-6)\n",
    "        \n",
    "    out['tl_p1_comeback_kos'] = p1_comeback_kos; out['tl_p2_comeback_kos'] = p2_comeback_kos\n",
    "    out['tl_comeback_kos_diff'] = p1_comeback_kos - p2_comeback_kos\n",
    "\n",
    "    for s in ['brn','par','slp','frz','psn','tox']:\n",
    "        out[f'tl_p1_inflicted_{s}_count'] = p1_statuses[s]\n",
    "        out[f'tl_p2_inflicted_{s}_count'] = p2_statuses[s]\n",
    "        out[f'tl_inflicted_{s}_diff'] = p1_statuses[s] - p2_statuses[s]\n",
    "        out[f'tl_p1_inflicted_{s}_rate'] = p1_statuses[s]/turns\n",
    "        out[f'tl_p2_inflicted_{s}_rate'] = p2_statuses[s]/turns\n",
    "        out[f'tl_inflicted_{s}_rate_diff'] = (p1_statuses[s]-p2_statuses[s])/turns\n",
    "\n",
    "    for mt in ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying','ghost','bug','poison','fighting']:\n",
    "        out[f'tl_p1_move_type_{mt}_count'] = p1_move_types[mt]\n",
    "        out[f'tl_p2_move_type_{mt}_count'] = p2_move_types[mt]\n",
    "        out[f'tl_move_type_{mt}_count_diff'] = p1_move_types[mt] - p2_move_types[mt]\n",
    "\n",
    "    out['tl_p1_damage_first2'] = p1_dmg_first2; out['tl_p2_damage_first2'] = p2_dmg_first2\n",
    "    out['tl_first2_damage_diff'] = p1_dmg_first2 - p2_dmg_first2\n",
    "    out['tl_turns_count'] = turns\n",
    "    out['tl_p1_moves_rate'] = p1_moves/turns; out['tl_p2_moves_rate'] = p2_moves/turns\n",
    "    out['tl_p1_damage_per_turn'] = p1_damage/turns; out['tl_p2_damage_per_turn'] = p2_damage/turns\n",
    "    out['tl_damage_rate_diff'] = out['tl_p1_damage_per_turn'] - out['tl_p2_damage_per_turn']\n",
    "\n",
    "    recent = sorted(seen_turns)[-5:] if seen_turns else []\n",
    "    p1_last5 = sum(p1_dmg_by_turn.get(t,0) for t in recent)\n",
    "    p2_last5 = sum(p2_dmg_by_turn.get(t,0) for t in recent)\n",
    "    out['tl_p1_damage_last5'] = p1_last5; out['tl_p2_damage_last5'] = p2_last5\n",
    "    out['tl_last5_damage_diff'] = p1_last5 - p2_last5\n",
    "    out['tl_p1_last5_damage_ratio'] = p1_last5/(p1_damage+1e-6)\n",
    "    out['tl_p2_last5_damage_ratio'] = p2_last5/(p2_damage+1e-6)\n",
    "    out['tl_last5_damage_ratio_diff'] = out['tl_p1_last5_damage_ratio'] - out['tl_p2_last5_damage_ratio']\n",
    "\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns); w = np.linspace(1.0, 2.0, num=len(ts)); w = w/w.sum()\n",
    "        adv = [(p1_dmg_by_turn.get(t,0)-p2_dmg_by_turn.get(t,0)) for t in ts]\n",
    "        out['tl_weighted_damage_diff'] = float(np.dot(w, adv))\n",
    "        cum = 0.0; signs = []\n",
    "        for t in ts:\n",
    "            cum += (p1_dmg_by_turn.get(t,0)-p2_dmg_by_turn.get(t,0))\n",
    "            s = 1 if cum > 1e-9 else (-1 if cum < -1e-9 else 0)\n",
    "            if s != 0 and (not signs or signs[-1] != s): signs.append(s)\n",
    "        out['tl_damage_adv_sign_flips'] = max(0, len(signs)-1)\n",
    "        out['tl_comeback_flag'] = 1 if (len(signs)>=2 and signs[0]!=signs[-1]) else 0\n",
    "    else:\n",
    "        out['tl_weighted_damage_diff'] = 0.0; out['tl_damage_adv_sign_flips'] = 0; out['tl_comeback_flag'] = 0\n",
    "\n",
    "    out['tl_first_ko_turn_p1_inflicted'] = int(first_ko_p1_inflicted or 0)\n",
    "    out['tl_first_ko_turn_p1_taken'] = int(first_ko_p1_taken or 0)\n",
    "    out['tl_first_ko_turn_diff'] = out['tl_first_ko_turn_p1_inflicted'] - out['tl_first_ko_turn_p1_taken']\n",
    "    out['tl_kos_early_p1'] = p1_kos_early; out['tl_kos_late_p1'] = p1_kos_late\n",
    "    out['tl_kos_early_p2'] = p2_kos_early; out['tl_kos_late_p2'] = p2_kos_late\n",
    "    return out\n",
    "\n",
    "def extract_move_coverage_from_timeline(timeline: list, prefix: str = 'p1_') -> dict:\n",
    "    out = {}\n",
    "    m_types = set(); m_cats = Counter(); unique_m = set(); stab = 0\n",
    "    for turn in timeline[:30]:\n",
    "        md = turn.get(f'{prefix[:-1]}_move_details')\n",
    "        ps = turn.get(f'{prefix[:-1]}_pokemon_state', {})\n",
    "        if not md: continue\n",
    "        if md.get('name'): unique_m.add(md['name'])\n",
    "        if t := (md.get('type') or '').lower(): m_types.add(t)\n",
    "        if c := md.get('category'): m_cats[c] += 1\n",
    "        if t in [pt.lower() for pt in ps.get('types', [])]: stab += 1\n",
    "    \n",
    "    out[f'{prefix}tl_unique_move_types'] = len(m_types)\n",
    "    out[f'{prefix}tl_unique_moves_used'] = len(unique_m)\n",
    "    out[f'{prefix}tl_stab_moves'] = stab\n",
    "    out[f'{prefix}tl_physical_moves'] = m_cats['physical']\n",
    "    out[f'{prefix}tl_special_moves'] = m_cats['special']\n",
    "    out[f'{prefix}tl_status_moves'] = m_cats['status']\n",
    "    out[f'{prefix}tl_coverage_score'] = len(m_types)/max(1, len(unique_m))\n",
    "    tot = sum(m_cats.values())\n",
    "    out[f'{prefix}tl_offensive_ratio'] = (m_cats['physical']+m_cats['special'])/tot if tot else 0.0\n",
    "    out[f'{prefix}tl_status_ratio'] = m_cats['status']/tot if tot else 0.0\n",
    "    return out\n",
    "\n",
    "def ability_features(team: list, prefix: str) -> dict:\n",
    "    imm = {'levitate':0,'volt_absorb':0,'water_absorb':0,'flash_fire':0}\n",
    "    drop = {'intimidate':0}; weather = {'drought':0,'drizzle':0,'sand_stream':0}\n",
    "    for p in team:\n",
    "        a = (p.get('ability','') or '').lower().replace(' ','_')\n",
    "        if a in imm: imm[a]+=1\n",
    "        if a in drop: drop[a]+=1\n",
    "        if a in weather: weather[a]+=1\n",
    "    out = {}\n",
    "    for k,v in imm.items(): out[f'{prefix}ability_{k}_count'] = v\n",
    "    for k,v in drop.items(): out[f'{prefix}ability_{k}_count'] = v\n",
    "    for k,v in weather.items(): out[f'{prefix}ability_{k}_count'] = v\n",
    "    out[f'{prefix}total_immunity_abilities'] = sum(imm.values())\n",
    "    out[f'{prefix}total_stat_drop_abilities'] = sum(drop.values())\n",
    "    return out\n",
    "\n",
    "def momentum_features(timeline: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline: return out\n",
    "    advs = []; cum = 0.0\n",
    "    for turn in timeline[:30]:\n",
    "        p1h = turn.get('p1_pokemon_state', {}).get('hp_pct', 100)\n",
    "        p2h = turn.get('p2_pokemon_state', {}).get('hp_pct', 100)\n",
    "        cum += (p1h - p2h); advs.append(cum)\n",
    "    if advs:\n",
    "        slope, intercept = np.polyfit(np.arange(len(advs)), advs, 1)\n",
    "        out['p1_momentum_slope'] = float(slope)\n",
    "        out['p1_momentum_intercept'] = float(intercept)\n",
    "        out['p1_final_advantage'] = float(advs[-1])\n",
    "        out['p1_advantage_volatility'] = float(np.std(advs))\n",
    "        out['p1_max_advantage'] = float(np.max(advs))\n",
    "        out['p1_min_advantage'] = float(np.min(advs))\n",
    "        out['p1_advantage_range'] = out['p1_max_advantage'] - out['p1_min_advantage']\n",
    "    return out\n",
    "\n",
    "def extract_opponent_team_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    seen = set(); types = []\n",
    "    for turn in timeline[:30]:\n",
    "        p2s = turn.get('p2_pokemon_state', {})\n",
    "        if p2s.get('name') and p2s['name'] not in seen:\n",
    "            seen.add(p2s['name'])\n",
    "            types.extend([t.lower() for t in p2s.get('types', [])])\n",
    "    \n",
    "    out['p2_tl_unique_pokemon_seen'] = len(seen)\n",
    "    out['p2_tl_switches_count'] = max(0, len(seen) - 1)\n",
    "    out['p2_tl_unique_types_seen'] = len(set(types))\n",
    "    out['p2_tl_type_entropy'] = _entropy(Counter(types))\n",
    "    \n",
    "    advs = 0\n",
    "    if types and p1_team:\n",
    "        for p1 in p1_team:\n",
    "            for t1 in [t.lower() for t in p1.get('types', [])]:\n",
    "                for t2 in set(types):\n",
    "                    if get_effectiveness(t1, [t2]) >= 2.0: advs += 1\n",
    "    out['p1_vs_p2_tl_type_advantages'] = advs\n",
    "    out['p1_vs_p2_tl_type_advantages_per_poke'] = advs / max(1, len(p1_team))\n",
    "    out['p2_tl_switch_rate'] = len(seen) / max(1, len(timeline[:30]))\n",
    "    return out\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. NUOVE FEATURE AVANZATE (DATA-DRIVEN, NO META)\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_information_advantage(timeline: list) -> dict:\n",
    "    p1_rev = set(); p2_rev = set(); reveal_turns_p2 = []\n",
    "    for turn in timeline[:30]:\n",
    "        t = turn.get('turn', 0)\n",
    "        if n1 := turn.get('p1_pokemon_state', {}).get('name'): p1_rev.add(n1)\n",
    "        if n2 := turn.get('p2_pokemon_state', {}).get('name'):\n",
    "            if n2 not in p2_rev: p2_rev.add(n2); reveal_turns_p2.append(t)\n",
    "    return {\n",
    "        'tl_p1_revealed_count': len(p1_rev),\n",
    "        'tl_p2_revealed_count': len(p2_rev),\n",
    "        'tl_info_advantage': len(p2_rev) - len(p1_rev),\n",
    "        'tl_p2_avg_reveal_turn': float(np.mean(reveal_turns_p2)) if reveal_turns_p2 else 30.0\n",
    "    }\n",
    "\n",
    "def extract_advanced_momentum(timeline: list) -> dict:\n",
    "    p1_immune = 0; p2_forced = 0\n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        if i == 0: continue\n",
    "        prev = timeline[i-1]\n",
    "        c1 = turn.get('p1_pokemon_state', {}).get('name')\n",
    "        p1 = prev.get('p1_pokemon_state', {}).get('name')\n",
    "        if c1 != p1 and not prev.get('p1_pokemon_state', {}).get('fainted'):\n",
    "            m2_type = (turn.get('p2_move_details') or {}).get('type', '').lower()\n",
    "            p1_types = [t.lower() for t in turn.get('p1_pokemon_state', {}).get('types', [])]\n",
    "            if m2_type and p1_types and get_effectiveness(m2_type, p1_types) == 0.0:\n",
    "                p1_immune += 1\n",
    "        c2 = turn.get('p2_pokemon_state', {}).get('name')\n",
    "        p2 = prev.get('p2_pokemon_state', {}).get('name')\n",
    "        if c2 != p2 and not prev.get('p2_pokemon_state', {}).get('fainted'):\n",
    "            if prev.get('p2_pokemon_state', {}).get('hp_pct', 1.0) < 0.50:\n",
    "                p2_forced += 1\n",
    "    return {'tl_p1_immune_switches': p1_immune, 'tl_p2_forced_switches': p2_forced}\n",
    "\n",
    "def extract_gamestate_snapshots(timeline: list) -> dict:\n",
    "    turns_lead = 0; hp_diff_10 = 0.0; hp_diff_20 = 0.0; hp_diff_30 = 0.0\n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        t = i + 1\n",
    "        h1 = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n",
    "        h2 = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n",
    "        if h1 > h2: turns_lead += 1\n",
    "        if t == 10: hp_diff_10 = h1 - h2\n",
    "        if t == 20: hp_diff_20 = h1 - h2\n",
    "        hp_diff_30 = h1 - h2 # Ultimo stato disponibile\n",
    "    return {\n",
    "        'tl_turns_with_hp_lead': turns_lead,\n",
    "        'tl_hp_diff_turn_10': float(hp_diff_10),\n",
    "        'tl_hp_diff_turn_20': float(hp_diff_20),\n",
    "        'tl_hp_diff_end': float(hp_diff_30)\n",
    "    }\n",
    "\n",
    "def extract_observed_mechanics(timeline: list) -> dict:\n",
    "    p1_heals = 0; p2_heals = 0; p1_frz = 0; p2_frz = 0\n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        if i == 0: continue\n",
    "        prev = timeline[i-1]\n",
    "        p1s = turn.get('p1_pokemon_state', {}); p1s_prev = prev.get('p1_pokemon_state', {})\n",
    "        p2s = turn.get('p2_pokemon_state', {}); p2s_prev = prev.get('p2_pokemon_state', {})\n",
    "        if p1s.get('name') == p1s_prev.get('name'):\n",
    "             if p1s.get('hp_pct', 0) > p1s_prev.get('hp_pct', 0): p1_heals += 1\n",
    "        if p2s.get('name') == p2s_prev.get('name'):\n",
    "             if p2s.get('hp_pct', 0) > p2s_prev.get('hp_pct', 0): p2_heals += 1\n",
    "        if p1s.get('status') == 'frz': p1_frz = 1\n",
    "        if p2s.get('status') == 'frz': p2_frz = 1\n",
    "    return {'tl_heal_diff': p1_heals - p2_heals, 'tl_freeze_adv': p2_frz - p1_frz}\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MASTER FUNCTION V3 (COMPLETA)\n",
    "# ==============================================================================\n",
    "\n",
    "def prepare_record_features_COMPLETE(record: dict, max_turns: int = 30) -> dict:\n",
    "    out = {'battle_id': record.get('battle_id')}\n",
    "    if 'player_won' in record: out['player_won'] = int(bool(record['player_won']))\n",
    "    \n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    p1_lead = p1_team[0] if p1_team else {}\n",
    "    tl = record.get('battle_timeline', [])[:max_turns]\n",
    "    \n",
    "    # --- VECCHIE FEATURE (MANTENUTE) ---\n",
    "    out.update(team_aggregate_features(p1_team, 'p1_'))\n",
    "    out.update(lead_aggregate_features(p2_lead, 'p2_lead_'))\n",
    "    out.update(ability_features(p1_team, 'p1_'))\n",
    "    out.update(lead_vs_lead_features(p1_lead, p2_lead))\n",
    "    out.update(ability_features([p2_lead], 'p2_lead_'))\n",
    "    out['p1_intimidate_vs_lead'] = int(out.get('p1_ability_intimidate_count',0) > 0)\n",
    "    out.update(summary_from_timeline(tl, p1_team))\n",
    "    out.update(extract_move_coverage_from_timeline(tl, 'p1_'))\n",
    "    out.update(extract_move_coverage_from_timeline(tl, 'p2_'))\n",
    "    out.update(extract_opponent_team_from_timeline(tl, p1_team))\n",
    "    out.update(quick_boost_features_v2(record))\n",
    "    out.update(momentum_features(tl))\n",
    "    \n",
    "    out['team_hp_sum_minus_p2lead_hp'] = out.get('p1_base_hp_sum',0) - out.get('p2_lead_base_hp',0)\n",
    "    out['team_spa_mean_minus_p2spa'] = out.get('p1_base_spa_mean',0) - out.get('p2_lead_base_spa',0)\n",
    "    out['speed_advantage'] = out.get('p1_base_spe_sum',0) - out.get('p2_lead_base_spe',0)\n",
    "    out['n_unique_types_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_lead_n_unique_types',1)\n",
    "    p1m = max(out.get('tl_p1_moves',1),1); p2m = max(out.get('tl_p2_moves',1),1)\n",
    "    out['damage_per_turn_diff'] = (out.get('tl_p1_est_damage',0)/p1m) - (out.get('tl_p2_est_damage',0)/p2m)\n",
    "    out['last_pair'] = f\"{out.get('tl_p1_last_active','')}_VS_{out.get('tl_p2_last_active','')}\"\n",
    "    \n",
    "    out.update(calculate_type_advantage(p1_team, p2_lead))\n",
    "    p2_bulk = out.get('p2_lead_base_def',1) + out.get('p2_lead_base_spd',1)\n",
    "    out['p1_se_options_vs_lead_bulk'] = out.get('p1_super_effective_options',0) / (p2_bulk + 1e-6)\n",
    "    \n",
    "    if p2_team := record.get('p2_team_details', []):\n",
    "        out.update(team_aggregate_features(p2_team, 'p2_'))\n",
    "        out['team_hp_sum_diff'] = out.get('p1_base_hp_sum',0) - out.get('p2_base_hp_sum',0)\n",
    "        out['team_spa_mean_diff'] = out.get('p1_base_spa_mean',0) - out.get('p2_base_spa_mean',0)\n",
    "        out['team_spe_mean_diff'] = out.get('p1_base_spe_mean',0) - out.get('p2_base_spe_mean',0)\n",
    "        out['n_unique_types_team_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_n_unique_types',0)\n",
    "        \n",
    "    # --- NUOVE FEATURE (AGGIUNTE) ---\n",
    "    if tl:\n",
    "        out.update(extract_information_advantage(tl))\n",
    "        out.update(extract_advanced_momentum(tl))\n",
    "        out.update(extract_gamestate_snapshots(tl))\n",
    "        out.update(extract_observed_mechanics(tl))\n",
    "    else:\n",
    "        # Defaults per record senza timeline\n",
    "        out.update({\n",
    "            'tl_p1_revealed_count': 1, 'tl_p2_revealed_count': 1, 'tl_info_advantage': 0,\n",
    "            'tl_p2_avg_reveal_turn': 30.0, 'tl_p1_immune_switches': 0, 'tl_p2_forced_switches': 0,\n",
    "            'tl_turns_with_hp_lead': 0, 'tl_hp_diff_turn_10': 0.0, 'tl_hp_diff_turn_20': 0.0,\n",
    "            'tl_hp_diff_end': 0.0, 'tl_heal_diff': 0, 'tl_freeze_adv': 0\n",
    "        })\n",
    "        \n",
    "    return out\n",
    "\n",
    "def create_features_from_raw(data: list) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for b in tqdm(data, desc='FE Complete'):\n",
    "        try:\n",
    "            # Usa la funzione master completa\n",
    "            feat = prepare_record_features_COMPLETE(b)\n",
    "            if 'battle_id' not in feat: feat['battle_id'] = b.get('battle_id')\n",
    "            rows.append(feat)\n",
    "        except Exception as e:\n",
    "            rows.append({'battle_id': b.get('battle_id'), 'error': 1})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if 'player_won' in df.columns: df['player_won'] = df['player_won'].astype(int)\n",
    "    return df.fillna(0)\n",
    "\n",
    "# Esecuzione\n",
    "train_df = create_features_from_raw(train_raw)\n",
    "test_df = create_features_from_raw(test_raw)\n",
    "print('Feature shape train/test:', train_df.shape, test_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bdb01",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1191bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num FEATURES numeriche: 289\n",
      "Preprocessing completato.\n",
      "Dataset completo size: 10000\n",
      "Features: 289\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing - LightGBM gestisce bene valori raw (no scaling necessario)\n",
    "exclude_cols = ['battle_id', 'player_won']\n",
    "string_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "exclude_cols.extend(string_cols)\n",
    "\n",
    "ALL_NUMERIC_FEATURES = [c for c in train_df.columns if c not in exclude_cols]\n",
    "FEATURES = ALL_NUMERIC_FEATURES\n",
    "\n",
    "print(f'Num FEATURES numeriche: {len(FEATURES)}')\n",
    "\n",
    "# Imputazione mediana\n",
    "num_df = train_df[FEATURES].astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "medians = num_df.median()\n",
    "train_imputed = num_df.fillna(medians)\n",
    "train_preproc_df = train_imputed.copy()\n",
    "\n",
    "y = train_df['player_won'].astype(int).values\n",
    "X = train_preproc_df.values\n",
    "\n",
    "print('Preprocessing completato.')\n",
    "print('Dataset completo size:', X.shape[0])\n",
    "print('Features:', len(FEATURES))\n",
    "\n",
    "# Allinea test\n",
    "test_aligned = test_df.reindex(columns=FEATURES, fill_value=np.nan).astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "test_imputed = test_aligned.fillna(medians)\n",
    "test_preproc_df = pd.DataFrame(test_imputed.values, columns=FEATURES, index=test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463df190",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (Optuna + LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970b6ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 23:07:45,833] A new study created in memory with name: LightGBM_Pokemon_V5_Advanced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸš€ OPTUNA ADVANCED HYPERPARAMETER OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Configurazione:\n",
      "   â€¢ n_trials: 300\n",
      "   â€¢ timeout: 10800\n",
      "   â€¢ cv_folds: 5\n",
      "   â€¢ early_stopping: 50\n",
      "   â€¢ n_startup_trials: 30\n",
      "   â€¢ use_stratified_cv: True\n",
      "   â€¢ random_state: 42\n",
      "\n",
      "ðŸ”„ Inizio ottimizzazione (300 trials, timeout 10800s)...\n",
      "   Baseline accuracy da battere: 0.7900\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dbde444eb84b1284bfec59bfca650f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 23:07:53,674] Trial 0 finished with value: 0.8405999999999999 and parameters: {'learning_rate': 0.012258326170847326, 'num_leaves': 147, 'max_depth': 9, 'reg_alpha': 0.06502468545951015, 'reg_lambda': 0.7979118876474873, 'min_split_gain': 0.2403950683025824, 'subsample': 0.5203292642588698, 'colsample_bytree': 0.8031616510212273, 'subsample_freq': 5, 'min_child_samples': 97, 'min_child_weight': 0.0012087541473056963, 'boosting_type': 'gbdt', 'n_estimators': 550}. Best is trial 0 with value: 0.8405999999999999.\n",
      "\n",
      "[Trial 0] Best so far: 0.8406\n",
      "[I 2025-11-11 23:08:04,142] Trial 1 finished with value: 0.8423 and parameters: {'learning_rate': 0.009841608300243988, 'num_leaves': 84, 'max_depth': 6, 'reg_alpha': 0.02922905212920092, 'reg_lambda': 1.823658142455605, 'min_split_gain': 0.36210622617823773, 'subsample': 0.7141485131528328, 'colsample_bytree': 0.5488228512282146, 'subsample_freq': 3, 'min_child_samples': 69, 'min_child_weight': 0.06672367170464207, 'boosting_type': 'gbdt', 'n_estimators': 800}. Best is trial 1 with value: 0.8423.\n",
      "[I 2025-11-11 23:08:13,318] Trial 2 finished with value: 0.8409000000000001 and parameters: {'learning_rate': 0.01571253829746061, 'num_leaves': 73, 'max_depth': 8, 'reg_alpha': 0.00063283099528693, 'reg_lambda': 0.6075808513336687, 'min_split_gain': 0.9539969835279999, 'subsample': 0.8379712115760958, 'colsample_bytree': 0.7829390718407614, 'subsample_freq': 3, 'min_child_samples': 47, 'min_child_weight': 0.5456725485601477, 'boosting_type': 'gbdt', 'n_estimators': 800}. Best is trial 1 with value: 0.8423.\n",
      "[I 2025-11-11 23:08:30,344] Trial 3 finished with value: 0.8426 and parameters: {'learning_rate': 0.00831969005876269, 'num_leaves': 143, 'max_depth': 6, 'reg_alpha': 0.12976941336928302, 'reg_lambda': 1.272083045469184, 'min_split_gain': 0.5680612190600297, 'subsample': 0.6913485977701479, 'colsample_bytree': 0.5646990594339345, 'subsample_freq': 7, 'min_child_samples': 102, 'min_child_weight': 5.727904470799623, 'boosting_type': 'gbdt', 'n_estimators': 1150}. Best is trial 3 with value: 0.8426.\n",
      "[I 2025-11-11 23:08:43,179] Trial 4 finished with value: 0.8423999999999999 and parameters: {'learning_rate': 0.008848721031156977, 'num_leaves': 85, 'max_depth': 5, 'reg_alpha': 0.003378449765619961, 'reg_lambda': 1.6019568611465231, 'min_split_gain': 0.34421412859650635, 'subsample': 0.7900581282031752, 'colsample_bytree': 0.6248636643427562, 'subsample_freq': 2, 'min_child_samples': 83, 'min_child_weight': 0.0036618192203924276, 'boosting_type': 'gbdt', 'n_estimators': 1200}. Best is trial 3 with value: 0.8426.\n",
      "[I 2025-11-11 23:08:50,602] Trial 5 finished with value: 0.8385999999999999 and parameters: {'learning_rate': 0.01928569649361389, 'num_leaves': 86, 'max_depth': 5, 'reg_alpha': 0.6789359290638651, 'reg_lambda': 4.155397855708038, 'min_split_gain': 0.7561064512368886, 'subsample': 0.769944621340081, 'colsample_bytree': 0.5259156281069316, 'subsample_freq': 3, 'min_child_samples': 49, 'min_child_weight': 2.8340904295147746, 'boosting_type': 'gbdt', 'n_estimators': 450}. Best is trial 3 with value: 0.8426.\n",
      "[I 2025-11-11 23:09:09,856] Trial 6 finished with value: 0.8189 and parameters: {'learning_rate': 0.011401962167072704, 'num_leaves': 96, 'max_depth': 9, 'reg_alpha': 0.09905204218383899, 'reg_lambda': 7.132805718188966, 'min_split_gain': 0.5249934326457544, 'subsample': 0.5418579860784056, 'colsample_bytree': 0.7496356755280482, 'subsample_freq': 6, 'min_child_samples': 85, 'min_child_weight': 1.2130221181165162, 'boosting_type': 'dart', 'drop_rate': 0.15688525458963742, 'skip_drop': 0.3101676506976381, 'n_estimators': 450}. Best is trial 3 with value: 0.8426.\n",
      "[I 2025-11-11 23:10:11,561] Trial 7 finished with value: 0.834 and parameters: {'learning_rate': 0.008291683573122316, 'num_leaves': 121, 'max_depth': 6, 'reg_alpha': 0.024533438588688842, 'reg_lambda': 7.5812568387896215, 'min_split_gain': 0.32436300623398745, 'subsample': 0.6436340230624704, 'colsample_bytree': 0.7644428984900671, 'subsample_freq': 2, 'min_child_samples': 46, 'min_child_weight': 0.014421346497969485, 'boosting_type': 'dart', 'drop_rate': 0.25203009489110423, 'skip_drop': 0.5533615026041694, 'n_estimators': 1100}. Best is trial 3 with value: 0.8426.\n",
      "[I 2025-11-11 23:10:22,542] Trial 8 finished with value: 0.843 and parameters: {'learning_rate': 0.01998881882634931, 'num_leaves': 85, 'max_depth': 10, 'reg_alpha': 0.03422575339553556, 'reg_lambda': 5.616604788742511, 'min_split_gain': 0.9064821699311439, 'subsample': 0.6113012162401523, 'colsample_bytree': 0.5385181735846869, 'subsample_freq': 2, 'min_child_samples': 74, 'min_child_weight': 1.8709365688887358, 'boosting_type': 'gbdt', 'n_estimators': 800}. Best is trial 8 with value: 0.843.\n",
      "[I 2025-11-11 23:10:37,127] Trial 9 finished with value: 0.8174999999999999 and parameters: {'learning_rate': 0.012871994068036947, 'num_leaves': 87, 'max_depth': 5, 'reg_alpha': 0.0038587226423781227, 'reg_lambda': 8.427986132210085, 'min_split_gain': 0.3908826388186797, 'subsample': 0.6815767176101781, 'colsample_bytree': 0.7460566356133123, 'subsample_freq': 3, 'min_child_samples': 118, 'min_child_weight': 7.076022085822011, 'boosting_type': 'dart', 'drop_rate': 0.12521957745419243, 'skip_drop': 0.413936197750987, 'n_estimators': 400}. Best is trial 8 with value: 0.843.\n",
      "[I 2025-11-11 23:10:41,840] Trial 10 pruned. \n",
      "\n",
      "[Trial 10] Best so far: 0.8430\n",
      "[I 2025-11-11 23:10:55,047] Trial 11 pruned. \n",
      "[I 2025-11-11 23:11:10,500] Trial 12 finished with value: 0.8412 and parameters: {'learning_rate': 0.01757925806521185, 'num_leaves': 101, 'max_depth': 10, 'reg_alpha': 0.00044279916323101574, 'reg_lambda': 1.389016988869002, 'min_split_gain': 0.20212616911653017, 'subsample': 0.823642766397497, 'colsample_bytree': 0.8070687736833433, 'subsample_freq': 2, 'min_child_samples': 93, 'min_child_weight': 1.857328833311487, 'boosting_type': 'gbdt', 'n_estimators': 600}. Best is trial 8 with value: 0.843.\n",
      "[I 2025-11-11 23:11:20,644] Trial 13 pruned. \n",
      "[I 2025-11-11 23:11:33,654] Trial 14 pruned. \n",
      "[I 2025-11-11 23:12:10,346] Trial 15 pruned. \n",
      "[I 2025-11-11 23:12:24,728] Trial 16 pruned. \n",
      "[I 2025-11-11 23:12:39,362] Trial 17 pruned. \n",
      "[I 2025-11-11 23:13:30,271] Trial 18 pruned. \n",
      "[I 2025-11-11 23:14:28,257] Trial 19 pruned. \n",
      "[I 2025-11-11 23:14:38,756] Trial 20 pruned. \n",
      "\n",
      "[Trial 20] Best so far: 0.8430\n",
      "[I 2025-11-11 23:15:07,112] Trial 21 pruned. \n",
      "[I 2025-11-11 23:15:33,054] Trial 22 pruned. \n",
      "[I 2025-11-11 23:15:44,976] Trial 23 pruned. \n",
      "[I 2025-11-11 23:16:15,997] Trial 24 pruned. \n",
      "[I 2025-11-11 23:16:21,419] Trial 25 pruned. \n",
      "[I 2025-11-11 23:16:30,031] Trial 26 pruned. \n",
      "[I 2025-11-11 23:16:53,043] Trial 27 pruned. \n",
      "[I 2025-11-11 23:17:05,945] Trial 28 pruned. \n",
      "[I 2025-11-11 23:17:29,468] Trial 29 pruned. \n",
      "[I 2025-11-11 23:18:04,672] Trial 30 finished with value: 0.842 and parameters: {'learning_rate': 0.010030288629198301, 'num_leaves': 136, 'max_depth': 5, 'reg_alpha': 0.15399704514869875, 'reg_lambda': 2.1417762971839225, 'min_split_gain': 0.7714184538839279, 'subsample': 0.7147824028612784, 'colsample_bytree': 0.5596117883248548, 'subsample_freq': 7, 'min_child_samples': 93, 'min_child_weight': 4.558468141200539, 'boosting_type': 'gbdt', 'n_estimators': 1150}. Best is trial 8 with value: 0.843.\n",
      "\n",
      "[Trial 30] Best so far: 0.8430\n",
      "[I 2025-11-11 23:18:16,859] Trial 31 pruned. \n",
      "[I 2025-11-11 23:18:25,057] Trial 32 pruned. \n",
      "[I 2025-11-11 23:18:37,440] Trial 33 pruned. \n",
      "[I 2025-11-11 23:19:42,793] Trial 34 finished with value: 0.8407 and parameters: {'learning_rate': 0.011000302558189888, 'num_leaves': 97, 'max_depth': 5, 'reg_alpha': 0.009663078970038442, 'reg_lambda': 2.324308199433848, 'min_split_gain': 0.2229082006996019, 'subsample': 0.7947527728092743, 'colsample_bytree': 0.6439857247948079, 'subsample_freq': 2, 'min_child_samples': 81, 'min_child_weight': 0.010639612702805737, 'boosting_type': 'dart', 'drop_rate': 0.11430957140898759, 'skip_drop': 0.6919036403990879, 'n_estimators': 1150}. Best is trial 8 with value: 0.843.\n",
      "[I 2025-11-11 23:19:49,270] Trial 35 pruned. \n",
      "[I 2025-11-11 23:20:22,824] Trial 36 finished with value: 0.8428000000000001 and parameters: {'learning_rate': 0.008354814283275409, 'num_leaves': 146, 'max_depth': 7, 'reg_alpha': 0.6057784354836017, 'reg_lambda': 1.2852967124144614, 'min_split_gain': 0.40856079226103037, 'subsample': 0.6654006812565889, 'colsample_bytree': 0.5790101692184993, 'subsample_freq': 5, 'min_child_samples': 104, 'min_child_weight': 0.28975471312636575, 'boosting_type': 'gbdt', 'n_estimators': 1200}. Best is trial 8 with value: 0.843.\n",
      "[I 2025-11-11 23:20:34,118] Trial 37 pruned. \n",
      "[I 2025-11-11 23:20:49,774] Trial 38 pruned. \n",
      "[I 2025-11-11 23:21:50,789] Trial 39 pruned. \n",
      "[I 2025-11-11 23:22:43,713] Trial 40 pruned. \n",
      "\n",
      "[Trial 40] Best so far: 0.8430\n",
      "[I 2025-11-11 23:22:53,583] Trial 41 pruned. \n",
      "[I 2025-11-11 23:23:02,229] Trial 42 pruned. \n",
      "[I 2025-11-11 23:23:28,580] Trial 43 finished with value: 0.8433999999999999 and parameters: {'learning_rate': 0.009589908550224641, 'num_leaves': 142, 'max_depth': 7, 'reg_alpha': 0.011488331164689967, 'reg_lambda': 0.5947966708608776, 'min_split_gain': 0.6495696336016116, 'subsample': 0.5804705695491061, 'colsample_bytree': 0.5792242040770511, 'subsample_freq': 7, 'min_child_samples': 89, 'min_child_weight': 5.832183719000369, 'boosting_type': 'gbdt', 'n_estimators': 1000}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:23:49,810] Trial 44 finished with value: 0.8427 and parameters: {'learning_rate': 0.010095094958211958, 'num_leaves': 128, 'max_depth': 9, 'reg_alpha': 0.007369820106064486, 'reg_lambda': 0.8297052469605586, 'min_split_gain': 0.7388392252672226, 'subsample': 0.6397199676416861, 'colsample_bytree': 0.6076449222636476, 'subsample_freq': 7, 'min_child_samples': 69, 'min_child_weight': 4.897850738727599, 'boosting_type': 'gbdt', 'n_estimators': 1000}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:24:13,280] Trial 45 finished with value: 0.8418999999999999 and parameters: {'learning_rate': 0.008904522724026814, 'num_leaves': 141, 'max_depth': 6, 'reg_alpha': 0.005719102354627447, 'reg_lambda': 0.540374841457196, 'min_split_gain': 0.8221906431896738, 'subsample': 0.5436917131507377, 'colsample_bytree': 0.5894868826409121, 'subsample_freq': 5, 'min_child_samples': 75, 'min_child_weight': 1.5916124594573149, 'boosting_type': 'gbdt', 'n_estimators': 1050}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:24:31,609] Trial 46 finished with value: 0.8413999999999999 and parameters: {'learning_rate': 0.014056899162435079, 'num_leaves': 120, 'max_depth': 9, 'reg_alpha': 0.026190438942295616, 'reg_lambda': 0.5480970839265061, 'min_split_gain': 0.7116016736052019, 'subsample': 0.5918800586515349, 'colsample_bytree': 0.6381674753083729, 'subsample_freq': 7, 'min_child_samples': 60, 'min_child_weight': 3.736164384072473, 'boosting_type': 'gbdt', 'n_estimators': 1200}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:24:47,642] Trial 47 pruned. \n",
      "[I 2025-11-11 23:24:55,212] Trial 48 pruned. \n",
      "[I 2025-11-11 23:25:21,785] Trial 49 pruned. \n",
      "[I 2025-11-11 23:25:37,620] Trial 50 pruned. \n",
      "\n",
      "[Trial 50] Best so far: 0.8434\n",
      "[I 2025-11-11 23:25:43,750] Trial 51 pruned. \n",
      "[I 2025-11-11 23:25:53,217] Trial 52 pruned. \n",
      "[I 2025-11-11 23:25:59,953] Trial 53 pruned. \n",
      "[I 2025-11-11 23:26:07,889] Trial 54 pruned. \n",
      "[I 2025-11-11 23:26:14,315] Trial 55 pruned. \n",
      "[I 2025-11-11 23:26:22,514] Trial 56 pruned. \n",
      "[I 2025-11-11 23:26:55,493] Trial 57 pruned. \n",
      "[I 2025-11-11 23:27:28,567] Trial 58 finished with value: 0.8431 and parameters: {'learning_rate': 0.008970115802409865, 'num_leaves': 147, 'max_depth': 8, 'reg_alpha': 3.488685829350358, 'reg_lambda': 1.1214779189987614, 'min_split_gain': 0.2883514479928092, 'subsample': 0.6340296609097149, 'colsample_bytree': 0.5753740201263998, 'subsample_freq': 6, 'min_child_samples': 112, 'min_child_weight': 0.9954305077035529, 'boosting_type': 'gbdt', 'n_estimators': 1150}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:27:37,494] Trial 59 pruned. \n",
      "[I 2025-11-11 23:28:02,450] Trial 60 finished with value: 0.8413999999999999 and parameters: {'learning_rate': 0.010026410858610873, 'num_leaves': 127, 'max_depth': 9, 'reg_alpha': 0.3495120014348586, 'reg_lambda': 1.077858056797957, 'min_split_gain': 0.2656321613889164, 'subsample': 0.5548570139076682, 'colsample_bytree': 0.5681490570694862, 'subsample_freq': 7, 'min_child_samples': 104, 'min_child_weight': 0.48135930147026457, 'boosting_type': 'gbdt', 'n_estimators': 1000}. Best is trial 43 with value: 0.8433999999999999.\n",
      "\n",
      "[Trial 60] Best so far: 0.8434\n",
      "[I 2025-11-11 23:28:26,918] Trial 61 finished with value: 0.8421999999999998 and parameters: {'learning_rate': 0.010764784823166531, 'num_leaves': 122, 'max_depth': 8, 'reg_alpha': 0.007375810031994249, 'reg_lambda': 1.61195286888854, 'min_split_gain': 0.9314019530841298, 'subsample': 0.6023097588629942, 'colsample_bytree': 0.5498405212116299, 'subsample_freq': 7, 'min_child_samples': 57, 'min_child_weight': 2.8797875510453, 'boosting_type': 'gbdt', 'n_estimators': 800}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:28:40,080] Trial 62 pruned. \n",
      "[I 2025-11-11 23:29:10,901] Trial 63 pruned. \n",
      "[I 2025-11-11 23:29:19,536] Trial 64 pruned. \n",
      "[I 2025-11-11 23:29:41,112] Trial 65 finished with value: 0.8412 and parameters: {'learning_rate': 0.01053631554287264, 'num_leaves': 126, 'max_depth': 7, 'reg_alpha': 0.012209361080658622, 'reg_lambda': 0.6222388565518432, 'min_split_gain': 0.605870494024012, 'subsample': 0.5601188600808317, 'colsample_bytree': 0.5903354583041244, 'subsample_freq': 7, 'min_child_samples': 71, 'min_child_weight': 1.765900571072273, 'boosting_type': 'gbdt', 'n_estimators': 750}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:29:57,382] Trial 66 pruned. \n",
      "[I 2025-11-11 23:30:08,189] Trial 67 pruned. \n",
      "[I 2025-11-11 23:30:27,084] Trial 68 pruned. \n",
      "[I 2025-11-11 23:30:38,910] Trial 69 pruned. \n",
      "[I 2025-11-11 23:30:45,681] Trial 70 pruned. \n",
      "\n",
      "[Trial 70] Best so far: 0.8434\n",
      "[I 2025-11-11 23:31:02,820] Trial 71 pruned. \n",
      "[I 2025-11-11 23:31:15,692] Trial 72 pruned. \n",
      "[I 2025-11-11 23:31:18,939] Trial 73 pruned. \n",
      "[I 2025-11-11 23:31:24,347] Trial 74 pruned. \n",
      "[I 2025-11-11 23:31:35,317] Trial 75 pruned. \n",
      "[I 2025-11-11 23:32:08,400] Trial 76 pruned. \n",
      "[I 2025-11-11 23:32:24,574] Trial 77 pruned. \n",
      "[I 2025-11-11 23:32:33,267] Trial 78 pruned. \n",
      "[I 2025-11-11 23:32:39,468] Trial 79 pruned. \n",
      "[I 2025-11-11 23:32:49,149] Trial 80 pruned. \n",
      "\n",
      "[Trial 80] Best so far: 0.8434\n",
      "[I 2025-11-11 23:32:54,661] Trial 81 pruned. \n",
      "[I 2025-11-11 23:33:06,291] Trial 82 pruned. \n",
      "[I 2025-11-11 23:33:14,850] Trial 83 pruned. \n",
      "[I 2025-11-11 23:33:38,973] Trial 84 finished with value: 0.8431 and parameters: {'learning_rate': 0.010754823411395569, 'num_leaves': 140, 'max_depth': 7, 'reg_alpha': 0.004280783487112993, 'reg_lambda': 0.6336137712436987, 'min_split_gain': 0.7101590610492736, 'subsample': 0.5986299381555973, 'colsample_bytree': 0.5501957881312514, 'subsample_freq': 6, 'min_child_samples': 97, 'min_child_weight': 8.318081620038674, 'boosting_type': 'gbdt', 'n_estimators': 1000}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:33:48,276] Trial 85 pruned. \n",
      "[I 2025-11-11 23:34:04,074] Trial 86 pruned. \n",
      "[I 2025-11-11 23:34:30,502] Trial 87 finished with value: 0.841 and parameters: {'learning_rate': 0.00973732469299426, 'num_leaves': 91, 'max_depth': 5, 'reg_alpha': 0.14070560010588756, 'reg_lambda': 0.5149076856488608, 'min_split_gain': 0.3253637122814855, 'subsample': 0.7324943641407303, 'colsample_bytree': 0.5679613916605308, 'subsample_freq': 3, 'min_child_samples': 66, 'min_child_weight': 0.001774228754572128, 'boosting_type': 'gbdt', 'n_estimators': 1050}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:34:37,356] Trial 88 pruned. \n",
      "[I 2025-11-11 23:34:46,316] Trial 89 pruned. \n",
      "[I 2025-11-11 23:35:33,962] Trial 90 pruned. \n",
      "\n",
      "[Trial 90] Best so far: 0.8434\n",
      "[I 2025-11-11 23:35:55,967] Trial 91 finished with value: 0.8427999999999999 and parameters: {'learning_rate': 0.01276160115405181, 'num_leaves': 87, 'max_depth': 6, 'reg_alpha': 0.04699228418203867, 'reg_lambda': 2.513873500627705, 'min_split_gain': 0.26788397077435316, 'subsample': 0.79178169045746, 'colsample_bytree': 0.5088397156853705, 'subsample_freq': 1, 'min_child_samples': 75, 'min_child_weight': 0.005394692476787338, 'boosting_type': 'gbdt', 'n_estimators': 800}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:36:05,638] Trial 92 pruned. \n",
      "[I 2025-11-11 23:36:14,883] Trial 93 pruned. \n",
      "[I 2025-11-11 23:36:28,310] Trial 94 pruned. \n",
      "[I 2025-11-11 23:36:39,602] Trial 95 pruned. \n",
      "[I 2025-11-11 23:36:49,867] Trial 96 pruned. \n",
      "[I 2025-11-11 23:37:08,227] Trial 97 pruned. \n",
      "[I 2025-11-11 23:37:14,517] Trial 98 pruned. \n",
      "[I 2025-11-11 23:37:44,606] Trial 99 pruned. \n",
      "[I 2025-11-11 23:37:58,362] Trial 100 pruned. \n",
      "\n",
      "[Trial 100] Best so far: 0.8434\n",
      "[I 2025-11-11 23:38:06,810] Trial 101 pruned. \n",
      "[I 2025-11-11 23:38:21,055] Trial 102 pruned. \n",
      "[I 2025-11-11 23:38:36,924] Trial 103 pruned. \n",
      "[I 2025-11-11 23:38:48,535] Trial 104 pruned. \n",
      "[I 2025-11-11 23:39:21,619] Trial 105 pruned. \n",
      "[I 2025-11-11 23:40:04,901] Trial 106 pruned. \n",
      "[I 2025-11-11 23:40:17,580] Trial 107 pruned. \n",
      "[I 2025-11-11 23:40:26,304] Trial 108 pruned. \n",
      "[I 2025-11-11 23:40:36,143] Trial 109 pruned. \n",
      "[I 2025-11-11 23:40:55,364] Trial 110 finished with value: 0.8421 and parameters: {'learning_rate': 0.011642410754776853, 'num_leaves': 120, 'max_depth': 7, 'reg_alpha': 0.05773772404707386, 'reg_lambda': 2.0315660267556335, 'min_split_gain': 0.9627847188984455, 'subsample': 0.6609571194101872, 'colsample_bytree': 0.6068744831587087, 'subsample_freq': 7, 'min_child_samples': 47, 'min_child_weight': 6.985398490025576, 'boosting_type': 'gbdt', 'n_estimators': 900}. Best is trial 43 with value: 0.8433999999999999.\n",
      "\n",
      "[Trial 110] Best so far: 0.8434\n",
      "[I 2025-11-11 23:41:03,880] Trial 111 pruned. \n",
      "[I 2025-11-11 23:41:11,744] Trial 112 pruned. \n",
      "[I 2025-11-11 23:41:17,665] Trial 113 pruned. \n",
      "[I 2025-11-11 23:41:36,060] Trial 114 finished with value: 0.8423 and parameters: {'learning_rate': 0.010860775480838298, 'num_leaves': 144, 'max_depth': 6, 'reg_alpha': 0.04897778772496928, 'reg_lambda': 4.882675458688318, 'min_split_gain': 0.9687328473292822, 'subsample': 0.573227001100602, 'colsample_bytree': 0.6193049706767385, 'subsample_freq': 5, 'min_child_samples': 42, 'min_child_weight': 0.9425675520755697, 'boosting_type': 'gbdt', 'n_estimators': 950}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:41:58,679] Trial 115 pruned. \n",
      "[I 2025-11-11 23:42:09,490] Trial 116 pruned. \n",
      "[I 2025-11-11 23:42:19,765] Trial 117 pruned. \n",
      "[I 2025-11-11 23:42:36,676] Trial 118 pruned. \n",
      "[I 2025-11-11 23:42:50,328] Trial 119 pruned. \n",
      "[I 2025-11-11 23:42:58,536] Trial 120 pruned. \n",
      "\n",
      "[Trial 120] Best so far: 0.8434\n",
      "[I 2025-11-11 23:43:03,894] Trial 121 pruned. \n",
      "[I 2025-11-11 23:43:09,876] Trial 122 pruned. \n",
      "[I 2025-11-11 23:43:49,955] Trial 123 pruned. \n",
      "[I 2025-11-11 23:43:58,289] Trial 124 pruned. \n",
      "[I 2025-11-11 23:44:07,508] Trial 125 pruned. \n",
      "[I 2025-11-11 23:44:25,160] Trial 126 pruned. \n",
      "[I 2025-11-11 23:44:33,531] Trial 127 pruned. \n",
      "[I 2025-11-11 23:44:47,005] Trial 128 pruned. \n",
      "[I 2025-11-11 23:44:55,962] Trial 129 pruned. \n",
      "[I 2025-11-11 23:45:08,569] Trial 130 pruned. \n",
      "\n",
      "[Trial 130] Best so far: 0.8434\n",
      "[I 2025-11-11 23:45:28,877] Trial 131 finished with value: 0.8421 and parameters: {'learning_rate': 0.009925815842939658, 'num_leaves': 126, 'max_depth': 9, 'reg_alpha': 1.113551667546573, 'reg_lambda': 1.2383813257938217, 'min_split_gain': 0.4016775887301881, 'subsample': 0.6382507017581013, 'colsample_bytree': 0.6422084297685533, 'subsample_freq': 4, 'min_child_samples': 116, 'min_child_weight': 0.6877084937148406, 'boosting_type': 'gbdt', 'n_estimators': 1100}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:45:35,066] Trial 132 pruned. \n",
      "[I 2025-11-11 23:45:51,005] Trial 133 finished with value: 0.8421 and parameters: {'learning_rate': 0.008446069696308326, 'num_leaves': 146, 'max_depth': 10, 'reg_alpha': 2.2015980916724933, 'reg_lambda': 0.7173181828862524, 'min_split_gain': 0.18788534897322204, 'subsample': 0.5434869241329056, 'colsample_bytree': 0.6308478231030021, 'subsample_freq': 4, 'min_child_samples': 105, 'min_child_weight': 3.1118228995769126, 'boosting_type': 'gbdt', 'n_estimators': 1200}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:45:56,539] Trial 134 pruned. \n",
      "[I 2025-11-11 23:46:06,909] Trial 135 pruned. \n",
      "[I 2025-11-11 23:46:13,788] Trial 136 pruned. \n",
      "[I 2025-11-11 23:46:21,661] Trial 137 finished with value: 0.8429 and parameters: {'learning_rate': 0.02313740613691794, 'num_leaves': 106, 'max_depth': 9, 'reg_alpha': 0.0037323570297380965, 'reg_lambda': 4.088536271499487, 'min_split_gain': 0.9304436155093644, 'subsample': 0.6438266123430634, 'colsample_bytree': 0.606065746768639, 'subsample_freq': 2, 'min_child_samples': 68, 'min_child_weight': 1.6437049552216245, 'boosting_type': 'gbdt', 'n_estimators': 800}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:46:59,590] Trial 138 pruned. \n",
      "[I 2025-11-11 23:47:05,241] Trial 139 pruned. \n",
      "[I 2025-11-11 23:47:08,775] Trial 140 pruned. \n",
      "\n",
      "[Trial 140] Best so far: 0.8434\n",
      "[I 2025-11-11 23:47:13,886] Trial 141 pruned. \n",
      "[I 2025-11-11 23:47:19,810] Trial 142 pruned. \n",
      "[I 2025-11-11 23:47:25,658] Trial 143 pruned. \n",
      "[I 2025-11-11 23:47:30,684] Trial 144 pruned. \n",
      "[I 2025-11-11 23:47:47,569] Trial 145 finished with value: 0.8429 and parameters: {'learning_rate': 0.008192916860312595, 'num_leaves': 134, 'max_depth': 8, 'reg_alpha': 0.007234758641146532, 'reg_lambda': 1.0745154217237711, 'min_split_gain': 0.5500750859748537, 'subsample': 0.5913128147022795, 'colsample_bytree': 0.5351509513209379, 'subsample_freq': 7, 'min_child_samples': 97, 'min_child_weight': 7.690000704713097, 'boosting_type': 'gbdt', 'n_estimators': 1050}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:48:06,231] Trial 146 finished with value: 0.8416 and parameters: {'learning_rate': 0.009127239175042176, 'num_leaves': 123, 'max_depth': 9, 'reg_alpha': 0.005736136981602185, 'reg_lambda': 2.1907637488680187, 'min_split_gain': 0.40708413054737114, 'subsample': 0.6048445141510548, 'colsample_bytree': 0.5172963787754349, 'subsample_freq': 7, 'min_child_samples': 78, 'min_child_weight': 4.499018647858057, 'boosting_type': 'gbdt', 'n_estimators': 950}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:48:13,233] Trial 147 pruned. \n",
      "[I 2025-11-11 23:48:16,264] Trial 148 pruned. \n",
      "[I 2025-11-11 23:48:22,916] Trial 149 pruned. \n",
      "[I 2025-11-11 23:48:37,606] Trial 150 finished with value: 0.8426 and parameters: {'learning_rate': 0.008029744397698248, 'num_leaves': 135, 'max_depth': 6, 'reg_alpha': 0.033581067008307014, 'reg_lambda': 1.2733116531686204, 'min_split_gain': 0.613876440798461, 'subsample': 0.6967053866302394, 'colsample_bytree': 0.5282563353155822, 'subsample_freq': 5, 'min_child_samples': 113, 'min_child_weight': 7.845354096937072, 'boosting_type': 'gbdt', 'n_estimators': 1200}. Best is trial 43 with value: 0.8433999999999999.\n",
      "\n",
      "[Trial 150] Best so far: 0.8434\n",
      "[I 2025-11-11 23:48:47,827] Trial 151 pruned. \n",
      "[I 2025-11-11 23:48:53,926] Trial 152 pruned. \n",
      "[I 2025-11-11 23:48:58,274] Trial 153 pruned. \n",
      "[I 2025-11-11 23:49:05,866] Trial 154 pruned. \n",
      "[I 2025-11-11 23:49:12,416] Trial 155 pruned. \n",
      "[I 2025-11-11 23:49:17,174] Trial 156 pruned. \n",
      "[I 2025-11-11 23:49:26,213] Trial 157 pruned. \n",
      "[I 2025-11-11 23:49:33,965] Trial 158 pruned. \n",
      "[I 2025-11-11 23:49:40,166] Trial 159 pruned. \n",
      "[I 2025-11-11 23:49:48,038] Trial 160 pruned. \n",
      "\n",
      "[Trial 160] Best so far: 0.8434\n",
      "[I 2025-11-11 23:49:55,038] Trial 161 pruned. \n",
      "[I 2025-11-11 23:50:05,063] Trial 162 pruned. \n",
      "[I 2025-11-11 23:50:14,886] Trial 163 pruned. \n",
      "[I 2025-11-11 23:50:20,825] Trial 164 pruned. \n",
      "[I 2025-11-11 23:50:28,972] Trial 165 finished with value: 0.8417 and parameters: {'learning_rate': 0.02040563331042467, 'num_leaves': 101, 'max_depth': 8, 'reg_alpha': 0.0006174695552824395, 'reg_lambda': 3.865406456296151, 'min_split_gain': 0.9893394800039361, 'subsample': 0.6717702273323579, 'colsample_bytree': 0.638473263826829, 'subsample_freq': 1, 'min_child_samples': 58, 'min_child_weight': 2.4385804040153873, 'boosting_type': 'gbdt', 'n_estimators': 850}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:50:38,826] Trial 166 pruned. \n",
      "[I 2025-11-11 23:50:53,195] Trial 167 pruned. \n",
      "[I 2025-11-11 23:50:59,505] Trial 168 pruned. \n",
      "[I 2025-11-11 23:51:05,078] Trial 169 pruned. \n",
      "[I 2025-11-11 23:51:18,198] Trial 170 finished with value: 0.8404999999999999 and parameters: {'learning_rate': 0.020781141815036118, 'num_leaves': 85, 'max_depth': 10, 'reg_alpha': 0.008882390186733558, 'reg_lambda': 5.826913737476455, 'min_split_gain': 0.7656427186205712, 'subsample': 0.5989370774971501, 'colsample_bytree': 0.5587140341466574, 'subsample_freq': 4, 'min_child_samples': 73, 'min_child_weight': 2.0352473682827337, 'boosting_type': 'gbdt', 'n_estimators': 950}. Best is trial 43 with value: 0.8433999999999999.\n",
      "\n",
      "[Trial 170] Best so far: 0.8434\n",
      "[I 2025-11-11 23:51:39,636] Trial 171 pruned. \n",
      "[I 2025-11-11 23:51:44,892] Trial 172 pruned. \n",
      "[I 2025-11-11 23:51:54,391] Trial 173 pruned. \n",
      "[I 2025-11-11 23:52:03,852] Trial 174 pruned. \n",
      "[I 2025-11-11 23:52:13,218] Trial 175 pruned. \n",
      "[I 2025-11-11 23:52:36,177] Trial 176 pruned. \n",
      "[I 2025-11-11 23:52:41,087] Trial 177 pruned. \n",
      "[I 2025-11-11 23:52:51,093] Trial 178 pruned. \n",
      "[I 2025-11-11 23:53:02,343] Trial 179 finished with value: 0.8432999999999999 and parameters: {'learning_rate': 0.014725019014769037, 'num_leaves': 95, 'max_depth': 5, 'reg_alpha': 0.48774207582915724, 'reg_lambda': 1.4340395280533742, 'min_split_gain': 0.2762521533716651, 'subsample': 0.8152274491606758, 'colsample_bytree': 0.5159928528383985, 'subsample_freq': 1, 'min_child_samples': 68, 'min_child_weight': 0.019514386413965877, 'boosting_type': 'gbdt', 'n_estimators': 700}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:53:05,884] Trial 180 pruned. \n",
      "\n",
      "[Trial 180] Best so far: 0.8434\n",
      "[I 2025-11-11 23:53:11,551] Trial 181 pruned. \n",
      "[I 2025-11-11 23:53:15,458] Trial 182 pruned. \n",
      "[I 2025-11-11 23:53:30,913] Trial 183 finished with value: 0.8416 and parameters: {'learning_rate': 0.011539426459388316, 'num_leaves': 132, 'max_depth': 8, 'reg_alpha': 0.018290003315496635, 'reg_lambda': 1.2989260179501014, 'min_split_gain': 0.9455489804711861, 'subsample': 0.6238607002976434, 'colsample_bytree': 0.522864659252297, 'subsample_freq': 5, 'min_child_samples': 74, 'min_child_weight': 6.492472286467124, 'boosting_type': 'gbdt', 'n_estimators': 1050}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:53:36,162] Trial 184 pruned. \n",
      "[I 2025-11-11 23:53:39,339] Trial 185 pruned. \n",
      "[I 2025-11-11 23:53:44,510] Trial 186 pruned. \n",
      "[I 2025-11-11 23:53:48,001] Trial 187 pruned. \n",
      "[I 2025-11-11 23:53:53,467] Trial 188 pruned. \n",
      "[I 2025-11-11 23:53:59,459] Trial 189 pruned. \n",
      "[I 2025-11-11 23:54:08,263] Trial 190 pruned. \n",
      "\n",
      "[Trial 190] Best so far: 0.8434\n",
      "[I 2025-11-11 23:54:22,632] Trial 191 pruned. \n",
      "[I 2025-11-11 23:54:26,672] Trial 192 pruned. \n",
      "[I 2025-11-11 23:54:32,359] Trial 193 pruned. \n",
      "[I 2025-11-11 23:54:49,291] Trial 194 pruned. \n",
      "[I 2025-11-11 23:54:58,543] Trial 195 pruned. \n",
      "[I 2025-11-11 23:55:05,007] Trial 196 pruned. \n",
      "[I 2025-11-11 23:55:14,027] Trial 197 pruned. \n",
      "[I 2025-11-11 23:55:17,042] Trial 198 pruned. \n",
      "[I 2025-11-11 23:55:23,525] Trial 199 pruned. \n",
      "[I 2025-11-11 23:55:30,599] Trial 200 pruned. \n",
      "\n",
      "[Trial 200] Best so far: 0.8434\n",
      "[I 2025-11-11 23:55:50,844] Trial 201 finished with value: 0.8412000000000001 and parameters: {'learning_rate': 0.008079143079102524, 'num_leaves': 143, 'max_depth': 8, 'reg_alpha': 0.010190443240287459, 'reg_lambda': 0.5516592045256673, 'min_split_gain': 0.8179973826095045, 'subsample': 0.6132902853649435, 'colsample_bytree': 0.6052023649705551, 'subsample_freq': 4, 'min_child_samples': 64, 'min_child_weight': 0.11423962909881127, 'boosting_type': 'gbdt', 'n_estimators': 850}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:55:55,649] Trial 202 pruned. \n",
      "[I 2025-11-11 23:56:02,753] Trial 203 pruned. \n",
      "[I 2025-11-11 23:56:10,167] Trial 204 pruned. \n",
      "[I 2025-11-11 23:56:28,104] Trial 205 finished with value: 0.8417999999999999 and parameters: {'learning_rate': 0.010327618104509443, 'num_leaves': 138, 'max_depth': 6, 'reg_alpha': 0.1577899983165561, 'reg_lambda': 4.973869552521665, 'min_split_gain': 0.9947988458555963, 'subsample': 0.5516162255333393, 'colsample_bytree': 0.5349470114125372, 'subsample_freq': 5, 'min_child_samples': 54, 'min_child_weight': 9.469906902341016, 'boosting_type': 'gbdt', 'n_estimators': 1150}. Best is trial 43 with value: 0.8433999999999999.\n",
      "[I 2025-11-11 23:56:33,112] Trial 206 pruned. \n",
      "[I 2025-11-11 23:56:38,167] Trial 207 pruned. \n",
      "[I 2025-11-11 23:56:57,844] Trial 208 pruned. \n",
      "[I 2025-11-11 23:57:05,913] Trial 209 pruned. \n",
      "[I 2025-11-11 23:57:27,117] Trial 210 pruned. \n",
      "\n",
      "[Trial 210] Best so far: 0.8434\n",
      "[I 2025-11-11 23:57:34,618] Trial 211 pruned. \n",
      "[I 2025-11-11 23:57:38,576] Trial 212 pruned. \n",
      "[I 2025-11-11 23:57:45,402] Trial 213 pruned. \n",
      "[I 2025-11-11 23:58:11,638] Trial 214 pruned. \n",
      "[I 2025-11-11 23:58:16,958] Trial 215 pruned. \n",
      "[I 2025-11-11 23:58:22,700] Trial 216 pruned. \n",
      "[I 2025-11-11 23:58:29,283] Trial 217 pruned. \n",
      "[I 2025-11-11 23:58:33,042] Trial 218 pruned. \n",
      "[I 2025-11-11 23:58:39,367] Trial 219 pruned. \n",
      "[I 2025-11-11 23:58:49,666] Trial 220 pruned. \n",
      "\n",
      "[Trial 220] Best so far: 0.8434\n",
      "[I 2025-11-11 23:59:01,730] Trial 221 finished with value: 0.8434000000000001 and parameters: {'learning_rate': 0.01993861963281415, 'num_leaves': 99, 'max_depth': 7, 'reg_alpha': 0.0009180810356660023, 'reg_lambda': 5.132232560736075, 'min_split_gain': 0.9902670309959428, 'subsample': 0.621860889889483, 'colsample_bytree': 0.5561932660996566, 'subsample_freq': 2, 'min_child_samples': 63, 'min_child_weight': 5.044889356294674, 'boosting_type': 'gbdt', 'n_estimators': 700}. Best is trial 221 with value: 0.8434000000000001.\n",
      "[I 2025-11-11 23:59:11,274] Trial 222 pruned. \n",
      "[I 2025-11-11 23:59:16,603] Trial 223 pruned. \n",
      "[I 2025-11-11 23:59:22,783] Trial 224 pruned. \n",
      "[I 2025-11-11 23:59:28,597] Trial 225 pruned. \n",
      "[I 2025-11-11 23:59:35,936] Trial 226 pruned. \n",
      "[I 2025-11-11 23:59:47,356] Trial 227 pruned. \n",
      "[I 2025-11-11 23:59:58,119] Trial 228 finished with value: 0.8409999999999999 and parameters: {'learning_rate': 0.011198500170922117, 'num_leaves': 119, 'max_depth': 7, 'reg_alpha': 0.009776419910799796, 'reg_lambda': 0.5042791674874163, 'min_split_gain': 0.6211579555648684, 'subsample': 0.5246622874210964, 'colsample_bytree': 0.6480141171740271, 'subsample_freq': 5, 'min_child_samples': 82, 'min_child_weight': 0.13952586649055, 'boosting_type': 'gbdt', 'n_estimators': 1100}. Best is trial 221 with value: 0.8434000000000001.\n",
      "[I 2025-11-12 00:00:03,757] Trial 229 pruned. \n",
      "[I 2025-11-12 00:00:07,028] Trial 230 pruned. \n",
      "\n",
      "[Trial 230] Best so far: 0.8434\n",
      "[I 2025-11-12 00:00:11,929] Trial 231 pruned. \n",
      "[I 2025-11-12 00:00:17,305] Trial 232 pruned. \n",
      "[I 2025-11-12 00:00:25,439] Trial 233 pruned. \n",
      "[I 2025-11-12 00:00:30,805] Trial 234 pruned. \n",
      "[I 2025-11-12 00:00:34,179] Trial 235 pruned. \n",
      "[I 2025-11-12 00:00:38,494] Trial 236 pruned. \n",
      "[I 2025-11-12 00:00:41,499] Trial 237 pruned. \n",
      "[I 2025-11-12 00:00:50,487] Trial 238 pruned. \n",
      "[I 2025-11-12 00:00:55,166] Trial 239 pruned. \n",
      "[I 2025-11-12 00:01:07,913] Trial 240 finished with value: 0.8432999999999999 and parameters: {'learning_rate': 0.01724934057553785, 'num_leaves': 90, 'max_depth': 7, 'reg_alpha': 0.0001330898498794814, 'reg_lambda': 6.186290740177439, 'min_split_gain': 0.7875402293061537, 'subsample': 0.6666665246644498, 'colsample_bytree': 0.5257309223969031, 'subsample_freq': 3, 'min_child_samples': 67, 'min_child_weight': 2.4186040237864455, 'boosting_type': 'gbdt', 'n_estimators': 550}. Best is trial 221 with value: 0.8434000000000001.\n",
      "\n",
      "[Trial 240] Best so far: 0.8434\n",
      "[I 2025-11-12 00:01:15,287] Trial 241 pruned. \n",
      "[I 2025-11-12 00:01:18,521] Trial 242 pruned. \n",
      "[I 2025-11-12 00:01:25,215] Trial 243 pruned. \n",
      "[I 2025-11-12 00:01:35,007] Trial 244 finished with value: 0.8442999999999999 and parameters: {'learning_rate': 0.01847769478400091, 'num_leaves': 103, 'max_depth': 7, 'reg_alpha': 0.0016618701008092077, 'reg_lambda': 4.228975028385842, 'min_split_gain': 0.9362627619622258, 'subsample': 0.6579559174378966, 'colsample_bytree': 0.743522961631095, 'subsample_freq': 1, 'min_child_samples': 63, 'min_child_weight': 0.26994900026670493, 'boosting_type': 'gbdt', 'n_estimators': 750}. Best is trial 244 with value: 0.8442999999999999.\n",
      "[I 2025-11-12 00:01:38,056] Trial 245 pruned. \n",
      "[I 2025-11-12 00:01:41,961] Trial 246 pruned. \n",
      "[I 2025-11-12 00:01:45,468] Trial 247 pruned. \n",
      "[I 2025-11-12 00:01:48,464] Trial 248 pruned. \n",
      "[I 2025-11-12 00:01:55,687] Trial 249 pruned. \n",
      "[I 2025-11-12 00:02:04,657] Trial 250 pruned. \n",
      "\n",
      "[Trial 250] Best so far: 0.8443\n",
      "[I 2025-11-12 00:02:24,644] Trial 251 finished with value: 0.8428000000000001 and parameters: {'learning_rate': 0.009094679854780413, 'num_leaves': 128, 'max_depth': 5, 'reg_alpha': 0.0887101921634221, 'reg_lambda': 3.7762920015367913, 'min_split_gain': 0.9485350984283998, 'subsample': 0.5015358274207588, 'colsample_bytree': 0.5544885946901268, 'subsample_freq': 6, 'min_child_samples': 53, 'min_child_weight': 2.8929954262986666, 'boosting_type': 'gbdt', 'n_estimators': 1100}. Best is trial 244 with value: 0.8442999999999999.\n",
      "[I 2025-11-12 00:02:44,131] Trial 252 pruned. \n",
      "[I 2025-11-12 00:03:08,829] Trial 253 pruned. \n",
      "[I 2025-11-12 00:03:16,599] Trial 254 pruned. \n",
      "[I 2025-11-12 00:03:26,321] Trial 255 finished with value: 0.842 and parameters: {'learning_rate': 0.01622660325472336, 'num_leaves': 98, 'max_depth': 6, 'reg_alpha': 0.00041822022650809626, 'reg_lambda': 4.494071705497191, 'min_split_gain': 0.9760500224427774, 'subsample': 0.5196302291693742, 'colsample_bytree': 0.5920697748450285, 'subsample_freq': 1, 'min_child_samples': 65, 'min_child_weight': 1.7557352218895055, 'boosting_type': 'gbdt', 'n_estimators': 750}. Best is trial 244 with value: 0.8442999999999999.\n",
      "[I 2025-11-12 00:03:28,526] Trial 256 pruned. \n",
      "[I 2025-11-12 00:03:32,266] Trial 257 pruned. \n",
      "[I 2025-11-12 00:03:37,219] Trial 258 pruned. \n",
      "[I 2025-11-12 00:03:40,271] Trial 259 pruned. \n",
      "[I 2025-11-12 00:03:45,105] Trial 260 pruned. \n",
      "\n",
      "[Trial 260] Best so far: 0.8443\n",
      "[I 2025-11-12 00:03:53,538] Trial 261 pruned. \n",
      "[I 2025-11-12 00:03:58,047] Trial 262 pruned. \n",
      "[I 2025-11-12 00:04:02,745] Trial 263 pruned. \n",
      "[I 2025-11-12 00:04:05,317] Trial 264 pruned. \n",
      "[I 2025-11-12 00:04:11,146] Trial 265 pruned. \n",
      "[I 2025-11-12 00:04:15,042] Trial 266 pruned. \n",
      "[I 2025-11-12 00:04:18,292] Trial 267 pruned. \n",
      "[I 2025-11-12 00:04:24,244] Trial 268 pruned. \n",
      "[I 2025-11-12 00:04:27,618] Trial 269 pruned. \n",
      "[I 2025-11-12 00:04:34,207] Trial 270 pruned. \n",
      "\n",
      "[Trial 270] Best so far: 0.8443\n",
      "[I 2025-11-12 00:04:38,958] Trial 271 pruned. \n",
      "[I 2025-11-12 00:04:51,049] Trial 272 finished with value: 0.8415000000000001 and parameters: {'learning_rate': 0.015194289794633728, 'num_leaves': 112, 'max_depth': 6, 'reg_alpha': 0.00023250952982953733, 'reg_lambda': 6.269714946313296, 'min_split_gain': 0.914845212348572, 'subsample': 0.6647652922527847, 'colsample_bytree': 0.7887267261410288, 'subsample_freq': 1, 'min_child_samples': 41, 'min_child_weight': 0.1423675117486078, 'boosting_type': 'gbdt', 'n_estimators': 850}. Best is trial 244 with value: 0.8442999999999999.\n",
      "[I 2025-11-12 00:04:55,363] Trial 273 pruned. \n",
      "[I 2025-11-12 00:04:59,074] Trial 274 pruned. \n",
      "[I 2025-11-12 00:05:04,707] Trial 275 pruned. \n",
      "[I 2025-11-12 00:05:10,256] Trial 276 pruned. \n",
      "[I 2025-11-12 00:05:14,214] Trial 277 pruned. \n",
      "[I 2025-11-12 00:05:22,481] Trial 278 finished with value: 0.8426 and parameters: {'learning_rate': 0.019745116907373197, 'num_leaves': 100, 'max_depth': 7, 'reg_alpha': 0.0001932897425339411, 'reg_lambda': 4.071780919811489, 'min_split_gain': 0.9031863533185776, 'subsample': 0.7753236736141496, 'colsample_bytree': 0.6501436617061944, 'subsample_freq': 1, 'min_child_samples': 51, 'min_child_weight': 0.002120581371804554, 'boosting_type': 'gbdt', 'n_estimators': 850}. Best is trial 244 with value: 0.8442999999999999.\n",
      "[I 2025-11-12 00:05:26,134] Trial 279 pruned. \n",
      "[I 2025-11-12 00:05:30,957] Trial 280 pruned. \n",
      "\n",
      "[Trial 280] Best so far: 0.8443\n",
      "[I 2025-11-12 00:05:35,687] Trial 281 pruned. \n",
      "[I 2025-11-12 00:05:38,931] Trial 282 pruned. \n",
      "[I 2025-11-12 00:05:43,217] Trial 283 pruned. \n",
      "[I 2025-11-12 00:05:47,820] Trial 284 pruned. \n",
      "[I 2025-11-12 00:05:52,382] Trial 285 pruned. \n",
      "[I 2025-11-12 00:05:56,625] Trial 286 pruned. \n",
      "[I 2025-11-12 00:06:19,572] Trial 287 pruned. \n",
      "[I 2025-11-12 00:06:23,747] Trial 288 pruned. \n",
      "[I 2025-11-12 00:06:32,012] Trial 289 pruned. \n",
      "[I 2025-11-12 00:06:39,464] Trial 290 pruned. \n",
      "\n",
      "[Trial 290] Best so far: 0.8443\n",
      "[I 2025-11-12 00:06:44,625] Trial 291 pruned. \n",
      "[I 2025-11-12 00:06:53,574] Trial 292 pruned. \n",
      "[I 2025-11-12 00:07:06,213] Trial 293 pruned. \n",
      "[I 2025-11-12 00:07:12,452] Trial 294 pruned. \n",
      "[I 2025-11-12 00:07:24,003] Trial 295 pruned. \n",
      "[I 2025-11-12 00:07:29,315] Trial 296 pruned. \n",
      "[I 2025-11-12 00:07:39,791] Trial 297 pruned. \n",
      "[I 2025-11-12 00:07:46,208] Trial 298 pruned. \n",
      "[I 2025-11-12 00:07:51,457] Trial 299 pruned. \n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š RISULTATI OTTIMIZZAZIONE\n",
      "================================================================================\n",
      "\n",
      "ðŸ† BEST TRIAL: #244\n",
      "   â€¢ Accuracy (CV media): 0.8443\n",
      "   â€¢ Std Accuracy: 0.0048\n",
      "   â€¢ Mean Best Iteration: 520\n",
      "\n",
      "ðŸ“ˆ MIGLIORAMENTO vs BASELINE:\n",
      "   â€¢ Baseline: 0.7900\n",
      "   â€¢ Nuovo: 0.8443\n",
      "   â€¢ Delta: +5.43%\n",
      "\n",
      "ðŸ”§ MIGLIORI PARAMETRI:\n",
      "   â€¢ learning_rate       : 0.018478  (baseline: 0.013679823261876542)\n",
      "   â€¢ num_leaves          : 103  (baseline: 97)\n",
      "   â€¢ max_depth           : 7  (baseline: 7)\n",
      "   â€¢ reg_alpha           : 0.001662  (baseline: 2.261339389106705e-06)\n",
      "   â€¢ reg_lambda          : 4.228975  (baseline: 1.8764227095178463)\n",
      "   â€¢ min_split_gain      : 0.936263  (baseline: 0.3554832229238166)\n",
      "   â€¢ subsample           : 0.657956  (baseline: 0.6161988793364829)\n",
      "   â€¢ colsample_bytree    : 0.743523  (baseline: 0.6136973726187104)\n",
      "   â€¢ subsample_freq      : 1  (baseline: 4)\n",
      "   â€¢ min_child_samples   : 63  (baseline: 70)\n",
      "   â€¢ min_child_weight    : 0.269949  (baseline: N/A)\n",
      "   â€¢ boosting_type       : gbdt  (baseline: N/A)\n",
      "   â€¢ n_estimators        : 750  (baseline: 650)\n",
      "\n",
      "ðŸ¥‡ TOP 5 TRIALS:\n",
      "   1. Trial #118: 0.8485 (std=0.0000)\n",
      "   2. Trial #119: 0.8485 (std=0.0000)\n",
      "   3. Trial #126: 0.8485 (std=0.0000)\n",
      "   4. Trial #149: 0.8485 (std=0.0000)\n",
      "   5. Trial #157: 0.8485 (std=0.0000)\n",
      "\n",
      "ðŸ’¾ Parametri salvati in `best_params_new`\n",
      "\n",
      "ðŸ“Š Generazione grafici interattivi...\n",
      "\n",
      "âš ï¸ Plotly non installato, grafici non generati (pip install plotly)\n",
      "================================================================================\n",
      "âœ… OTTIMIZZAZIONE COMPLETATA\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ Variabili disponibili:\n",
      "   â€¢ best_params_new  â†’ Usa in Cross-Validation\n",
      "   â€¢ study            â†’ Oggetto Optuna per analisi\n",
      "   â€¢ BASELINE_PARAMS  â†’ Parametri precedenti per confronto\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# ðŸ”¬ OPTUNA ADVANCED OPTIMIZATION - MULTI-STRATEGY\n",
    "# ================================================================================\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ OPTUNA ADVANCED HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ================================================================================\n",
    "# 1ï¸âƒ£ CONFIGURAZIONE AVANZATA\n",
    "# ================================================================================\n",
    "\n",
    "# Baseline attuali (per confronto)\n",
    "BASELINE_PARAMS = {\n",
    "    'learning_rate': 0.013679823261876542,\n",
    "    'n_estimators': 650,\n",
    "    'num_leaves': 97,\n",
    "    'max_depth': 7,\n",
    "    'min_child_samples': 70,\n",
    "    'subsample': 0.6161988793364829,\n",
    "    'subsample_freq': 4,\n",
    "    'colsample_bytree': 0.6136973726187104,\n",
    "    'reg_alpha': 2.261339389106705e-06,\n",
    "    'reg_lambda': 1.8764227095178463,\n",
    "    'min_split_gain': 0.3554832229238166\n",
    "}\n",
    "\n",
    "# Configurazione ottimizzazione\n",
    "CONFIG = {\n",
    "    'n_trials': 300,              # â† Aumenta da 150 a 300 per esplorazione piÃ¹ profonda\n",
    "    'timeout': 10800,             # â† 3 ore (aumenta se possibile)\n",
    "    'cv_folds': 5,                # â† Mantieni 5 per bilanciare accuratezza/velocitÃ \n",
    "    'early_stopping': 50,         # â† Early stopping piÃ¹ paziente\n",
    "    'n_startup_trials': 30,       # â† Esplorazione iniziale casuale (prima di TPE)\n",
    "    'use_stratified_cv': True,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“Š Configurazione:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"   â€¢ {k}: {v}\")\n",
    "\n",
    "# ================================================================================\n",
    "# 2ï¸âƒ£ FUNZIONE OBIETTIVO CON SEARCH SPACE OTTIMIZZATO\n",
    "# ================================================================================\n",
    "\n",
    "def objective_v2(trial):\n",
    "    \"\"\"\n",
    "    Funzione obiettivo migliorata con:\n",
    "    - Search space ristretto attorno ai best params\n",
    "    - Focus su learning_rate, regularization e tree structure\n",
    "    - Pruning intelligente\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- STRATEGIA 1: Search Space Ristretto (Fine-Tuning) ---\n",
    "    # Centra la ricerca attorno ai parametri attuali con range piÃ¹ stretti\n",
    "    \n",
    "    # Learning Rate: esplora valori vicini con piÃ¹ granularitÃ \n",
    "    lr = trial.suggest_float('learning_rate', 0.008, 0.025, log=True)\n",
    "    \n",
    "    # Tree Structure: test configurazioni piÃ¹ complesse E piÃ¹ semplici\n",
    "    num_leaves = trial.suggest_int('num_leaves', 70, 150)  # Da 97 Â± range\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)      # Da 7 Â± range\n",
    "    \n",
    "    # Regularization: esplora regolarizzazione piÃ¹ forte\n",
    "    # I tuoi valori sono MOLTO bassi (reg_alpha ~2e-6), prova range piÃ¹ alto\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 1e-4, 5.0, log=True)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0.5, 10.0, log=True)\n",
    "    min_split_gain = trial.suggest_float('min_split_gain', 0.1, 1.0)\n",
    "    \n",
    "    # Sampling: ottimizza subsample per ridurre overfitting\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 0.85)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.85)\n",
    "    subsample_freq = trial.suggest_int('subsample_freq', 1, 7)\n",
    "    \n",
    "    # Tree Constraints: aggiungi nuovi parametri critici\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 40, 120)\n",
    "    min_child_weight = trial.suggest_float('min_child_weight', 1e-3, 10.0, log=True)\n",
    "    \n",
    "    # Boosting: esplora dart per ridurre overfitting\n",
    "    boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart'])\n",
    "    \n",
    "    # Se DART, aggiungi parametri specifici\n",
    "    if boosting_type == 'dart':\n",
    "        drop_rate = trial.suggest_float('drop_rate', 0.05, 0.3)\n",
    "        skip_drop = trial.suggest_float('skip_drop', 0.3, 0.7)\n",
    "    else:\n",
    "        drop_rate = 0.1\n",
    "        skip_drop = 0.5\n",
    "    \n",
    "    # --- STRATEGIA 2: N_estimators Adattivo ---\n",
    "    # Invece di fisso, trova il numero ottimale con early stopping\n",
    "    n_estimators = trial.suggest_int('n_estimators', 400, 1200, step=50)\n",
    "    \n",
    "    # --- Assembla Parametri ---\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': boosting_type,\n",
    "        'verbosity': -1,\n",
    "        'seed': CONFIG['random_state'],\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': lr,\n",
    "        'n_estimators': n_estimators,\n",
    "        'num_leaves': num_leaves,\n",
    "        'max_depth': max_depth,\n",
    "        'min_child_samples': min_child_samples,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'subsample': subsample,\n",
    "        'subsample_freq': subsample_freq,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'reg_alpha': reg_alpha,\n",
    "        'reg_lambda': reg_lambda,\n",
    "        'min_split_gain': min_split_gain,\n",
    "    }\n",
    "    \n",
    "    if boosting_type == 'dart':\n",
    "        params['drop_rate'] = drop_rate\n",
    "        params['skip_drop'] = skip_drop\n",
    "    \n",
    "    # --- Cross-Validation con Early Stopping ---\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=CONFIG['cv_folds'], \n",
    "        shuffle=True, \n",
    "        random_state=CONFIG['random_state']\n",
    "    )\n",
    "    \n",
    "    cv_scores = []\n",
    "    best_iterations = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        \n",
    "        # Fit con early stopping\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='binary_logloss',\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=CONFIG['early_stopping'], verbose=False)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Predizioni\n",
    "        preds = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        cv_scores.append(acc)\n",
    "        \n",
    "        # Salva best iteration\n",
    "        if hasattr(model, 'best_iteration_'):\n",
    "            best_iterations.append(model.best_iteration_)\n",
    "        \n",
    "        # --- STRATEGIA 3: Pruning Intelligente per Fold ---\n",
    "        # Se il primo fold Ã¨ molto peggio del baseline, pruna subito\n",
    "        if fold_idx == 0 and acc < 0.78:  # â† Threshold basato sui tuoi risultati\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Report intermedio (per MedianPruner)\n",
    "        trial.report(acc, step=fold_idx)\n",
    "        \n",
    "        # Controlla se Optuna vuole prunare\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    # --- Metriche Finali ---\n",
    "    mean_acc = np.mean(cv_scores)\n",
    "    std_acc = np.std(cv_scores)\n",
    "    mean_iter = np.mean(best_iterations) if best_iterations else n_estimators\n",
    "    \n",
    "    # Salva attributi per analisi successiva\n",
    "    trial.set_user_attr('std_acc', float(std_acc))\n",
    "    trial.set_user_attr('mean_best_iter', float(mean_iter))\n",
    "    trial.set_user_attr('cv_scores', [float(x) for x in cv_scores])\n",
    "    \n",
    "    return mean_acc\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "# 3ï¸âƒ£ CONFIGURAZIONE SAMPLER E PRUNER AVANZATI\n",
    "# ================================================================================\n",
    "\n",
    "# TPE Sampler: algoritmo bayesiano ottimizzato\n",
    "sampler = TPESampler(\n",
    "    n_startup_trials=CONFIG['n_startup_trials'],  # Esplorazione casuale iniziale\n",
    "    n_ei_candidates=24,                           # Candidate per Expected Improvement\n",
    "    seed=CONFIG['random_state'],\n",
    "    multivariate=True,                            # Considera correlazioni tra parametri\n",
    "    group=True,                                   # Raggruppa parametri correlati\n",
    "    constant_liar=True                            # Parallelize-friendly\n",
    ")\n",
    "\n",
    "# MedianPruner: termina trial scadenti prima\n",
    "pruner = MedianPruner(\n",
    "    n_startup_trials=10,   # Non prunare i primi 10 trial (troppo pochi dati)\n",
    "    n_warmup_steps=1,      # Pruna dopo almeno 1 fold\n",
    "    interval_steps=1       # Controlla ad ogni fold\n",
    ")\n",
    "\n",
    "# ================================================================================\n",
    "# 4ï¸âƒ£ ESECUZIONE OTTIMIZZAZIONE\n",
    "# ================================================================================\n",
    "\n",
    "# Crea studio\n",
    "study_name = 'LightGBM_Pokemon_V5_Advanced'\n",
    "\n",
    "try:\n",
    "    optuna.delete_study(study_name=study_name, storage=None)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name=study_name,\n",
    "    sampler=sampler,\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# Callback per monitoraggio\n",
    "def callback(study, trial):\n",
    "    if trial.number % 10 == 0:\n",
    "        print(f\"\\n[Trial {trial.number}] Best so far: {study.best_value:.4f}\")\n",
    "\n",
    "# Ottimizza\n",
    "print(f\"\\nðŸ”„ Inizio ottimizzazione ({CONFIG['n_trials']} trials, timeout {CONFIG['timeout']}s)...\")\n",
    "print(f\"   Baseline accuracy da battere: {np.mean([0.79] * 10):.4f}\")  # â† Sostituisci con tua media CV\n",
    "\n",
    "study.optimize(\n",
    "    objective_v2, \n",
    "    n_trials=CONFIG['n_trials'], \n",
    "    timeout=CONFIG['timeout'],\n",
    "    callbacks=[callback],\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# ================================================================================\n",
    "# 5ï¸âƒ£ ANALISI RISULTATI DETTAGLIATA\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š RISULTATI OTTIMIZZAZIONE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f\"\\nðŸ† BEST TRIAL: #{best_trial.number}\")\n",
    "print(f\"   â€¢ Accuracy (CV media): {best_trial.value:.4f}\")\n",
    "print(f\"   â€¢ Std Accuracy: {best_trial.user_attrs.get('std_acc', 0):.4f}\")\n",
    "print(f\"   â€¢ Mean Best Iteration: {best_trial.user_attrs.get('mean_best_iter', 0):.0f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ MIGLIORAMENTO vs BASELINE:\")\n",
    "baseline_acc = 0.79  # â† Sostituisci con tua accuracy attuale\n",
    "improvement = (best_trial.value - baseline_acc) * 100\n",
    "print(f\"   â€¢ Baseline: {baseline_acc:.4f}\")\n",
    "print(f\"   â€¢ Nuovo: {best_trial.value:.4f}\")\n",
    "print(f\"   â€¢ Delta: {improvement:+.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ”§ MIGLIORI PARAMETRI:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    baseline_val = BASELINE_PARAMS.get(key, 'N/A')\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   â€¢ {key:20s}: {value:.6f}  (baseline: {baseline_val})\")\n",
    "    else:\n",
    "        print(f\"   â€¢ {key:20s}: {value}  (baseline: {baseline_val})\")\n",
    "\n",
    "# --- Confronto con Top 5 Trial ---\n",
    "print(f\"\\nðŸ¥‡ TOP 5 TRIALS:\")\n",
    "top_trials = sorted(study.trials, key=lambda t: t.value if t.value else 0, reverse=True)[:5]\n",
    "for i, trial in enumerate(top_trials, 1):\n",
    "    if trial.value:\n",
    "        print(f\"   {i}. Trial #{trial.number:3d}: {trial.value:.4f} \"\n",
    "              f\"(std={trial.user_attrs.get('std_acc', 0):.4f})\")\n",
    "\n",
    "# --- Salva Best Params ---\n",
    "best_params_new = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': best_trial.params['boosting_type'],\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "    **best_trial.params\n",
    "}\n",
    "\n",
    "# Rimuovi n_estimators se vuoi usare early stopping in CV\n",
    "best_params_new.pop('n_estimators', None)\n",
    "best_params_new['n_estimators'] = int(best_trial.user_attrs.get('mean_best_iter', 650))\n",
    "\n",
    "print(f\"\\nðŸ’¾ Parametri salvati in `best_params_new`\")\n",
    "\n",
    "# ================================================================================\n",
    "# 6ï¸âƒ£ VISUALIZZAZIONI OPZIONALI (se hai plotly)\n",
    "# ================================================================================\n",
    "\n",
    "try:\n",
    "    from optuna.visualization import (\n",
    "        plot_optimization_history, \n",
    "        plot_param_importances,\n",
    "        plot_parallel_coordinate\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Generazione grafici interattivi...\")\n",
    "    \n",
    "    # History\n",
    "    fig1 = plot_optimization_history(study)\n",
    "    fig1.write_html('optuna_history.html')\n",
    "    \n",
    "    # Param importance\n",
    "    fig2 = plot_param_importances(study)\n",
    "    fig2.write_html('optuna_param_importance.html')\n",
    "    \n",
    "    # Parallel coordinates\n",
    "    fig3 = plot_parallel_coordinate(study)\n",
    "    fig3.write_html('optuna_parallel.html')\n",
    "    \n",
    "    print(f\"   âœ… Grafici salvati: optuna_history.html, optuna_param_importance.html, optuna_parallel.html\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(f\"\\nâš ï¸ Plotly non installato, grafici non generati (pip install plotly)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… OTTIMIZZAZIONE COMPLETATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ================================================================================\n",
    "# 7ï¸âƒ£ VARIABILI ESPORTATE\n",
    "# ================================================================================\n",
    "print(f\"\\nðŸ”§ Variabili disponibili:\")\n",
    "print(f\"   â€¢ best_params_new  â†’ Usa in Cross-Validation\")\n",
    "print(f\"   â€¢ study            â†’ Oggetto Optuna per analisi\")\n",
    "print(f\"   â€¢ BASELINE_PARAMS  â†’ Parametri precedenti per confronto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90672b94",
   "metadata": {},
   "source": [
    "# 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb30d229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10-Fold Cross-Validation - LightGBM ===\n",
      "Parametri utilizzati: {'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt', 'verbosity': -1, 'seed': 42, 'learning_rate': 0.013679823261876542, 'n_estimators': 650, 'num_leaves': 97, 'max_depth': 7, 'min_child_samples': 70, 'subsample': 0.6161988793364829, 'subsample_freq': 4, 'colsample_bytree': 0.6136973726187104, 'reg_alpha': 2.261339389106705e-06, 'reg_lambda': 1.8764227095178463, 'min_split_gain': 0.3554832229238166}\n",
      "\n",
      "Fold 1: train=9000, val=1000, val_acc=83.00%, train_acc=87.32%, gap=4.32%, best_iter=312\n",
      "Fold 2: train=9000, val=1000, val_acc=84.60%, train_acc=89.91%, gap=5.31%, best_iter=596\n",
      "Fold 3: train=9000, val=1000, val_acc=83.80%, train_acc=89.97%, gap=6.17%, best_iter=588\n",
      "Fold 4: train=9000, val=1000, val_acc=85.00%, train_acc=89.46%, gap=4.46%, best_iter=545\n",
      "Fold 5: train=9000, val=1000, val_acc=85.70%, train_acc=89.06%, gap=3.36%, best_iter=504\n",
      "Fold 6: train=9000, val=1000, val_acc=84.10%, train_acc=89.53%, gap=5.43%, best_iter=543\n",
      "Fold 7: train=9000, val=1000, val_acc=83.10%, train_acc=90.56%, gap=7.46%, best_iter=645\n",
      "Fold 8: train=9000, val=1000, val_acc=84.00%, train_acc=88.79%, gap=4.79%, best_iter=456\n",
      "Fold 9: train=9000, val=1000, val_acc=83.90%, train_acc=88.23%, gap=4.33%, best_iter=401\n",
      "Fold 10: train=9000, val=1000, val_acc=84.90%, train_acc=88.58%, gap=3.68%, best_iter=435\n",
      "\n",
      "============================================================\n",
      "Risultati Cross-Validation\n",
      "============================================================\n",
      "  Fold 1: val_acc=83.00%, train_acc=87.32%, gap=4.32%\n",
      "  Fold 2: val_acc=84.60%, train_acc=89.91%, gap=5.31%\n",
      "  Fold 3: val_acc=83.80%, train_acc=89.97%, gap=6.17%\n",
      "  Fold 4: val_acc=85.00%, train_acc=89.46%, gap=4.46%\n",
      "  Fold 5: val_acc=85.70%, train_acc=89.06%, gap=3.36%\n",
      "  Fold 6: val_acc=84.10%, train_acc=89.53%, gap=5.43%\n",
      "  Fold 7: val_acc=83.10%, train_acc=90.56%, gap=7.46%\n",
      "  Fold 8: val_acc=84.00%, train_acc=88.79%, gap=4.79%\n",
      "  Fold 9: val_acc=83.90%, train_acc=88.23%, gap=4.33%\n",
      "  Fold 10: val_acc=84.90%, train_acc=88.58%, gap=3.68%\n",
      "\n",
      "Mean CV accuracy: 84.21%\n",
      "Std CV accuracy:  0.81%\n",
      "Mean train accuracy: 89.14%\n",
      "Mean gap (train - val): 4.93%\n",
      "Min/Max val acc:  83.00% / 85.70%\n",
      "\n",
      "Peggiore fold: #1 con val_acc=83.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 10-Fold Cross-Validation - LightGBM ===\")\n",
    "best_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "    'learning_rate': 0.013679823261876542,\n",
    "    'n_estimators': 650,\n",
    "    'num_leaves': 97,\n",
    "    'max_depth': 7,\n",
    "    'min_child_samples': 70,\n",
    "    'subsample': 0.6161988793364829,\n",
    "    'subsample_freq': 4,\n",
    "    'colsample_bytree': 0.6136973726187104,\n",
    "    'reg_alpha': 2.261339389106705e-06,\n",
    "    'reg_lambda': 1.8764227095178463,\n",
    "    'min_split_gain': 0.3554832229238166\n",
    "}\n",
    "\n",
    "print(f\"Parametri utilizzati: {best_params}\\n\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_accuracies = []\n",
    "train_accuracies = []\n",
    "train_val_gaps = []\n",
    "folds_info = []\n",
    "\n",
    "fold_idx = 0\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    fold_idx += 1\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Train LightGBM con early stopping\n",
    "    clf = lgb.LGBMClassifier(**best_params)\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Validation predictions\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_proba_val = clf.predict_proba(X_val)[:, 1]\n",
    "    val_acc = accuracy_score(y_val, y_pred_val)\n",
    "    outer_accuracies.append(val_acc)\n",
    "    \n",
    "    # Train accuracy\n",
    "    y_pred_tr = clf.predict(X_tr)\n",
    "    tr_acc = accuracy_score(y_tr, y_pred_tr)\n",
    "    gap = tr_acc - val_acc\n",
    "    train_accuracies.append(tr_acc)\n",
    "    train_val_gaps.append(gap)\n",
    "    \n",
    "    # Best iteration info\n",
    "    best_iter = clf.best_iteration_ if hasattr(clf, 'best_iteration_') else clf.n_estimators\n",
    "    \n",
    "    folds_info.append({\n",
    "        'fold': fold_idx,\n",
    "        'val_acc': float(val_acc),\n",
    "        'train_acc': float(tr_acc),\n",
    "        'gap': float(gap),\n",
    "        'best_iteration': int(best_iter),\n",
    "        'val_idx': val_idx,\n",
    "        'y_true': y_val.astype(int),\n",
    "        'y_pred': y_pred_val.astype(int),\n",
    "        'y_proba': y_proba_val.astype(float)\n",
    "    })\n",
    "    \n",
    "    print(f'Fold {fold_idx}: train={len(y_tr)}, val={len(y_val)}, '\n",
    "          f'val_acc={val_acc*100:.2f}%, train_acc={tr_acc*100:.2f}%, '\n",
    "          f'gap={gap*100:.2f}%, best_iter={best_iter}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Risultati Cross-Validation')\n",
    "print('='*60)\n",
    "for i, info in enumerate(folds_info, 1):\n",
    "    print(f\"  Fold {i}: val_acc={info['val_acc']*100:.2f}%, \"\n",
    "          f\"train_acc={info['train_acc']*100:.2f}%, gap={info['gap']*100:.2f}%\")\n",
    "\n",
    "print(f'\\nMean CV accuracy: {np.mean(outer_accuracies)*100:.2f}%')\n",
    "print(f'Std CV accuracy:  {np.std(outer_accuracies)*100:.2f}%')\n",
    "print(f'Mean train accuracy: {np.mean(train_accuracies)*100:.2f}%')\n",
    "print(f'Mean gap (train - val): {np.mean(train_val_gaps)*100:.2f}%')\n",
    "print(f'Min/Max val acc:  {np.min(outer_accuracies)*100:.2f}% / {np.max(outer_accuracies)*100:.2f}%')\n",
    "\n",
    "worst_idx = int(np.argmin(outer_accuracies))\n",
    "print(f\"\\nPeggiore fold: #{worst_idx+1} con val_acc={outer_accuracies[worst_idx]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56eb9c",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c5a5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission con LightGBM trainato su tutto il dataset ===\n",
      "âœ… File di submission salvato in submission_lightgbm.csv\n",
      "Modello: LightGBM trainato su 10000 samples\n",
      "Stima CV accuracy: 84.11% Â± 0.74%\n",
      "Mean gap: 5.05%\n",
      "\n",
      "Preview submission:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           1\n",
       "2          2           1\n",
       "3          3           1\n",
       "4          4           1\n",
       "5          5           1\n",
       "6          6           1\n",
       "7          7           1\n",
       "8          8           1\n",
       "9          9           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuzione predizioni: {0: 2542, 1: 2458}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Submission con LightGBM trainato su tutto il dataset ===\")\n",
    "\n",
    "# Train finale su tutto il dataset\n",
    "submission_model = lgb.LGBMClassifier(**best_params)\n",
    "submission_model.fit(X, y)\n",
    "\n",
    "# Predict su test\n",
    "X_test_matrix = test_preproc_df.values\n",
    "test_predictions = submission_model.predict(X_test_matrix).astype(int)\n",
    "\n",
    "# Crea submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': test_predictions.astype(np.int64)\n",
    "})\n",
    "\n",
    "submission_path = 'submission_lightgbm.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"âœ… File di submission salvato in {submission_path}\")\n",
    "print(f\"Modello: LightGBM trainato su {len(X)} samples\")\n",
    "print(f\"Stima CV accuracy: {np.mean(outer_accuracies)*100:.2f}% Â± {np.std(outer_accuracies)*100:.2f}%\")\n",
    "print(f\"Mean gap: {np.mean(train_val_gaps)*100:.2f}%\")\n",
    "print(\"\\nPreview submission:\")\n",
    "display(submission_df.head(10))\n",
    "print(f\"\\nDistribuzione predizioni: {submission_df['player_won'].value_counts().to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
