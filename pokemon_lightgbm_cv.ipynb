{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e90af5",
   "metadata": {},
   "source": [
    "# Pokémon battles — LightGBM with 10-fold CV\n",
    "Notebook che implementa LightGBM con: feature engineering completo, 10-fold CV, Optuna hyperparameter tuning, e submission finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52572bf2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99172c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati...\n",
      "Train records: 10000, Test records: 5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Percorsi ---\n",
    "train_file_path = 'train.jsonl'\n",
    "test_file_path = 'test.jsonl'\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "print('Caricamento dati...')\n",
    "train_raw = load_jsonl(train_file_path)\n",
    "test_raw = load_jsonl(test_file_path)\n",
    "print(f'Train records: {len(train_raw)}, Test records: {len(test_raw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f8a7b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b032f7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b35f398f1e94be8b43ad5080ebb4ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FE Complete:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40a3442394345029c343e3980362432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FE Complete:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape train/test: (10000, 296) (5000, 295)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "      <th>p1_base_hp_sum</th>\n",
       "      <th>p1_base_hp_mean</th>\n",
       "      <th>p1_base_hp_max</th>\n",
       "      <th>p1_base_hp_min</th>\n",
       "      <th>p1_base_hp_std</th>\n",
       "      <th>p1_base_atk_sum</th>\n",
       "      <th>p1_base_atk_mean</th>\n",
       "      <th>p1_base_atk_max</th>\n",
       "      <th>...</th>\n",
       "      <th>tl_info_advantage</th>\n",
       "      <th>tl_p2_avg_reveal_turn</th>\n",
       "      <th>tl_p1_immune_switches</th>\n",
       "      <th>tl_p2_forced_switches</th>\n",
       "      <th>tl_turns_with_hp_lead</th>\n",
       "      <th>tl_hp_diff_turn_10</th>\n",
       "      <th>tl_hp_diff_turn_20</th>\n",
       "      <th>tl_hp_diff_end</th>\n",
       "      <th>tl_heal_diff</th>\n",
       "      <th>tl_freeze_adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>695.0</td>\n",
       "      <td>115.833333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.367179</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.58891</td>\n",
       "      <td>-0.201018</td>\n",
       "      <td>0.279549</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>250.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.204534</td>\n",
       "      <td>435.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>124.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>64.382753</td>\n",
       "      <td>505.0</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>730.0</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65.362239</td>\n",
       "      <td>465.0</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>685.0</td>\n",
       "      <td>114.166667</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.794107</td>\n",
       "      <td>455.0</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.03000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won  p1_base_hp_sum  p1_base_hp_mean  p1_base_hp_max  \\\n",
       "0          0           1           695.0       115.833333           250.0   \n",
       "1          1           1           740.0       123.333333           250.0   \n",
       "2          2           1           745.0       124.166667           250.0   \n",
       "3          3           1           730.0       121.666667           250.0   \n",
       "4          4           1           685.0       114.166667           250.0   \n",
       "\n",
       "   p1_base_hp_min  p1_base_hp_std  p1_base_atk_sum  p1_base_atk_mean  \\\n",
       "0            55.0       69.367179            435.0         72.500000   \n",
       "1            65.0       64.204534            435.0         72.500000   \n",
       "2            60.0       64.382753            505.0         84.166667   \n",
       "3            60.0       65.362239            465.0         77.500000   \n",
       "4            50.0       70.794107            455.0         75.833333   \n",
       "\n",
       "   p1_base_atk_max  ...  tl_info_advantage  tl_p2_avg_reveal_turn  \\\n",
       "0            110.0  ...                  0               8.500000   \n",
       "1            110.0  ...                  0               9.666667   \n",
       "2            130.0  ...                  1               9.750000   \n",
       "3            110.0  ...                 -1               5.750000   \n",
       "4            110.0  ...                  0              15.200000   \n",
       "\n",
       "   tl_p1_immune_switches  tl_p2_forced_switches  tl_turns_with_hp_lead  \\\n",
       "0                      0                      3                     12   \n",
       "1                      0                      6                     15   \n",
       "2                      0                      2                     13   \n",
       "3                      0                      2                     10   \n",
       "4                      0                      5                     13   \n",
       "\n",
       "   tl_hp_diff_turn_10  tl_hp_diff_turn_20  tl_hp_diff_end  tl_heal_diff  \\\n",
       "0            -0.58891           -0.201018        0.279549             0   \n",
       "1             0.28000            0.600000       -0.320000             0   \n",
       "2             0.00000            0.240000       -0.240000            -1   \n",
       "3             0.13000            0.540000       -0.060000             2   \n",
       "4            -0.03000           -0.180000        0.320000            -1   \n",
       "\n",
       "   tl_freeze_adv  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 296 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. COSTANTI & FUNZIONI BASE\n",
    "# ==============================================================================\n",
    "\n",
    "TYPE_CHART = {\n",
    "    'normal': {'rock': 0.5, 'ghost': 0},\n",
    "    'fire': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ice': 2, 'bug': 2, 'rock': 0.5, 'dragon': 0.5},\n",
    "    'water': {'fire': 2, 'water': 0.5, 'grass': 0.5, 'ground': 2, 'rock': 2, 'dragon': 0.5},\n",
    "    'grass': {'fire': 0.5, 'water': 2, 'grass': 0.5, 'poison': 0.5, 'ground': 2, 'flying': 0.5, 'bug': 0.5, 'rock': 2, 'dragon': 0.5},\n",
    "    'electric': {'water': 2, 'grass': 0.5, 'electric': 0.5, 'ground': 0, 'flying': 2, 'dragon': 0.5},\n",
    "    'ice': {'fire': 0.5, 'water': 0.5, 'grass': 2, 'ground': 2, 'flying': 2, 'dragon': 2},\n",
    "    'fighting': {'normal': 2, 'ice': 2, 'poison': 0.5, 'flying': 0.5, 'psychic': 0.5, 'bug': 0.5, 'rock': 2, 'ghost': 0},\n",
    "    'poison': {'grass': 2, 'poison': 0.5, 'ground': 0.5, 'bug': 2, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground': {'fire': 2, 'grass': 0.5, 'electric': 2, 'poison': 2, 'flying': 0, 'bug': 0.5, 'rock': 2},\n",
    "    'flying': {'grass': 2, 'electric': 0.5, 'fighting': 2, 'bug': 2, 'rock': 0.5},\n",
    "    'psychic': {'fighting': 2, 'poison': 2, 'psychic': 0.5, 'ghost': 0},\n",
    "    'bug': {'fire': 0.5, 'grass': 2, 'fighting': 0.5, 'poison': 2, 'flying': 0.5, 'psychic': 2, 'ghost': 0.5},\n",
    "    'rock': {'fire': 2, 'ice': 2, 'fighting': 0.5, 'ground': 0.5, 'flying': 2, 'bug': 2},\n",
    "    'ghost': {'normal': 0, 'psychic': 0, 'ghost': 2},\n",
    "    'dragon': {'dragon': 2}\n",
    "}\n",
    "\n",
    "def get_effectiveness(attack_type: str, defense_types: list) -> float:\n",
    "    if not attack_type or not defense_types: return 1.0\n",
    "    eff = 1.0\n",
    "    for d in defense_types: eff *= TYPE_CHART.get(attack_type, {}).get(d, 1.0)\n",
    "    return eff\n",
    "\n",
    "def _entropy(counter: Counter) -> float:\n",
    "    total = sum(counter.values())\n",
    "    if total == 0: return 0.0\n",
    "    ent = 0.0\n",
    "    for v in counter.values():\n",
    "        p = v / total\n",
    "        if p > 0: ent -= p * math.log(p, 2)\n",
    "    return ent\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ESTRATTORI FEATURE ORIGINALI (CONSERVATI)\n",
    "# ==============================================================================\n",
    "\n",
    "def calculate_type_advantage(team1: list, team2_lead: dict) -> dict:\n",
    "    out = {'p1_vs_lead_avg_effectiveness': 0.0, 'p1_vs_lead_max_effectiveness': 0.0, 'p1_super_effective_options': 0}\n",
    "    if not team1 or not team2_lead: return out\n",
    "    lead_types = [t.lower() for t in team2_lead.get('types', [])]\n",
    "    if not lead_types: return out\n",
    "    effs = []\n",
    "    for p in team1:\n",
    "        p_types = [t.lower() for t in p.get('types', [])]\n",
    "        max_eff = 0.0\n",
    "        for pt in p_types: max_eff = max(max_eff, get_effectiveness(pt, lead_types))\n",
    "        effs.append(max_eff)\n",
    "    if not effs: return out\n",
    "    out['p1_vs_lead_avg_effectiveness'] = float(np.mean(effs))\n",
    "    out['p1_vs_lead_max_effectiveness'] = float(np.max(effs))\n",
    "    out['p1_super_effective_options'] = int(sum(1 for e in effs if e >= 2))\n",
    "    return out\n",
    "\n",
    "def team_aggregate_features(team: list, prefix: str = 'p1_') -> dict:\n",
    "    stats = ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']\n",
    "    out = {}\n",
    "    vals = {s: [] for s in stats}\n",
    "    levels = []; types_counter = Counter(); names = []\n",
    "    for p in team:\n",
    "        names.append(p.get('name',''))\n",
    "        for s in stats: vals[s].append(p.get(s, 0))\n",
    "        levels.append(p.get('level', 0))\n",
    "        for t in p.get('types', []): types_counter[t.lower()] += 1\n",
    "    for s in stats:\n",
    "        arr = np.array(vals[s], dtype=float)\n",
    "        out[f'{prefix}{s}_sum'] = float(arr.sum())\n",
    "        out[f'{prefix}{s}_mean'] = float(arr.mean())\n",
    "        out[f'{prefix}{s}_max'] = float(arr.max())\n",
    "        out[f'{prefix}{s}_min'] = float(arr.min())\n",
    "        out[f'{prefix}{s}_std'] = float(arr.std())\n",
    "    level_arr = np.array(levels, dtype=float)\n",
    "    out[f'{prefix}level_mean'] = float(level_arr.mean()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}level_sum'] = float(level_arr.sum()) if level_arr.size else 0.0\n",
    "    out[f'{prefix}n_unique_types'] = int(len(types_counter))\n",
    "    for t in ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']:\n",
    "        out[f'{prefix}type_{t}_count'] = int(types_counter.get(t, 0))\n",
    "    out[f'{prefix}lead_name'] = names[0] if names else ''\n",
    "    out[f'{prefix}n_unique_names'] = int(len(set(names)))\n",
    "    out[f'{prefix}type_entropy'] = float(_entropy(types_counter))\n",
    "    spe_arr = np.array(vals['base_spe'], dtype=float)\n",
    "    out[f'{prefix}spe_p25'] = float(np.percentile(spe_arr, 25)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p50'] = float(np.percentile(spe_arr, 50)) if spe_arr.size else 0.0\n",
    "    out[f'{prefix}spe_p75'] = float(np.percentile(spe_arr, 75)) if spe_arr.size else 0.0\n",
    "    return out\n",
    "\n",
    "def lead_vs_lead_features(p1_lead: dict, p2_lead: dict) -> dict:\n",
    "    out = {}\n",
    "    for s in ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']:\n",
    "        out[f'lead_diff_{s}'] = float(p1_lead.get(s,0) - p2_lead.get(s,0))\n",
    "    out['lead_speed_advantage'] = float(p1_lead.get('base_spe',0) - p2_lead.get('base_spe',0))\n",
    "    p1_types = [t.lower() for t in p1_lead.get('types', [])]\n",
    "    p2_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    max_eff = 0.0\n",
    "    for pt in p1_types: max_eff = max(max_eff, get_effectiveness(pt, p2_types))\n",
    "    out['lead_p1_vs_p2_effectiveness'] = float(max_eff)\n",
    "    return out\n",
    "\n",
    "def lead_aggregate_features(pokemon: dict, prefix: str = 'p2_lead_') -> dict:\n",
    "    out = {}\n",
    "    for s in ['base_hp','base_atk','base_def','base_spa','base_spd','base_spe']:\n",
    "        out[f'{prefix}{s}'] = float(pokemon.get(s,0))\n",
    "    out[f'{prefix}level'] = int(pokemon.get('level',0))\n",
    "    types = [x.lower() for x in pokemon.get('types', [])]\n",
    "    for t in ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying']:\n",
    "        out[f'{prefix}type_{t}'] = int(t in types)\n",
    "    out[f'{prefix}name'] = pokemon.get('name','')\n",
    "    out[f'{prefix}n_unique_types'] = int(len(set(types)))\n",
    "    return out\n",
    "\n",
    "def quick_boost_features_v2(record: dict) -> dict:\n",
    "    out = {}\n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    timeline = record.get('battle_timeline', [])\n",
    "    if not p1_team: return out\n",
    "    \n",
    "    p2_lead_spe = p2_lead.get('base_spe', 0)\n",
    "    out['p1_faster_than_lead_count'] = sum(1 for p in p1_team if p.get('base_spe', 0) > p2_lead_spe)\n",
    "    out['p1_slower_than_lead_count'] = sum(1 for p in p1_team if p.get('base_spe', 0) <= p2_lead_spe)\n",
    "    out['p1_speed_control_ratio'] = out['p1_faster_than_lead_count'] / max(1, len(p1_team))\n",
    "    \n",
    "    p1_avg_bulk = np.mean([p.get('base_hp', 0)*(p.get('base_def', 0)+p.get('base_spd', 0)) for p in p1_team])\n",
    "    p2_lead_bulk = p2_lead.get('base_hp', 1)*(p2_lead.get('base_def', 1)+p2_lead.get('base_spd', 1))\n",
    "    out['p1_avg_bulk_vs_lead'] = p1_avg_bulk / max(p2_lead_bulk, 1)\n",
    "    \n",
    "    p1_total_atk = sum(p.get('base_atk', 0) + p.get('base_spa', 0) for p in p1_team)\n",
    "    p2_lead_offense = p2_lead.get('base_atk', 0) + p2_lead.get('base_spa', 0)\n",
    "    out['p1_total_offense'] = p1_total_atk\n",
    "    out['p1_offense_advantage'] = p1_total_atk / max(p2_lead_offense, 1)\n",
    "    \n",
    "    p2_lead_types = [t.lower() for t in p2_lead.get('types', [])]\n",
    "    if p2_lead_types:\n",
    "        cov = []\n",
    "        for p in p1_team:\n",
    "            p_types = [t.lower() for t in p.get('types', [])]\n",
    "            cov.append(max([get_effectiveness(pt, p2_lead_types) for pt in p_types] or [1.0]))\n",
    "        out['p1_avg_effectiveness_vs_lead'] = float(np.mean(cov))\n",
    "        out['p1_max_effectiveness_vs_lead'] = float(np.max(cov))\n",
    "        out['p1_se_count_vs_lead'] = sum(1 for s in cov if s >= 2.0)\n",
    "        out['p1_weak_count_vs_lead'] = sum(1 for s in cov if s <= 0.5)\n",
    "        \n",
    "    if timeline:\n",
    "        first_p1_ko = False; first_p2_ko = False\n",
    "        for turn in timeline[:30]:\n",
    "            if not first_p2_ko and turn.get('p2_pokemon_state', {}).get('fainted'):\n",
    "                first_p1_ko = True; out['p1_first_blood'] = 1; out['p1_first_blood_turn'] = turn.get('turn', 0); break\n",
    "            if not first_p1_ko and turn.get('p1_pokemon_state', {}).get('fainted'):\n",
    "                first_p2_ko = True; out['p1_first_blood'] = 0; out['p1_first_blood_turn'] = turn.get('turn', 0); break\n",
    "        if not first_p1_ko and not first_p2_ko:\n",
    "            out['p1_first_blood'] = -1; out['p1_first_blood_turn'] = 0\n",
    "            \n",
    "    p1_avg_level = np.mean([p.get('level', 50) for p in p1_team])\n",
    "    out['p1_avg_level_advantage'] = p1_avg_level - p2_lead.get('level', 50)\n",
    "    \n",
    "    p1_prods = [(p.get('base_hp',1)*p.get('base_atk',1)*p.get('base_def',1)*p.get('base_spa',1)*p.get('base_spd',1)*p.get('base_spe',1)) for p in p1_team]\n",
    "    out['p1_avg_stat_product'] = float(np.mean(p1_prods))\n",
    "    out['p1_max_stat_product'] = float(np.max(p1_prods))\n",
    "    p2_prod = p2_lead.get('base_hp',1)*p2_lead.get('base_atk',1)*p2_lead.get('base_def',1)*p2_lead.get('base_spa',1)*p2_lead.get('base_spd',1)*p2_lead.get('base_spe',1)\n",
    "    out['p1_stat_product_advantage'] = out['p1_avg_stat_product'] / max(p2_prod, 1)\n",
    "    return out\n",
    "\n",
    "def summary_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline: return {'tl_p1_moves':0,'tl_p2_moves':0,'tl_p1_est_damage':0.0,'tl_p2_est_damage':0.0,'damage_diff':0.0}\n",
    "    p1_moves = p2_moves = 0; p1_damage = p2_damage = 0.0\n",
    "    p1_last_active = p2_last_active = ''; p1_fainted = p2_fainted = 0\n",
    "    p1_fainted_names = set(); p2_fainted_names = set()\n",
    "    last_p1_hp = {}; last_p2_hp = {}\n",
    "    p1_comeback_kos = p2_comeback_kos = 0\n",
    "    p1_statuses = Counter(); p2_statuses = Counter()\n",
    "    p1_poke_statuses = {}; p2_poke_statuses = {}\n",
    "    p1_move_types = Counter(); p2_move_types = Counter()\n",
    "    p1_dmg_first2 = p2_dmg_first2 = 0.0\n",
    "    p1_dmg_by_turn = {}; p2_dmg_by_turn = {}; seen_turns = set()\n",
    "    first_ko_p1_taken = None; first_ko_p1_inflicted = None\n",
    "    p1_kos_early = p1_kos_late = p2_kos_early = p2_kos_late = 0\n",
    "\n",
    "    for turn in timeline[:30]:\n",
    "        prev_p1_f, prev_p2_f = p1_fainted, p2_fainted\n",
    "        p1s = turn.get('p1_pokemon_state',{}) or {}; p2s = turn.get('p2_pokemon_state',{}) or {}\n",
    "        tnum = turn.get('turn', len(seen_turns) + 1); seen_turns.add(tnum)\n",
    "\n",
    "        if p1s.get('name'): p1_last_active = p1s.get('name')\n",
    "        if p2s.get('name'): p2_last_active = p2s.get('name')\n",
    "\n",
    "        if p1s.get('fainted') and p1s.get('name') not in p1_fainted_names:\n",
    "            p1_fainted += 1; p1_fainted_names.add(p1s.get('name'))\n",
    "            if first_ko_p1_taken is None: first_ko_p1_taken = tnum\n",
    "            if tnum <= 10: p2_kos_early += 1\n",
    "            else: p2_kos_late += 1\n",
    "        if p2s.get('fainted') and p2s.get('name') not in p2_fainted_names:\n",
    "            p2_fainted += 1; p2_fainted_names.add(p2s.get('name'))\n",
    "            if first_ko_p1_inflicted is None: first_ko_p1_inflicted = tnum\n",
    "            if tnum <= 10: p1_kos_early += 1\n",
    "            else: p1_kos_late += 1\n",
    "\n",
    "        if p2s.get('name') and p2s.get('hp_pct') is not None:\n",
    "            prev = last_p2_hp.get(p2s['name'])\n",
    "            if prev is not None:\n",
    "                delta = max(0.0, prev - p2s['hp_pct'])\n",
    "                p1_damage += delta; p1_dmg_by_turn[tnum] = p1_dmg_by_turn.get(tnum,0.0)+delta\n",
    "                if tnum <= 2: p1_dmg_first2 += delta\n",
    "            last_p2_hp[p2s['name']] = p2s['hp_pct']\n",
    "\n",
    "        if p1s.get('name') and p1s.get('hp_pct') is not None:\n",
    "            prev = last_p1_hp.get(p1s['name'])\n",
    "            if prev is not None:\n",
    "                delta = max(0.0, prev - p1s['hp_pct'])\n",
    "                p2_damage += delta; p2_dmg_by_turn[tnum] = p2_dmg_by_turn.get(tnum,0.0)+delta\n",
    "                if tnum <= 2: p2_dmg_first2 += delta\n",
    "            last_p1_hp[p1s['name']] = p1s['hp_pct']\n",
    "\n",
    "        dmg_diff = p1_damage - p2_damage\n",
    "        if p2_fainted > prev_p2_f and dmg_diff < -1.0: p1_comeback_kos += 1\n",
    "        if p1_fainted > prev_p1_f and dmg_diff > 1.0: p2_comeback_kos += 1\n",
    "\n",
    "        if p2s.get('name') and p2s.get('status') and p2_poke_statuses.get(p2s['name']) != p2s['status']:\n",
    "            p1_statuses[p2s['status']] += 1; p2_poke_statuses[p2s['name']] = p2s['status']\n",
    "        if p1s.get('name') and p1s.get('status') and p1_poke_statuses.get(p1s['name']) != p1s['status']:\n",
    "            p2_statuses[p1s['status']] += 1; p1_poke_statuses[p1s['name']] = p1s['status']\n",
    "\n",
    "        if turn.get('p1_move_details'):\n",
    "            p1_moves += 1; mtype = (turn['p1_move_details'].get('type') or '').lower()\n",
    "            if mtype: p1_move_types[mtype] += 1\n",
    "        if turn.get('p2_move_details'):\n",
    "            p2_moves += 1; mtype = (turn['p2_move_details'].get('type') or '').lower()\n",
    "            if mtype: p2_move_types[mtype] += 1\n",
    "\n",
    "    out['tl_p1_moves'] = p1_moves; out['tl_p2_moves'] = p2_moves\n",
    "    out['tl_p1_est_damage'] = float(p1_damage); out['tl_p2_est_damage'] = float(p2_damage)\n",
    "    out['tl_p1_fainted'] = p1_fainted; out['tl_p2_fainted'] = p2_fainted\n",
    "    turns = max(1, len(seen_turns))\n",
    "    out['tl_p1_fainted_rate'] = p1_fainted/turns; out['tl_p2_fainted_rate'] = p2_fainted/turns\n",
    "    out['damage_diff'] = float(p1_damage - p2_damage); out['fainted_diff'] = int(p1_fainted - p2_fainted)\n",
    "    out['tl_p1_last_hp'] = float(last_p1_hp.get(p1_last_active, 0) if p1_last_active else 0)\n",
    "    out['tl_p2_last_hp'] = float(last_p2_hp.get(p2_last_active, 0) if p2_last_active else 0)\n",
    "    out['tl_p1_last_active'] = p1_last_active; out['tl_p2_last_active'] = p2_last_active\n",
    "    \n",
    "    if p1_team:\n",
    "        p1_hp_sum = sum(p.get('base_hp',0) for p in p1_team)\n",
    "        p1_def_avg = np.mean([p.get('base_def',0)+p.get('base_spd',0) for p in p1_team])\n",
    "        out['tl_p2_damage_vs_p1_hp_pool'] = p2_damage / (p1_hp_sum + 1e-6)\n",
    "        out['tl_p1_defensive_endurance'] = p1_def_avg / (p2_damage + 1e-6)\n",
    "        \n",
    "    out['tl_p1_comeback_kos'] = p1_comeback_kos; out['tl_p2_comeback_kos'] = p2_comeback_kos\n",
    "    out['tl_comeback_kos_diff'] = p1_comeback_kos - p2_comeback_kos\n",
    "\n",
    "    for s in ['brn','par','slp','frz','psn','tox']:\n",
    "        out[f'tl_p1_inflicted_{s}_count'] = p1_statuses[s]\n",
    "        out[f'tl_p2_inflicted_{s}_count'] = p2_statuses[s]\n",
    "        out[f'tl_inflicted_{s}_diff'] = p1_statuses[s] - p2_statuses[s]\n",
    "        out[f'tl_p1_inflicted_{s}_rate'] = p1_statuses[s]/turns\n",
    "        out[f'tl_p2_inflicted_{s}_rate'] = p2_statuses[s]/turns\n",
    "        out[f'tl_inflicted_{s}_rate_diff'] = (p1_statuses[s]-p2_statuses[s])/turns\n",
    "\n",
    "    for mt in ['normal','fire','water','electric','grass','psychic','ice','dragon','rock','ground','flying','ghost','bug','poison','fighting']:\n",
    "        out[f'tl_p1_move_type_{mt}_count'] = p1_move_types[mt]\n",
    "        out[f'tl_p2_move_type_{mt}_count'] = p2_move_types[mt]\n",
    "        out[f'tl_move_type_{mt}_count_diff'] = p1_move_types[mt] - p2_move_types[mt]\n",
    "\n",
    "    out['tl_p1_damage_first2'] = p1_dmg_first2; out['tl_p2_damage_first2'] = p2_dmg_first2\n",
    "    out['tl_first2_damage_diff'] = p1_dmg_first2 - p2_dmg_first2\n",
    "    out['tl_turns_count'] = turns\n",
    "    out['tl_p1_moves_rate'] = p1_moves/turns; out['tl_p2_moves_rate'] = p2_moves/turns\n",
    "    out['tl_p1_damage_per_turn'] = p1_damage/turns; out['tl_p2_damage_per_turn'] = p2_damage/turns\n",
    "    out['tl_damage_rate_diff'] = out['tl_p1_damage_per_turn'] - out['tl_p2_damage_per_turn']\n",
    "\n",
    "    recent = sorted(seen_turns)[-5:] if seen_turns else []\n",
    "    p1_last5 = sum(p1_dmg_by_turn.get(t,0) for t in recent)\n",
    "    p2_last5 = sum(p2_dmg_by_turn.get(t,0) for t in recent)\n",
    "    out['tl_p1_damage_last5'] = p1_last5; out['tl_p2_damage_last5'] = p2_last5\n",
    "    out['tl_last5_damage_diff'] = p1_last5 - p2_last5\n",
    "    out['tl_p1_last5_damage_ratio'] = p1_last5/(p1_damage+1e-6)\n",
    "    out['tl_p2_last5_damage_ratio'] = p2_last5/(p2_damage+1e-6)\n",
    "    out['tl_last5_damage_ratio_diff'] = out['tl_p1_last5_damage_ratio'] - out['tl_p2_last5_damage_ratio']\n",
    "\n",
    "    if seen_turns:\n",
    "        ts = sorted(seen_turns); w = np.linspace(1.0, 2.0, num=len(ts)); w = w/w.sum()\n",
    "        adv = [(p1_dmg_by_turn.get(t,0)-p2_dmg_by_turn.get(t,0)) for t in ts]\n",
    "        out['tl_weighted_damage_diff'] = float(np.dot(w, adv))\n",
    "        cum = 0.0; signs = []\n",
    "        for t in ts:\n",
    "            cum += (p1_dmg_by_turn.get(t,0)-p2_dmg_by_turn.get(t,0))\n",
    "            s = 1 if cum > 1e-9 else (-1 if cum < -1e-9 else 0)\n",
    "            if s != 0 and (not signs or signs[-1] != s): signs.append(s)\n",
    "        out['tl_damage_adv_sign_flips'] = max(0, len(signs)-1)\n",
    "        out['tl_comeback_flag'] = 1 if (len(signs)>=2 and signs[0]!=signs[-1]) else 0\n",
    "    else:\n",
    "        out['tl_weighted_damage_diff'] = 0.0; out['tl_damage_adv_sign_flips'] = 0; out['tl_comeback_flag'] = 0\n",
    "\n",
    "    out['tl_first_ko_turn_p1_inflicted'] = int(first_ko_p1_inflicted or 0)\n",
    "    out['tl_first_ko_turn_p1_taken'] = int(first_ko_p1_taken or 0)\n",
    "    out['tl_first_ko_turn_diff'] = out['tl_first_ko_turn_p1_inflicted'] - out['tl_first_ko_turn_p1_taken']\n",
    "    out['tl_kos_early_p1'] = p1_kos_early; out['tl_kos_late_p1'] = p1_kos_late\n",
    "    out['tl_kos_early_p2'] = p2_kos_early; out['tl_kos_late_p2'] = p2_kos_late\n",
    "    return out\n",
    "\n",
    "def extract_move_coverage_from_timeline(timeline: list, prefix: str = 'p1_') -> dict:\n",
    "    out = {}\n",
    "    m_types = set(); m_cats = Counter(); unique_m = set(); stab = 0\n",
    "    for turn in timeline[:30]:\n",
    "        md = turn.get(f'{prefix[:-1]}_move_details')\n",
    "        ps = turn.get(f'{prefix[:-1]}_pokemon_state', {})\n",
    "        if not md: continue\n",
    "        if md.get('name'): unique_m.add(md['name'])\n",
    "        if t := (md.get('type') or '').lower(): m_types.add(t)\n",
    "        if c := md.get('category'): m_cats[c] += 1\n",
    "        if t in [pt.lower() for pt in ps.get('types', [])]: stab += 1\n",
    "    \n",
    "    out[f'{prefix}tl_unique_move_types'] = len(m_types)\n",
    "    out[f'{prefix}tl_unique_moves_used'] = len(unique_m)\n",
    "    out[f'{prefix}tl_stab_moves'] = stab\n",
    "    out[f'{prefix}tl_physical_moves'] = m_cats['physical']\n",
    "    out[f'{prefix}tl_special_moves'] = m_cats['special']\n",
    "    out[f'{prefix}tl_status_moves'] = m_cats['status']\n",
    "    out[f'{prefix}tl_coverage_score'] = len(m_types)/max(1, len(unique_m))\n",
    "    tot = sum(m_cats.values())\n",
    "    out[f'{prefix}tl_offensive_ratio'] = (m_cats['physical']+m_cats['special'])/tot if tot else 0.0\n",
    "    out[f'{prefix}tl_status_ratio'] = m_cats['status']/tot if tot else 0.0\n",
    "    return out\n",
    "\n",
    "def ability_features(team: list, prefix: str) -> dict:\n",
    "    imm = {'levitate':0,'volt_absorb':0,'water_absorb':0,'flash_fire':0}\n",
    "    drop = {'intimidate':0}; weather = {'drought':0,'drizzle':0,'sand_stream':0}\n",
    "    for p in team:\n",
    "        a = (p.get('ability','') or '').lower().replace(' ','_')\n",
    "        if a in imm: imm[a]+=1\n",
    "        if a in drop: drop[a]+=1\n",
    "        if a in weather: weather[a]+=1\n",
    "    out = {}\n",
    "    for k,v in imm.items(): out[f'{prefix}ability_{k}_count'] = v\n",
    "    for k,v in drop.items(): out[f'{prefix}ability_{k}_count'] = v\n",
    "    for k,v in weather.items(): out[f'{prefix}ability_{k}_count'] = v\n",
    "    out[f'{prefix}total_immunity_abilities'] = sum(imm.values())\n",
    "    out[f'{prefix}total_stat_drop_abilities'] = sum(drop.values())\n",
    "    return out\n",
    "\n",
    "def momentum_features(timeline: list) -> dict:\n",
    "    out = {}\n",
    "    if not timeline: return out\n",
    "    advs = []; cum = 0.0\n",
    "    for turn in timeline[:30]:\n",
    "        p1h = turn.get('p1_pokemon_state', {}).get('hp_pct', 100)\n",
    "        p2h = turn.get('p2_pokemon_state', {}).get('hp_pct', 100)\n",
    "        cum += (p1h - p2h); advs.append(cum)\n",
    "    if advs:\n",
    "        slope, intercept = np.polyfit(np.arange(len(advs)), advs, 1)\n",
    "        out['p1_momentum_slope'] = float(slope)\n",
    "        out['p1_momentum_intercept'] = float(intercept)\n",
    "        out['p1_final_advantage'] = float(advs[-1])\n",
    "        out['p1_advantage_volatility'] = float(np.std(advs))\n",
    "        out['p1_max_advantage'] = float(np.max(advs))\n",
    "        out['p1_min_advantage'] = float(np.min(advs))\n",
    "        out['p1_advantage_range'] = out['p1_max_advantage'] - out['p1_min_advantage']\n",
    "    return out\n",
    "\n",
    "def extract_opponent_team_from_timeline(timeline: list, p1_team: list) -> dict:\n",
    "    out = {}\n",
    "    seen = set(); types = []\n",
    "    for turn in timeline[:30]:\n",
    "        p2s = turn.get('p2_pokemon_state', {})\n",
    "        if p2s.get('name') and p2s['name'] not in seen:\n",
    "            seen.add(p2s['name'])\n",
    "            types.extend([t.lower() for t in p2s.get('types', [])])\n",
    "    \n",
    "    out['p2_tl_unique_pokemon_seen'] = len(seen)\n",
    "    out['p2_tl_switches_count'] = max(0, len(seen) - 1)\n",
    "    out['p2_tl_unique_types_seen'] = len(set(types))\n",
    "    out['p2_tl_type_entropy'] = _entropy(Counter(types))\n",
    "    \n",
    "    advs = 0\n",
    "    if types and p1_team:\n",
    "        for p1 in p1_team:\n",
    "            for t1 in [t.lower() for t in p1.get('types', [])]:\n",
    "                for t2 in set(types):\n",
    "                    if get_effectiveness(t1, [t2]) >= 2.0: advs += 1\n",
    "    out['p1_vs_p2_tl_type_advantages'] = advs\n",
    "    out['p1_vs_p2_tl_type_advantages_per_poke'] = advs / max(1, len(p1_team))\n",
    "    out['p2_tl_switch_rate'] = len(seen) / max(1, len(timeline[:30]))\n",
    "    return out\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. NUOVE FEATURE AVANZATE (DATA-DRIVEN, NO META)\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_information_advantage(timeline: list) -> dict:\n",
    "    p1_rev = set(); p2_rev = set(); reveal_turns_p2 = []\n",
    "    for turn in timeline[:30]:\n",
    "        t = turn.get('turn', 0)\n",
    "        if n1 := turn.get('p1_pokemon_state', {}).get('name'): p1_rev.add(n1)\n",
    "        if n2 := turn.get('p2_pokemon_state', {}).get('name'):\n",
    "            if n2 not in p2_rev: p2_rev.add(n2); reveal_turns_p2.append(t)\n",
    "    return {\n",
    "        'tl_p1_revealed_count': len(p1_rev),\n",
    "        'tl_p2_revealed_count': len(p2_rev),\n",
    "        'tl_info_advantage': len(p2_rev) - len(p1_rev),\n",
    "        'tl_p2_avg_reveal_turn': float(np.mean(reveal_turns_p2)) if reveal_turns_p2 else 30.0\n",
    "    }\n",
    "\n",
    "def extract_advanced_momentum(timeline: list) -> dict:\n",
    "    p1_immune = 0; p2_forced = 0\n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        if i == 0: continue\n",
    "        prev = timeline[i-1]\n",
    "        c1 = turn.get('p1_pokemon_state', {}).get('name')\n",
    "        p1 = prev.get('p1_pokemon_state', {}).get('name')\n",
    "        if c1 != p1 and not prev.get('p1_pokemon_state', {}).get('fainted'):\n",
    "            m2_type = (turn.get('p2_move_details') or {}).get('type', '').lower()\n",
    "            p1_types = [t.lower() for t in turn.get('p1_pokemon_state', {}).get('types', [])]\n",
    "            if m2_type and p1_types and get_effectiveness(m2_type, p1_types) == 0.0:\n",
    "                p1_immune += 1\n",
    "        c2 = turn.get('p2_pokemon_state', {}).get('name')\n",
    "        p2 = prev.get('p2_pokemon_state', {}).get('name')\n",
    "        if c2 != p2 and not prev.get('p2_pokemon_state', {}).get('fainted'):\n",
    "            if prev.get('p2_pokemon_state', {}).get('hp_pct', 1.0) < 0.50:\n",
    "                p2_forced += 1\n",
    "    return {'tl_p1_immune_switches': p1_immune, 'tl_p2_forced_switches': p2_forced}\n",
    "\n",
    "def extract_gamestate_snapshots(timeline: list) -> dict:\n",
    "    turns_lead = 0; hp_diff_10 = 0.0; hp_diff_20 = 0.0; hp_diff_30 = 0.0\n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        t = i + 1\n",
    "        h1 = turn.get('p1_pokemon_state', {}).get('hp_pct', 0)\n",
    "        h2 = turn.get('p2_pokemon_state', {}).get('hp_pct', 0)\n",
    "        if h1 > h2: turns_lead += 1\n",
    "        if t == 10: hp_diff_10 = h1 - h2\n",
    "        if t == 20: hp_diff_20 = h1 - h2\n",
    "        hp_diff_30 = h1 - h2 # Ultimo stato disponibile\n",
    "    return {\n",
    "        'tl_turns_with_hp_lead': turns_lead,\n",
    "        'tl_hp_diff_turn_10': float(hp_diff_10),\n",
    "        'tl_hp_diff_turn_20': float(hp_diff_20),\n",
    "        'tl_hp_diff_end': float(hp_diff_30)\n",
    "    }\n",
    "\n",
    "def extract_observed_mechanics(timeline: list) -> dict:\n",
    "    p1_heals = 0; p2_heals = 0; p1_frz = 0; p2_frz = 0\n",
    "    for i, turn in enumerate(timeline[:30]):\n",
    "        if i == 0: continue\n",
    "        prev = timeline[i-1]\n",
    "        p1s = turn.get('p1_pokemon_state', {}); p1s_prev = prev.get('p1_pokemon_state', {})\n",
    "        p2s = turn.get('p2_pokemon_state', {}); p2s_prev = prev.get('p2_pokemon_state', {})\n",
    "        if p1s.get('name') == p1s_prev.get('name'):\n",
    "             if p1s.get('hp_pct', 0) > p1s_prev.get('hp_pct', 0): p1_heals += 1\n",
    "        if p2s.get('name') == p2s_prev.get('name'):\n",
    "             if p2s.get('hp_pct', 0) > p2s_prev.get('hp_pct', 0): p2_heals += 1\n",
    "        if p1s.get('status') == 'frz': p1_frz = 1\n",
    "        if p2s.get('status') == 'frz': p2_frz = 1\n",
    "    return {'tl_heal_diff': p1_heals - p2_heals, 'tl_freeze_adv': p2_frz - p1_frz}\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MASTER FUNCTION V3 (COMPLETA)\n",
    "# ==============================================================================\n",
    "\n",
    "def prepare_record_features_COMPLETE(record: dict, max_turns: int = 30) -> dict:\n",
    "    out = {'battle_id': record.get('battle_id')}\n",
    "    if 'player_won' in record: out['player_won'] = int(bool(record['player_won']))\n",
    "    \n",
    "    p1_team = record.get('p1_team_details', [])\n",
    "    p2_lead = record.get('p2_lead_details', {})\n",
    "    p1_lead = p1_team[0] if p1_team else {}\n",
    "    tl = record.get('battle_timeline', [])[:max_turns]\n",
    "    \n",
    "    # --- VECCHIE FEATURE (MANTENUTE) ---\n",
    "    out.update(team_aggregate_features(p1_team, 'p1_'))\n",
    "    out.update(lead_aggregate_features(p2_lead, 'p2_lead_'))\n",
    "    out.update(ability_features(p1_team, 'p1_'))\n",
    "    out.update(lead_vs_lead_features(p1_lead, p2_lead))\n",
    "    out.update(ability_features([p2_lead], 'p2_lead_'))\n",
    "    out['p1_intimidate_vs_lead'] = int(out.get('p1_ability_intimidate_count',0) > 0)\n",
    "    out.update(summary_from_timeline(tl, p1_team))\n",
    "    out.update(extract_move_coverage_from_timeline(tl, 'p1_'))\n",
    "    out.update(extract_move_coverage_from_timeline(tl, 'p2_'))\n",
    "    out.update(extract_opponent_team_from_timeline(tl, p1_team))\n",
    "    out.update(quick_boost_features_v2(record))\n",
    "    out.update(momentum_features(tl))\n",
    "    \n",
    "    out['team_hp_sum_minus_p2lead_hp'] = out.get('p1_base_hp_sum',0) - out.get('p2_lead_base_hp',0)\n",
    "    out['team_spa_mean_minus_p2spa'] = out.get('p1_base_spa_mean',0) - out.get('p2_lead_base_spa',0)\n",
    "    out['speed_advantage'] = out.get('p1_base_spe_sum',0) - out.get('p2_lead_base_spe',0)\n",
    "    out['n_unique_types_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_lead_n_unique_types',1)\n",
    "    p1m = max(out.get('tl_p1_moves',1),1); p2m = max(out.get('tl_p2_moves',1),1)\n",
    "    out['damage_per_turn_diff'] = (out.get('tl_p1_est_damage',0)/p1m) - (out.get('tl_p2_est_damage',0)/p2m)\n",
    "    out['last_pair'] = f\"{out.get('tl_p1_last_active','')}_VS_{out.get('tl_p2_last_active','')}\"\n",
    "    \n",
    "    out.update(calculate_type_advantage(p1_team, p2_lead))\n",
    "    p2_bulk = out.get('p2_lead_base_def',1) + out.get('p2_lead_base_spd',1)\n",
    "    out['p1_se_options_vs_lead_bulk'] = out.get('p1_super_effective_options',0) / (p2_bulk + 1e-6)\n",
    "    \n",
    "    if p2_team := record.get('p2_team_details', []):\n",
    "        out.update(team_aggregate_features(p2_team, 'p2_'))\n",
    "        out['team_hp_sum_diff'] = out.get('p1_base_hp_sum',0) - out.get('p2_base_hp_sum',0)\n",
    "        out['team_spa_mean_diff'] = out.get('p1_base_spa_mean',0) - out.get('p2_base_spa_mean',0)\n",
    "        out['team_spe_mean_diff'] = out.get('p1_base_spe_mean',0) - out.get('p2_base_spe_mean',0)\n",
    "        out['n_unique_types_team_diff'] = out.get('p1_n_unique_types',0) - out.get('p2_n_unique_types',0)\n",
    "        \n",
    "    # --- NUOVE FEATURE (AGGIUNTE) ---\n",
    "    if tl:\n",
    "        out.update(extract_information_advantage(tl))\n",
    "        out.update(extract_advanced_momentum(tl))\n",
    "        out.update(extract_gamestate_snapshots(tl))\n",
    "        out.update(extract_observed_mechanics(tl))\n",
    "    else:\n",
    "        # Defaults per record senza timeline\n",
    "        out.update({\n",
    "            'tl_p1_revealed_count': 1, 'tl_p2_revealed_count': 1, 'tl_info_advantage': 0,\n",
    "            'tl_p2_avg_reveal_turn': 30.0, 'tl_p1_immune_switches': 0, 'tl_p2_forced_switches': 0,\n",
    "            'tl_turns_with_hp_lead': 0, 'tl_hp_diff_turn_10': 0.0, 'tl_hp_diff_turn_20': 0.0,\n",
    "            'tl_hp_diff_end': 0.0, 'tl_heal_diff': 0, 'tl_freeze_adv': 0\n",
    "        })\n",
    "        \n",
    "    return out\n",
    "\n",
    "def create_features_from_raw(data: list) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for b in tqdm(data, desc='FE Complete'):\n",
    "        try:\n",
    "            # Usa la funzione master completa\n",
    "            feat = prepare_record_features_COMPLETE(b)\n",
    "            if 'battle_id' not in feat: feat['battle_id'] = b.get('battle_id')\n",
    "            rows.append(feat)\n",
    "        except Exception as e:\n",
    "            rows.append({'battle_id': b.get('battle_id'), 'error': 1})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if 'player_won' in df.columns: df['player_won'] = df['player_won'].astype(int)\n",
    "    return df.fillna(0)\n",
    "\n",
    "# Esecuzione\n",
    "train_df = create_features_from_raw(train_raw)\n",
    "test_df = create_features_from_raw(test_raw)\n",
    "print('Feature shape train/test:', train_df.shape, test_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bdb01",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1191bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num FEATURES numeriche: 289\n",
      "Preprocessing completato.\n",
      "Dataset completo size: 10000\n",
      "Features: 289\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing - LightGBM gestisce bene valori raw (no scaling necessario)\n",
    "exclude_cols = ['battle_id', 'player_won']\n",
    "string_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "exclude_cols.extend(string_cols)\n",
    "\n",
    "ALL_NUMERIC_FEATURES = [c for c in train_df.columns if c not in exclude_cols]\n",
    "FEATURES = ALL_NUMERIC_FEATURES\n",
    "\n",
    "print(f'Num FEATURES numeriche: {len(FEATURES)}')\n",
    "\n",
    "# Imputazione mediana\n",
    "num_df = train_df[FEATURES].astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "medians = num_df.median()\n",
    "train_imputed = num_df.fillna(medians)\n",
    "train_preproc_df = train_imputed.copy()\n",
    "\n",
    "y = train_df['player_won'].astype(int).values\n",
    "X = train_preproc_df.values\n",
    "\n",
    "print('Preprocessing completato.')\n",
    "print('Dataset completo size:', X.shape[0])\n",
    "print('Features:', len(FEATURES))\n",
    "\n",
    "# Allinea test\n",
    "test_aligned = test_df.reindex(columns=FEATURES, fill_value=np.nan).astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "test_imputed = test_aligned.fillna(medians)\n",
    "test_preproc_df = pd.DataFrame(test_imputed.values, columns=FEATURES, index=test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463df190",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (Optuna + LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "970b6ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 19:19:48,978] A new study created in memory with name: LGBM_Pokemon_V4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature numeriche selezionate: 289\n",
      "Optuna ready: X shape (10000, 289), y shape (10000,)\n",
      "Inizio ottimizzazione Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 19:19:49,797] Trial 0 finished with value: 0.8384 and parameters: {'learning_rate': 0.18904519102765419, 'n_estimators': 400, 'num_leaves': 50, 'max_depth': 3, 'min_child_samples': 65, 'subsample': 0.8733912768784295, 'subsample_freq': 7, 'colsample_bytree': 0.9149167555916753, 'reg_alpha': 2.421275327166644, 'reg_lambda': 7.131882789133064e-07, 'min_split_gain': 0.3045255421333785}. Best is trial 0 with value: 0.8384.\n",
      "[I 2025-11-08 19:19:51,805] Trial 1 finished with value: 0.8387 and parameters: {'learning_rate': 0.08961174206814042, 'n_estimators': 1000, 'num_leaves': 133, 'max_depth': 8, 'min_child_samples': 24, 'subsample': 0.6360961119647561, 'subsample_freq': 5, 'colsample_bytree': 0.8499862058017057, 'reg_alpha': 7.183961014067617e-08, 'reg_lambda': 7.7507482097572105, 'min_split_gain': 0.15687167888162334}. Best is trial 1 with value: 0.8387.\n",
      "[I 2025-11-08 19:19:56,189] Trial 2 finished with value: 0.8389 and parameters: {'learning_rate': 0.014514817450789967, 'n_estimators': 500, 'num_leaves': 40, 'max_depth': 6, 'min_child_samples': 43, 'subsample': 0.9139185435056985, 'subsample_freq': 7, 'colsample_bytree': 0.9665732303053155, 'reg_alpha': 0.7354762446644248, 'reg_lambda': 9.757813324777584e-07, 'min_split_gain': 0.3577445705282952}. Best is trial 2 with value: 0.8389.\n",
      "[I 2025-11-08 19:19:58,999] Trial 3 finished with value: 0.8403 and parameters: {'learning_rate': 0.01382087296829915, 'n_estimators': 400, 'num_leaves': 79, 'max_depth': 6, 'min_child_samples': 93, 'subsample': 0.674559872862193, 'subsample_freq': 6, 'colsample_bytree': 0.7928292536781488, 'reg_alpha': 6.49730678703761e-05, 'reg_lambda': 0.0013530516828563117, 'min_split_gain': 0.03021934982832275}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:01,443] Trial 4 finished with value: 0.8337 and parameters: {'learning_rate': 0.010851824869239142, 'n_estimators': 300, 'num_leaves': 127, 'max_depth': 5, 'min_child_samples': 24, 'subsample': 0.9858564954475488, 'subsample_freq': 6, 'colsample_bytree': 0.6847865457232285, 'reg_alpha': 9.591629620544254e-07, 'reg_lambda': 1.5583051008438104e-08, 'min_split_gain': 0.3319396202933849}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:03,770] Trial 5 finished with value: 0.8385999999999999 and parameters: {'learning_rate': 0.01842123746955939, 'n_estimators': 800, 'num_leaves': 40, 'max_depth': 3, 'min_child_samples': 75, 'subsample': 0.6928545020427143, 'subsample_freq': 7, 'colsample_bytree': 0.8898532106991122, 'reg_alpha': 0.000562905768055538, 'reg_lambda': 0.1293254730238288, 'min_split_gain': 0.495166995472507}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:05,085] Trial 6 finished with value: 0.8364 and parameters: {'learning_rate': 0.08707725648803258, 'n_estimators': 350, 'num_leaves': 53, 'max_depth': 10, 'min_child_samples': 69, 'subsample': 0.9977075923061454, 'subsample_freq': 0, 'colsample_bytree': 0.8172759055467008, 'reg_alpha': 2.963049755395422, 'reg_lambda': 2.445913907667512, 'min_split_gain': 0.4252559874517783}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:07,122] Trial 7 finished with value: 0.8389 and parameters: {'learning_rate': 0.03303298124096645, 'n_estimators': 750, 'num_leaves': 44, 'max_depth': 4, 'min_child_samples': 22, 'subsample': 0.9722020762431338, 'subsample_freq': 0, 'colsample_bytree': 0.7269709956004932, 'reg_alpha': 0.012438351768223117, 'reg_lambda': 2.075390654032251e-07, 'min_split_gain': 0.14269952404361025}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:11,156] Trial 8 finished with value: 0.8398 and parameters: {'learning_rate': 0.024182015741778033, 'n_estimators': 550, 'num_leaves': 49, 'max_depth': 10, 'min_child_samples': 37, 'subsample': 0.9173447554296432, 'subsample_freq': 6, 'colsample_bytree': 0.7592182749770804, 'reg_alpha': 9.297661730067233e-05, 'reg_lambda': 0.0007914440190161723, 'min_split_gain': 0.30838273564199475}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:16,596] Trial 9 finished with value: 0.8372999999999999 and parameters: {'learning_rate': 0.025817878301855418, 'n_estimators': 350, 'num_leaves': 77, 'max_depth': 12, 'min_child_samples': 18, 'subsample': 0.9395887467799886, 'subsample_freq': 2, 'colsample_bytree': 0.9243584978761088, 'reg_alpha': 0.029637343058897234, 'reg_lambda': 0.002645487103763037, 'min_split_gain': 0.3849359407564744}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:17,686] Trial 10 finished with value: 0.8366 and parameters: {'learning_rate': 0.043851454667008356, 'n_estimators': 100, 'num_leaves': 98, 'max_depth': 7, 'min_child_samples': 98, 'subsample': 0.7508454936778274, 'subsample_freq': 4, 'colsample_bytree': 0.6210329734472778, 'reg_alpha': 8.454645616592006e-06, 'reg_lambda': 2.7102020151223696e-05, 'min_split_gain': 0.004304917803158025}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:22,346] Trial 11 finished with value: 0.8401 and parameters: {'learning_rate': 0.021224134590333996, 'n_estimators': 650, 'num_leaves': 80, 'max_depth': 9, 'min_child_samples': 45, 'subsample': 0.8266006312625108, 'subsample_freq': 5, 'colsample_bytree': 0.7528856930789928, 'reg_alpha': 5.4991489115019255e-05, 'reg_lambda': 0.0007648666301693627, 'min_split_gain': 0.2066468198933281}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:28,632] Trial 12 finished with value: 0.8391 and parameters: {'learning_rate': 0.010625756023934499, 'n_estimators': 700, 'num_leaves': 87, 'max_depth': 9, 'min_child_samples': 99, 'subsample': 0.8100218340179667, 'subsample_freq': 3, 'colsample_bytree': 0.7872406804264414, 'reg_alpha': 0.0006224725832918142, 'reg_lambda': 0.012149157010187196, 'min_split_gain': 0.0026896091327184013}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:29,916] Trial 13 finished with value: 0.8370000000000001 and parameters: {'learning_rate': 0.057535759151629104, 'n_estimators': 100, 'num_leaves': 107, 'max_depth': 7, 'min_child_samples': 51, 'subsample': 0.8094119485891669, 'subsample_freq': 5, 'colsample_bytree': 0.7012205633031099, 'reg_alpha': 1.1345028501611662e-05, 'reg_lambda': 4.896876345583838e-05, 'min_split_gain': 0.141091408146292}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:34,414] Trial 14 finished with value: 0.8381000000000001 and parameters: {'learning_rate': 0.01748250616481657, 'n_estimators': 650, 'num_leaves': 70, 'max_depth': 12, 'min_child_samples': 80, 'subsample': 0.717392942186759, 'subsample_freq': 4, 'colsample_bytree': 0.6417037184740615, 'reg_alpha': 1.8757396347805285e-08, 'reg_lambda': 0.03444338415485069, 'min_split_gain': 0.21575354476889463}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:36,707] Trial 15 finished with value: 0.8402999999999998 and parameters: {'learning_rate': 0.03573243652966497, 'n_estimators': 900, 'num_leaves': 113, 'max_depth': 9, 'min_child_samples': 84, 'subsample': 0.6418081360920848, 'subsample_freq': 5, 'colsample_bytree': 0.8337572400185858, 'reg_alpha': 0.010535534767654006, 'reg_lambda': 7.68373810727183e-05, 'min_split_gain': 0.07215949430800994}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:37,510] Trial 16 finished with value: 0.8345999999999998 and parameters: {'learning_rate': 0.21778987945785797, 'n_estimators': 950, 'num_leaves': 113, 'max_depth': 6, 'min_child_samples': 86, 'subsample': 0.6081373163025922, 'subsample_freq': 2, 'colsample_bytree': 0.8428287582213172, 'reg_alpha': 0.01364649320704025, 'reg_lambda': 4.6194722630330966e-05, 'min_split_gain': 0.07553893260057201}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:38,915] Trial 17 finished with value: 0.8384 and parameters: {'learning_rate': 0.061481841150499456, 'n_estimators': 850, 'num_leaves': 150, 'max_depth': 5, 'min_child_samples': 88, 'subsample': 0.6617196385090992, 'subsample_freq': 6, 'colsample_bytree': 0.9871318367168423, 'reg_alpha': 0.1148953127346569, 'reg_lambda': 5.44009660005122e-06, 'min_split_gain': 0.07178875452214856}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:40,612] Trial 18 finished with value: 0.8384 and parameters: {'learning_rate': 0.03531301291929886, 'n_estimators': 200, 'num_leaves': 20, 'max_depth': 8, 'min_child_samples': 60, 'subsample': 0.7435103491981531, 'subsample_freq': 3, 'colsample_bytree': 0.8750514239580919, 'reg_alpha': 0.005483372311826173, 'reg_lambda': 0.25451333859253367, 'min_split_gain': 0.06579273469500613}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:41,799] Trial 19 finished with value: 0.8347 and parameters: {'learning_rate': 0.10650181075392501, 'n_estimators': 550, 'num_leaves': 119, 'max_depth': 11, 'min_child_samples': 92, 'subsample': 0.6009649256266827, 'subsample_freq': 5, 'colsample_bytree': 0.7989205497284554, 'reg_alpha': 0.0013787226322078902, 'reg_lambda': 0.00027127189959274243, 'min_split_gain': 0.10334096308808091}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:42,871] Trial 20 finished with value: 0.8349 and parameters: {'learning_rate': 0.1506477172806852, 'n_estimators': 900, 'num_leaves': 93, 'max_depth': 9, 'min_child_samples': 78, 'subsample': 0.6931679619739562, 'subsample_freq': 6, 'colsample_bytree': 0.8235383344476128, 'reg_alpha': 0.17877635390025473, 'reg_lambda': 0.008035971040241608, 'min_split_gain': 0.24383810618677085}. Best is trial 3 with value: 0.8403.\n",
      "[I 2025-11-08 19:20:47,028] Trial 21 finished with value: 0.8413 and parameters: {'learning_rate': 0.02262093820374529, 'n_estimators': 650, 'num_leaves': 66, 'max_depth': 9, 'min_child_samples': 53, 'subsample': 0.8606001500215199, 'subsample_freq': 5, 'colsample_bytree': 0.7585270364195598, 'reg_alpha': 9.59334579981118e-05, 'reg_lambda': 0.0005130298080980534, 'min_split_gain': 0.19147260319746517}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:20:53,735] Trial 22 finished with value: 0.8412000000000001 and parameters: {'learning_rate': 0.014579391066546743, 'n_estimators': 550, 'num_leaves': 66, 'max_depth': 10, 'min_child_samples': 57, 'subsample': 0.8470915434171354, 'subsample_freq': 4, 'colsample_bytree': 0.7875026957639324, 'reg_alpha': 1.669855339287874e-06, 'reg_lambda': 0.0001362655324334608, 'min_split_gain': 0.03628177555254836}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:00,790] Trial 23 finished with value: 0.8388 and parameters: {'learning_rate': 0.013653011772175448, 'n_estimators': 450, 'num_leaves': 66, 'max_depth': 11, 'min_child_samples': 32, 'subsample': 0.8511202732197656, 'subsample_freq': 4, 'colsample_bytree': 0.7611712876983276, 'reg_alpha': 4.593780020430133e-07, 'reg_lambda': 0.00026065519279040266, 'min_split_gain': 0.030278181152497214}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:06,674] Trial 24 finished with value: 0.8383999999999998 and parameters: {'learning_rate': 0.014374797002203076, 'n_estimators': 600, 'num_leaves': 63, 'max_depth': 10, 'min_child_samples': 57, 'subsample': 0.7802292468176967, 'subsample_freq': 3, 'colsample_bytree': 0.6767365511585971, 'reg_alpha': 2.4304272432514505e-06, 'reg_lambda': 8.401796155090339e-06, 'min_split_gain': 0.17448581312009498}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:12,954] Trial 25 finished with value: 0.8379999999999999 and parameters: {'learning_rate': 0.010611409835630704, 'n_estimators': 450, 'num_leaves': 74, 'max_depth': 8, 'min_child_samples': 50, 'subsample': 0.8844369046633126, 'subsample_freq': 2, 'colsample_bytree': 0.7801796074931086, 'reg_alpha': 6.82333929718025e-05, 'reg_lambda': 0.0021374971307038648, 'min_split_gain': 0.04113554383068736}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:17,210] Trial 26 finished with value: 0.8378 and parameters: {'learning_rate': 0.025865361303102092, 'n_estimators': 250, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 10, 'subsample': 0.8449526268153756, 'subsample_freq': 4, 'colsample_bytree': 0.7242430938258078, 'reg_alpha': 8.378103735842848e-06, 'reg_lambda': 0.051782531827366335, 'min_split_gain': 0.11346026578689172}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:20,619] Trial 27 finished with value: 0.8411 and parameters: {'learning_rate': 0.017921716340373185, 'n_estimators': 550, 'num_leaves': 30, 'max_depth': 6, 'min_child_samples': 70, 'subsample': 0.7743423061228928, 'subsample_freq': 6, 'colsample_bytree': 0.7299186014691988, 'reg_alpha': 1.4899947177142902e-07, 'reg_lambda': 0.004086133853472228, 'min_split_gain': 0.11123624095748863}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:23,632] Trial 28 finished with value: 0.8411 and parameters: {'learning_rate': 0.019924525640189684, 'n_estimators': 700, 'num_leaves': 22, 'max_depth': 7, 'min_child_samples': 71, 'subsample': 0.7806327502818341, 'subsample_freq': 5, 'colsample_bytree': 0.7285339176667243, 'reg_alpha': 1.7383264286813033e-07, 'reg_lambda': 0.009947365009159766, 'min_split_gain': 0.18870817848594257}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:24,361] Trial 29 finished with value: 0.8335000000000001 and parameters: {'learning_rate': 0.27424383857086476, 'n_estimators': 550, 'num_leaves': 31, 'max_depth': 5, 'min_child_samples': 64, 'subsample': 0.8808500093713054, 'subsample_freq': 7, 'colsample_bytree': 0.6538814885961122, 'reg_alpha': 1.5517159400137706e-08, 'reg_lambda': 4.669320686086149e-06, 'min_split_gain': 0.106526687792839}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:26,322] Trial 30 finished with value: 0.8398 and parameters: {'learning_rate': 0.04549871797102196, 'n_estimators': 600, 'num_leaves': 32, 'max_depth': 10, 'min_child_samples': 64, 'subsample': 0.8637382396117388, 'subsample_freq': 4, 'colsample_bytree': 0.702006992800312, 'reg_alpha': 1.0921963332615909e-07, 'reg_lambda': 0.494663392446525, 'min_split_gain': 0.27823576102070713}. Best is trial 21 with value: 0.8413.\n",
      "[I 2025-11-08 19:21:29,512] Trial 31 finished with value: 0.842 and parameters: {'learning_rate': 0.018989888452322808, 'n_estimators': 750, 'num_leaves': 23, 'max_depth': 7, 'min_child_samples': 70, 'subsample': 0.7762912136929895, 'subsample_freq': 5, 'colsample_bytree': 0.7278952828528387, 'reg_alpha': 1.792485274667382e-07, 'reg_lambda': 0.007384740256695711, 'min_split_gain': 0.1798421534506041}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:21:33,350] Trial 32 finished with value: 0.8414999999999999 and parameters: {'learning_rate': 0.01623949569633662, 'n_estimators': 750, 'num_leaves': 28, 'max_depth': 8, 'min_child_samples': 53, 'subsample': 0.7741224223484309, 'subsample_freq': 6, 'colsample_bytree': 0.7533091584973858, 'reg_alpha': 1.6361088399265076e-06, 'reg_lambda': 0.00022641245388788637, 'min_split_gain': 0.24049790831373707}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:21:38,405] Trial 33 finished with value: 0.8402 and parameters: {'learning_rate': 0.0157329396398066, 'n_estimators': 800, 'num_leaves': 55, 'max_depth': 8, 'min_child_samples': 53, 'subsample': 0.8249702305408014, 'subsample_freq': 5, 'colsample_bytree': 0.7651501770659623, 'reg_alpha': 2.019293214960462e-06, 'reg_lambda': 0.00019620675648014254, 'min_split_gain': 0.26142533988339456}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:21:41,394] Trial 34 finished with value: 0.8393999999999998 and parameters: {'learning_rate': 0.028934303608629364, 'n_estimators': 700, 'num_leaves': 45, 'max_depth': 8, 'min_child_samples': 58, 'subsample': 0.7470003385960093, 'subsample_freq': 7, 'colsample_bytree': 0.7456132081241047, 'reg_alpha': 5.084074608631535e-07, 'reg_lambda': 1.328847716321087e-06, 'min_split_gain': 0.22492610190100507}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:21:44,759] Trial 35 finished with value: 0.8385 and parameters: {'learning_rate': 0.0230359919863586, 'n_estimators': 800, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 39, 'subsample': 0.8992121110307848, 'subsample_freq': 6, 'colsample_bytree': 0.8101596941482766, 'reg_alpha': 2.691690217074304e-05, 'reg_lambda': 1.6643618541109784e-05, 'min_split_gain': 0.2784802301835764}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:21:50,076] Trial 36 finished with value: 0.841 and parameters: {'learning_rate': 0.012469444892799655, 'n_estimators': 750, 'num_leaves': 25, 'max_depth': 9, 'min_child_samples': 45, 'subsample': 0.8363022693040938, 'subsample_freq': 4, 'colsample_bytree': 0.6994505811123044, 'reg_alpha': 4.053831712606038e-08, 'reg_lambda': 0.00012367628239359633, 'min_split_gain': 0.168598628951861}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:21:55,267] Trial 37 finished with value: 0.8407 and parameters: {'learning_rate': 0.01310546524035737, 'n_estimators': 1000, 'num_leaves': 39, 'max_depth': 8, 'min_child_samples': 62, 'subsample': 0.7947638267506189, 'subsample_freq': 5, 'colsample_bytree': 0.6690971847524216, 'reg_alpha': 2.1359810651055765e-06, 'reg_lambda': 0.0007762635451029454, 'min_split_gain': 0.3336542517576446}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:00,899] Trial 38 finished with value: 0.8360999999999998 and parameters: {'learning_rate': 0.016559242790851067, 'n_estimators': 650, 'num_leaves': 57, 'max_depth': 10, 'min_child_samples': 33, 'subsample': 0.7237946848513005, 'subsample_freq': 7, 'colsample_bytree': 0.8579036105818206, 'reg_alpha': 0.0001794763107143432, 'reg_lambda': 8.655883850811445e-08, 'min_split_gain': 0.24483231953579937}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:03,880] Trial 39 finished with value: 0.8385999999999999 and parameters: {'learning_rate': 0.029687239903642623, 'n_estimators': 450, 'num_leaves': 50, 'max_depth': 9, 'min_child_samples': 49, 'subsample': 0.7653368170173708, 'subsample_freq': 3, 'colsample_bytree': 0.7758551859507425, 'reg_alpha': 4.546491262735492e-06, 'reg_lambda': 0.03408565700856462, 'min_split_gain': 0.15080640018210836}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:07,587] Trial 40 finished with value: 0.8412000000000001 and parameters: {'learning_rate': 0.020872836040214362, 'n_estimators': 750, 'num_leaves': 86, 'max_depth': 7, 'min_child_samples': 67, 'subsample': 0.9418410626563422, 'subsample_freq': 6, 'colsample_bytree': 0.6018875516353454, 'reg_alpha': 6.161650316760787e-07, 'reg_lambda': 7.836649829764062, 'min_split_gain': 0.38866473731599493}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:11,044] Trial 41 finished with value: 0.8401 and parameters: {'learning_rate': 0.02146856162141149, 'n_estimators': 750, 'num_leaves': 93, 'max_depth': 7, 'min_child_samples': 68, 'subsample': 0.927974736802953, 'subsample_freq': 6, 'colsample_bytree': 0.6226518608779322, 'reg_alpha': 4.905654908773986e-07, 'reg_lambda': 0.4774347832778558, 'min_split_gain': 0.47827272654961894}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:14,943] Trial 42 finished with value: 0.8394999999999999 and parameters: {'learning_rate': 0.019306588556329527, 'n_estimators': 850, 'num_leaves': 83, 'max_depth': 6, 'min_child_samples': 74, 'subsample': 0.9548670981476175, 'subsample_freq': 5, 'colsample_bytree': 0.9006380278496489, 'reg_alpha': 1.0946853378651702e-06, 'reg_lambda': 3.915164543189039, 'min_split_gain': 0.30676236503747684}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:20,001] Trial 43 finished with value: 0.8396000000000001 and parameters: {'learning_rate': 0.01593283647134647, 'n_estimators': 600, 'num_leaves': 72, 'max_depth': 7, 'min_child_samples': 55, 'subsample': 0.9584292588502703, 'subsample_freq': 6, 'colsample_bytree': 0.8017854745559512, 'reg_alpha': 5.590600447069757e-08, 'reg_lambda': 0.0006573315990900339, 'min_split_gain': 0.38328816334544047}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:25,629] Trial 44 finished with value: 0.842 and parameters: {'learning_rate': 0.010059188447271352, 'n_estimators': 750, 'num_leaves': 26, 'max_depth': 8, 'min_child_samples': 67, 'subsample': 0.8665784777645577, 'subsample_freq': 7, 'colsample_bytree': 0.7454610447167216, 'reg_alpha': 1.8307322956293333e-05, 'reg_lambda': 7.990798346347656, 'min_split_gain': 0.42313143389286234}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:31,992] Trial 45 finished with value: 0.8404999999999999 and parameters: {'learning_rate': 0.011394214415356867, 'n_estimators': 850, 'num_leaves': 42, 'max_depth': 8, 'min_child_samples': 59, 'subsample': 0.8592619621602535, 'subsample_freq': 7, 'colsample_bytree': 0.7402903654840322, 'reg_alpha': 2.5615020610112427e-05, 'reg_lambda': 1.4831100677437288, 'min_split_gain': 0.451668007481336}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:37,114] Trial 46 finished with value: 0.8394999999999999 and parameters: {'learning_rate': 0.013111346174102693, 'n_estimators': 650, 'num_leaves': 29, 'max_depth': 9, 'min_child_samples': 41, 'subsample': 0.7983563021721529, 'subsample_freq': 7, 'colsample_bytree': 0.7152026632063562, 'reg_alpha': 0.00026079876449303736, 'reg_lambda': 0.0015454395476690618, 'min_split_gain': 0.1946899574680497}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:42,338] Trial 47 finished with value: 0.8401 and parameters: {'learning_rate': 0.011344152052868867, 'n_estimators': 500, 'num_leaves': 37, 'max_depth': 11, 'min_child_samples': 74, 'subsample': 0.9059156554423263, 'subsample_freq': 5, 'colsample_bytree': 0.775726131225487, 'reg_alpha': 1.7314394941618235e-05, 'reg_lambda': 0.10563090123858541, 'min_split_gain': 0.3477119079386584}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:48,174] Trial 48 finished with value: 0.8394999999999999 and parameters: {'learning_rate': 0.010325873853031225, 'n_estimators': 700, 'num_leaves': 26, 'max_depth': 9, 'min_child_samples': 54, 'subsample': 0.8191467085264516, 'subsample_freq': 6, 'colsample_bytree': 0.74385817367856, 'reg_alpha': 4.876467544367416e-06, 'reg_lambda': 1.8902944259951506e-06, 'min_split_gain': 0.22943231516126344}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:53,883] Trial 49 finished with value: 0.8402999999999998 and parameters: {'learning_rate': 0.01526020791085087, 'n_estimators': 800, 'num_leaves': 45, 'max_depth': 10, 'min_child_samples': 46, 'subsample': 0.8934390688971376, 'subsample_freq': 4, 'colsample_bytree': 0.9388166149323841, 'reg_alpha': 2.729151891632886e-07, 'reg_lambda': 1.945112368578188e-05, 'min_split_gain': 0.2870974737817798}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:55,298] Trial 50 finished with value: 0.8394999999999999 and parameters: {'learning_rate': 0.04094031609804646, 'n_estimators': 750, 'num_leaves': 20, 'max_depth': 3, 'min_child_samples': 81, 'subsample': 0.8371653996305919, 'subsample_freq': 5, 'colsample_bytree': 0.7112738776158282, 'reg_alpha': 0.001359909127948859, 'reg_lambda': 7.786994856417587e-05, 'min_split_gain': 0.4074579939226093}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:22:58,595] Trial 51 finished with value: 0.8412000000000001 and parameters: {'learning_rate': 0.023878756294001064, 'n_estimators': 750, 'num_leaves': 90, 'max_depth': 7, 'min_child_samples': 67, 'subsample': 0.8665253124268573, 'subsample_freq': 6, 'colsample_bytree': 0.6037016186399846, 'reg_alpha': 6.513406641923065e-07, 'reg_lambda': 8.921526465287451, 'min_split_gain': 0.362221413354509}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:03,050] Trial 52 finished with value: 0.8396000000000001 and parameters: {'learning_rate': 0.01783976458370283, 'n_estimators': 650, 'num_leaves': 102, 'max_depth': 8, 'min_child_samples': 62, 'subsample': 0.991886511955891, 'subsample_freq': 7, 'colsample_bytree': 0.7954035817363145, 'reg_alpha': 1.531673183177595e-06, 'reg_lambda': 2.1090440521370595, 'min_split_gain': 0.45461990856940393}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:06,029] Trial 53 finished with value: 0.8394 and parameters: {'learning_rate': 0.02973143652530165, 'n_estimators': 700, 'num_leaves': 85, 'max_depth': 8, 'min_child_samples': 66, 'subsample': 0.9145576032602108, 'subsample_freq': 6, 'colsample_bytree': 0.7575027250386608, 'reg_alpha': 4.062964799009784e-06, 'reg_lambda': 5.182504708129288, 'min_split_gain': 0.4188891181503219}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:11,502] Trial 54 finished with value: 0.8384 and parameters: {'learning_rate': 0.012140363834902763, 'n_estimators': 900, 'num_leaves': 79, 'max_depth': 7, 'min_child_samples': 72, 'subsample': 0.9311699190764121, 'subsample_freq': 5, 'colsample_bytree': 0.6899894113776277, 'reg_alpha': 2.949893801742628e-08, 'reg_lambda': 1.050816182030316, 'min_split_gain': 0.3862527434272942}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:14,908] Trial 55 finished with value: 0.8412 and parameters: {'learning_rate': 0.020219075706625355, 'n_estimators': 600, 'num_leaves': 101, 'max_depth': 6, 'min_child_samples': 49, 'subsample': 0.8108480319046786, 'subsample_freq': 7, 'colsample_bytree': 0.6512465214526315, 'reg_alpha': 4.2913033070677084e-05, 'reg_lambda': 0.00045554590988265524, 'min_split_gain': 0.13477583696579873}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:16,586] Trial 56 finished with value: 0.8402 and parameters: {'learning_rate': 0.08157672910534254, 'n_estimators': 800, 'num_leaves': 67, 'max_depth': 9, 'min_child_samples': 77, 'subsample': 0.8745394324836017, 'subsample_freq': 1, 'colsample_bytree': 0.8246324678622463, 'reg_alpha': 0.00011529531116557027, 'reg_lambda': 0.005200994804653095, 'min_split_gain': 0.4387080497710001}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:20,544] Trial 57 finished with value: 0.8392000000000002 and parameters: {'learning_rate': 0.01423922697442176, 'n_estimators': 850, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 56, 'subsample': 0.7269506686390759, 'subsample_freq': 6, 'colsample_bytree': 0.7700732755803584, 'reg_alpha': 1.2365345931302219e-05, 'reg_lambda': 0.017079137285333067, 'min_split_gain': 0.49191612122388195}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:24,110] Trial 58 finished with value: 0.8393 and parameters: {'learning_rate': 0.021645856622681276, 'n_estimators': 500, 'num_leaves': 26, 'max_depth': 8, 'min_child_samples': 60, 'subsample': 0.9768490984639231, 'subsample_freq': 4, 'colsample_bytree': 0.7893478050629804, 'reg_alpha': 0.0007348532690763724, 'reg_lambda': 3.583904539894564e-07, 'min_split_gain': 0.2041026537274894}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:26,363] Trial 59 finished with value: 0.8392999999999999 and parameters: {'learning_rate': 0.026256433098141605, 'n_estimators': 950, 'num_leaves': 131, 'max_depth': 5, 'min_child_samples': 52, 'subsample': 0.7569592274786517, 'subsample_freq': 5, 'colsample_bytree': 0.7366348619869884, 'reg_alpha': 6.235742295390557e-06, 'reg_lambda': 4.1509378072607514e-05, 'min_split_gain': 0.32753774958392673}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:30,428] Trial 60 finished with value: 0.8402 and parameters: {'learning_rate': 0.017318363377065406, 'n_estimators': 650, 'num_leaves': 148, 'max_depth': 7, 'min_child_samples': 62, 'subsample': 0.7861842244591377, 'subsample_freq': 6, 'colsample_bytree': 0.861174127315684, 'reg_alpha': 3.2136386324902657e-07, 'reg_lambda': 0.00014302888794989117, 'min_split_gain': 0.1661924931275781}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:33,662] Trial 61 finished with value: 0.8409000000000001 and parameters: {'learning_rate': 0.026211669061677524, 'n_estimators': 750, 'num_leaves': 91, 'max_depth': 7, 'min_child_samples': 67, 'subsample': 0.8697741562315455, 'subsample_freq': 6, 'colsample_bytree': 0.6002966142824185, 'reg_alpha': 1.1657504383887865e-07, 'reg_lambda': 3.077982472976007, 'min_split_gain': 0.36467020987928117}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:37,125] Trial 62 finished with value: 0.8411 and parameters: {'learning_rate': 0.02468203348089517, 'n_estimators': 750, 'num_leaves': 89, 'max_depth': 7, 'min_child_samples': 69, 'subsample': 0.8519382451717792, 'subsample_freq': 6, 'colsample_bytree': 0.6063879535563652, 'reg_alpha': 8.026831259262322e-07, 'reg_lambda': 9.075296329489342, 'min_split_gain': 0.37655188334128437}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:40,119] Trial 63 finished with value: 0.8404 and parameters: {'learning_rate': 0.03297814224071374, 'n_estimators': 700, 'num_leaves': 98, 'max_depth': 8, 'min_child_samples': 66, 'subsample': 0.8862310696682647, 'subsample_freq': 6, 'colsample_bytree': 0.627759588800586, 'reg_alpha': 7.700472610794892e-07, 'reg_lambda': 8.958978706137103, 'min_split_gain': 0.4233520969636666}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:46,806] Trial 64 finished with value: 0.8398999999999999 and parameters: {'learning_rate': 0.010107260527480193, 'n_estimators': 800, 'num_leaves': 74, 'max_depth': 9, 'min_child_samples': 76, 'subsample': 0.8338323607873012, 'subsample_freq': 7, 'colsample_bytree': 0.6379189962910037, 'reg_alpha': 6.914090281904035e-08, 'reg_lambda': 0.44721068224294985, 'min_split_gain': 0.40100427706472647}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:49,770] Trial 65 finished with value: 0.8398 and parameters: {'learning_rate': 0.022655230374730412, 'n_estimators': 750, 'num_leaves': 81, 'max_depth': 6, 'min_child_samples': 82, 'subsample': 0.8590554881666854, 'subsample_freq': 5, 'colsample_bytree': 0.6691571852461057, 'reg_alpha': 2.29177155216448e-07, 'reg_lambda': 0.9432280932644848, 'min_split_gain': 0.18641440542315244}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:53,320] Trial 66 finished with value: 0.8413999999999999 and parameters: {'learning_rate': 0.0147383918453807, 'n_estimators': 600, 'num_leaves': 109, 'max_depth': 7, 'min_child_samples': 71, 'subsample': 0.7021495418410265, 'subsample_freq': 4, 'colsample_bytree': 0.7526923900479892, 'reg_alpha': 6.451592150647669, 'reg_lambda': 0.23762541096669496, 'min_split_gain': 0.257432726835355}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:23:58,477] Trial 67 finished with value: 0.841 and parameters: {'learning_rate': 0.014616304830552745, 'n_estimators': 600, 'num_leaves': 119, 'max_depth': 10, 'min_child_samples': 72, 'subsample': 0.6909579862839881, 'subsample_freq': 4, 'colsample_bytree': 0.8080163215421099, 'reg_alpha': 0.18141831230156216, 'reg_lambda': 0.06366253567514778, 'min_split_gain': 0.26461355818773963}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:24:04,083] Trial 68 finished with value: 0.8394999999999999 and parameters: {'learning_rate': 0.01193310542618104, 'n_estimators': 550, 'num_leaves': 109, 'max_depth': 8, 'min_child_samples': 47, 'subsample': 0.671144146302324, 'subsample_freq': 4, 'colsample_bytree': 0.7176784575684106, 'reg_alpha': 0.0053628879122776104, 'reg_lambda': 0.1939647190891534, 'min_split_gain': 0.12442809711976294}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:24:08,225] Trial 69 finished with value: 0.8390000000000001 and parameters: {'learning_rate': 0.019078504627335315, 'n_estimators': 700, 'num_leaves': 61, 'max_depth': 9, 'min_child_samples': 64, 'subsample': 0.6473250461462033, 'subsample_freq': 3, 'colsample_bytree': 0.7529051951973115, 'reg_alpha': 0.861714895626618, 'reg_lambda': 0.0024992669011550915, 'min_split_gain': 0.08541619992243465}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:24:10,822] Trial 70 finished with value: 0.8374 and parameters: {'learning_rate': 0.016409151314747326, 'n_estimators': 400, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 57, 'subsample': 0.7086677382894583, 'subsample_freq': 5, 'colsample_bytree': 0.8365483014247371, 'reg_alpha': 9.51227538147629, 'reg_lambda': 0.02312607150416869, 'min_split_gain': 0.2354550016222526}. Best is trial 31 with value: 0.842.\n",
      "[I 2025-11-08 19:24:14,956] Trial 71 finished with value: 0.843 and parameters: {'learning_rate': 0.013679823261876542, 'n_estimators': 650, 'num_leaves': 97, 'max_depth': 7, 'min_child_samples': 70, 'subsample': 0.6161988793364829, 'subsample_freq': 4, 'colsample_bytree': 0.6136973726187104, 'reg_alpha': 2.261339389106705e-06, 'reg_lambda': 1.8764227095178463, 'min_split_gain': 0.3554832229238166}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:19,510] Trial 72 finished with value: 0.8416 and parameters: {'learning_rate': 0.014160318630613783, 'n_estimators': 650, 'num_leaves': 97, 'max_depth': 7, 'min_child_samples': 79, 'subsample': 0.6299514092463769, 'subsample_freq': 3, 'colsample_bytree': 0.7877714264797687, 'reg_alpha': 2.9835769325343455e-06, 'reg_lambda': 3.9694054856076266, 'min_split_gain': 0.21252965816752717}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:24,344] Trial 73 finished with value: 0.8422000000000001 and parameters: {'learning_rate': 0.013385408370268496, 'n_estimators': 650, 'num_leaves': 106, 'max_depth': 8, 'min_child_samples': 84, 'subsample': 0.6228020600436902, 'subsample_freq': 3, 'colsample_bytree': 0.7835606731709108, 'reg_alpha': 4.0306840927220365e-05, 'reg_lambda': 0.8549637458255808, 'min_split_gain': 0.21326612410152126}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:28,766] Trial 74 finished with value: 0.8423 and parameters: {'learning_rate': 0.013086255966609428, 'n_estimators': 650, 'num_leaves': 109, 'max_depth': 8, 'min_child_samples': 90, 'subsample': 0.6058842693209614, 'subsample_freq': 3, 'colsample_bytree': 0.7639246486534157, 'reg_alpha': 4.2088124744024254e-05, 'reg_lambda': 0.9775876471559688, 'min_split_gain': 0.2096809479149574}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:33,218] Trial 75 finished with value: 0.8421 and parameters: {'learning_rate': 0.013149735297697595, 'n_estimators': 600, 'num_leaves': 118, 'max_depth': 8, 'min_child_samples': 91, 'subsample': 0.6216911472533111, 'subsample_freq': 3, 'colsample_bytree': 0.7830962143936887, 'reg_alpha': 4.562140060690196e-05, 'reg_lambda': 0.8831895441330129, 'min_split_gain': 0.21655376209193736}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:37,567] Trial 76 finished with value: 0.8418000000000001 and parameters: {'learning_rate': 0.013038262016201604, 'n_estimators': 650, 'num_leaves': 120, 'max_depth': 8, 'min_child_samples': 91, 'subsample': 0.6224084501549567, 'subsample_freq': 2, 'colsample_bytree': 0.7848708551690505, 'reg_alpha': 3.491498281219935e-05, 'reg_lambda': 0.7913187478219329, 'min_split_gain': 0.2103329544403434}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:41,822] Trial 77 finished with value: 0.8412000000000001 and parameters: {'learning_rate': 0.013030612253803484, 'n_estimators': 650, 'num_leaves': 122, 'max_depth': 8, 'min_child_samples': 95, 'subsample': 0.6160690888355042, 'subsample_freq': 2, 'colsample_bytree': 0.8201236240342703, 'reg_alpha': 3.942512861046169e-05, 'reg_lambda': 0.7650565154550413, 'min_split_gain': 0.2155505847072071}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:45,667] Trial 78 finished with value: 0.8404999999999999 and parameters: {'learning_rate': 0.011261299144881177, 'n_estimators': 500, 'num_leaves': 114, 'max_depth': 8, 'min_child_samples': 88, 'subsample': 0.63146326882812, 'subsample_freq': 2, 'colsample_bytree': 0.7834675956985531, 'reg_alpha': 2.022548307178075e-05, 'reg_lambda': 1.962539827907628, 'min_split_gain': 0.211554595585159}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:50,207] Trial 79 finished with value: 0.8402 and parameters: {'learning_rate': 0.012499073869277191, 'n_estimators': 600, 'num_leaves': 104, 'max_depth': 8, 'min_child_samples': 90, 'subsample': 0.6208843991711998, 'subsample_freq': 3, 'colsample_bytree': 0.8079567703539117, 'reg_alpha': 0.00012154776044923686, 'reg_lambda': 3.5963637538508926, 'min_split_gain': 0.19830342894047862}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:54,614] Trial 80 finished with value: 0.8404 and parameters: {'learning_rate': 0.013714835447637021, 'n_estimators': 650, 'num_leaves': 127, 'max_depth': 7, 'min_child_samples': 85, 'subsample': 0.6570193381043943, 'subsample_freq': 3, 'colsample_bytree': 0.7679227902818251, 'reg_alpha': 0.000351566150442825, 'reg_lambda': 0.11911450140248307, 'min_split_gain': 0.18316231366365965}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:24:59,759] Trial 81 finished with value: 0.841 and parameters: {'learning_rate': 0.010202123173843732, 'n_estimators': 700, 'num_leaves': 97, 'max_depth': 8, 'min_child_samples': 95, 'subsample': 0.602619656646964, 'subsample_freq': 1, 'colsample_bytree': 0.7950228904251079, 'reg_alpha': 1.212991498880672e-05, 'reg_lambda': 1.3989347114326334, 'min_split_gain': 0.22422406429361502}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:04,822] Trial 82 finished with value: 0.8411 and parameters: {'learning_rate': 0.011504869881645135, 'n_estimators': 650, 'num_leaves': 116, 'max_depth': 8, 'min_child_samples': 79, 'subsample': 0.6310764808947161, 'subsample_freq': 3, 'colsample_bytree': 0.7830264544683554, 'reg_alpha': 5.135647295906214e-05, 'reg_lambda': 0.6090426368239327, 'min_split_gain': 0.2445855353063175}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:09,027] Trial 83 finished with value: 0.8407 and parameters: {'learning_rate': 0.01564338387096595, 'n_estimators': 700, 'num_leaves': 123, 'max_depth': 8, 'min_child_samples': 100, 'subsample': 0.6159125838455898, 'subsample_freq': 2, 'colsample_bytree': 0.7702265612157081, 'reg_alpha': 3.4313611873418487e-06, 'reg_lambda': 4.785055315335057, 'min_split_gain': 0.15722520378563198}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:13,173] Trial 84 finished with value: 0.8413 and parameters: {'learning_rate': 0.013215317877327486, 'n_estimators': 600, 'num_leaves': 107, 'max_depth': 7, 'min_child_samples': 89, 'subsample': 0.6469614231987365, 'subsample_freq': 3, 'colsample_bytree': 0.7301657600785172, 'reg_alpha': 8.378284344676379e-06, 'reg_lambda': 0.35841865337901524, 'min_split_gain': 0.17565342679219542}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:16,849] Trial 85 finished with value: 0.8423 and parameters: {'learning_rate': 0.01778567270046262, 'n_estimators': 650, 'num_leaves': 95, 'max_depth': 8, 'min_child_samples': 83, 'subsample': 0.6224864061755085, 'subsample_freq': 3, 'colsample_bytree': 0.75078828980754, 'reg_alpha': 2.9450646213278076e-05, 'reg_lambda': 1.9212834221508852, 'min_split_gain': 0.29206166851237847}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:21,503] Trial 86 finished with value: 0.8405999999999999 and parameters: {'learning_rate': 0.010868476324923349, 'n_estimators': 600, 'num_leaves': 97, 'max_depth': 9, 'min_child_samples': 82, 'subsample': 0.6241011880672845, 'subsample_freq': 3, 'colsample_bytree': 0.761816769895826, 'reg_alpha': 7.801289939398352e-05, 'reg_lambda': 1.9794523433370772, 'min_split_gain': 0.32424428753316265}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:25,071] Trial 87 finished with value: 0.8422000000000001 and parameters: {'learning_rate': 0.018396209596412427, 'n_estimators': 550, 'num_leaves': 142, 'max_depth': 7, 'min_child_samples': 91, 'subsample': 0.6589576480876319, 'subsample_freq': 2, 'colsample_bytree': 0.745825334998156, 'reg_alpha': 2.991871436180121e-05, 'reg_lambda': 1.344146220631974, 'min_split_gain': 0.293333388823697}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:28,591] Trial 88 finished with value: 0.8429 and parameters: {'learning_rate': 0.018193111586111303, 'n_estimators': 550, 'num_leaves': 111, 'max_depth': 8, 'min_child_samples': 93, 'subsample': 0.6116036317209143, 'subsample_freq': 2, 'colsample_bytree': 0.7423853280394884, 'reg_alpha': 0.00019758809159244148, 'reg_lambda': 0.3229620884354699, 'min_split_gain': 0.294203627297089}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:31,686] Trial 89 finished with value: 0.8408999999999999 and parameters: {'learning_rate': 0.018842799981911684, 'n_estimators': 500, 'num_leaves': 141, 'max_depth': 6, 'min_child_samples': 87, 'subsample': 0.6048468485418576, 'subsample_freq': 1, 'colsample_bytree': 0.7070995093691413, 'reg_alpha': 0.00021286414733976962, 'reg_lambda': 0.1658566623896045, 'min_split_gain': 0.29469349867441613}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:35,675] Trial 90 finished with value: 0.8414999999999999 and parameters: {'learning_rate': 0.017287935326412273, 'n_estimators': 550, 'num_leaves': 138, 'max_depth': 9, 'min_child_samples': 93, 'subsample': 0.6586419798517327, 'subsample_freq': 2, 'colsample_bytree': 0.7356017743959232, 'reg_alpha': 0.0003903072977104013, 'reg_lambda': 0.3003847459957774, 'min_split_gain': 0.2759952792727299}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:36,668] Trial 91 finished with value: 0.8375 and parameters: {'learning_rate': 0.14159554144088238, 'n_estimators': 550, 'num_leaves': 111, 'max_depth': 8, 'min_child_samples': 96, 'subsample': 0.6390550708676456, 'subsample_freq': 2, 'colsample_bytree': 0.746327448001514, 'reg_alpha': 3.5468534743166874e-05, 'reg_lambda': 0.9585779308230766, 'min_split_gain': 0.317497783512775}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:40,756] Trial 92 finished with value: 0.8426 and parameters: {'learning_rate': 0.01197930904021886, 'n_estimators': 550, 'num_leaves': 118, 'max_depth': 8, 'min_child_samples': 92, 'subsample': 0.6122127412485922, 'subsample_freq': 2, 'colsample_bytree': 0.7213579339802083, 'reg_alpha': 0.00016424852623849658, 'reg_lambda': 0.08011939436702273, 'min_split_gain': 0.34287077955850065}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:42,153] Trial 93 finished with value: 0.8375999999999999 and parameters: {'learning_rate': 0.06757201731109898, 'n_estimators': 450, 'num_leaves': 106, 'max_depth': 8, 'min_child_samples': 98, 'subsample': 0.611474343022477, 'subsample_freq': 1, 'colsample_bytree': 0.7220644855873948, 'reg_alpha': 0.0008727073606170322, 'reg_lambda': 0.06279651512565053, 'min_split_gain': 0.34052329516375207}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:46,057] Trial 94 finished with value: 0.8417 and parameters: {'learning_rate': 0.01189658651916985, 'n_estimators': 550, 'num_leaves': 127, 'max_depth': 7, 'min_child_samples': 85, 'subsample': 0.6694458088024612, 'subsample_freq': 2, 'colsample_bytree': 0.6949254301132844, 'reg_alpha': 0.00012545138367240497, 'reg_lambda': 1.5166949469246263, 'min_split_gain': 0.297755167673635}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:49,857] Trial 95 finished with value: 0.8408999999999999 and parameters: {'learning_rate': 0.015462114685082948, 'n_estimators': 500, 'num_leaves': 102, 'max_depth': 8, 'min_child_samples': 92, 'subsample': 0.6485145983483183, 'subsample_freq': 3, 'colsample_bytree': 0.6812053303021113, 'reg_alpha': 1.631893196167896e-05, 'reg_lambda': 0.08893751592201436, 'min_split_gain': 0.31298611555228223}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:53,428] Trial 96 finished with value: 0.8408999999999999 and parameters: {'learning_rate': 0.017899779684829302, 'n_estimators': 600, 'num_leaves': 117, 'max_depth': 7, 'min_child_samples': 83, 'subsample': 0.6105487433207233, 'subsample_freq': 3, 'colsample_bytree': 0.7468898276346656, 'reg_alpha': 5.847217649902334e-05, 'reg_lambda': 2.4364250825064118, 'min_split_gain': 0.3488129757833989}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:25:57,045] Trial 97 finished with value: 0.8405000000000001 and parameters: {'learning_rate': 0.012233206170770197, 'n_estimators': 500, 'num_leaves': 112, 'max_depth': 9, 'min_child_samples': 97, 'subsample': 0.6020634417883852, 'subsample_freq': 2, 'colsample_bytree': 0.7289799203719705, 'reg_alpha': 0.0004890872013727459, 'reg_lambda': 6.06128405466027, 'min_split_gain': 0.2859183679456937}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:01,117] Trial 98 finished with value: 0.8409000000000001 and parameters: {'learning_rate': 0.010988269433345584, 'n_estimators': 550, 'num_leaves': 133, 'max_depth': 8, 'min_child_samples': 93, 'subsample': 0.62567430339236, 'subsample_freq': 3, 'colsample_bytree': 0.7071792612504297, 'reg_alpha': 0.0001996761162429844, 'reg_lambda': 0.5651467562054198, 'min_split_gain': 0.3716642801864883}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:04,543] Trial 99 finished with value: 0.8408999999999999 and parameters: {'learning_rate': 0.0168035964861058, 'n_estimators': 600, 'num_leaves': 101, 'max_depth': 6, 'min_child_samples': 86, 'subsample': 0.6390305932829284, 'subsample_freq': 2, 'colsample_bytree': 0.7755000805792533, 'reg_alpha': 1.0987662043439657e-08, 'reg_lambda': 0.34302272025259106, 'min_split_gain': 0.254890313953215}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:07,737] Trial 100 finished with value: 0.8400000000000001 and parameters: {'learning_rate': 0.02022479666251793, 'n_estimators': 450, 'num_leaves': 95, 'max_depth': 7, 'min_child_samples': 90, 'subsample': 0.6828639095065234, 'subsample_freq': 3, 'colsample_bytree': 0.7350051183967516, 'reg_alpha': 7.053806234595558e-05, 'reg_lambda': 1.321840950388026e-08, 'min_split_gain': 0.26817215448338494}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:12,275] Trial 101 finished with value: 0.8415000000000001 and parameters: {'learning_rate': 0.013399505885437743, 'n_estimators': 650, 'num_leaves': 117, 'max_depth': 8, 'min_child_samples': 91, 'subsample': 0.6215357739451506, 'subsample_freq': 2, 'colsample_bytree': 0.7648148742557317, 'reg_alpha': 3.177872651715441e-05, 'reg_lambda': 1.0453786892567054, 'min_split_gain': 0.2287641832680319}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:17,161] Trial 102 finished with value: 0.8414999999999999 and parameters: {'learning_rate': 0.01261890189372638, 'n_estimators': 700, 'num_leaves': 123, 'max_depth': 8, 'min_child_samples': 94, 'subsample': 0.615193019064978, 'subsample_freq': 1, 'colsample_bytree': 0.8022831085833916, 'reg_alpha': 2.0829236007322307e-05, 'reg_lambda': 0.6571849303205903, 'min_split_gain': 0.2966578211696032}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:21,142] Trial 103 finished with value: 0.842 and parameters: {'learning_rate': 0.015166430995458197, 'n_estimators': 650, 'num_leaves': 106, 'max_depth': 8, 'min_child_samples': 87, 'subsample': 0.6004499261079198, 'subsample_freq': 2, 'colsample_bytree': 0.7570766953514623, 'reg_alpha': 0.00012255647716095475, 'reg_lambda': 1.405013043226076, 'min_split_gain': 0.24797878440244314}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:25,189] Trial 104 finished with value: 0.8408 and parameters: {'learning_rate': 0.014973453055702707, 'n_estimators': 550, 'num_leaves': 104, 'max_depth': 8, 'min_child_samples': 87, 'subsample': 0.6335157215927817, 'subsample_freq': 2, 'colsample_bytree': 0.7543439623502808, 'reg_alpha': 0.00014783858598274197, 'reg_lambda': 2.7915429816573236, 'min_split_gain': 0.2531330582076891}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:29,011] Trial 105 finished with value: 0.8416 and parameters: {'learning_rate': 0.014256000093116993, 'n_estimators': 600, 'num_leaves': 106, 'max_depth': 7, 'min_child_samples': 84, 'subsample': 0.6076342558910787, 'subsample_freq': 3, 'colsample_bytree': 0.720615232770134, 'reg_alpha': 0.0029556975606859926, 'reg_lambda': 1.4340902414213952, 'min_split_gain': 0.2743888181006835}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:32,725] Trial 106 finished with value: 0.8416 and parameters: {'learning_rate': 0.018201153119141354, 'n_estimators': 700, 'num_leaves': 109, 'max_depth': 9, 'min_child_samples': 75, 'subsample': 0.6013174338165589, 'subsample_freq': 2, 'colsample_bytree': 0.7422577735116993, 'reg_alpha': 7.841873232633352e-06, 'reg_lambda': 0.15944935837882046, 'min_split_gain': 0.346622756558262}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:36,756] Trial 107 finished with value: 0.8417 and parameters: {'learning_rate': 0.016111582877590677, 'n_estimators': 650, 'num_leaves': 114, 'max_depth': 8, 'min_child_samples': 89, 'subsample': 0.6428639515616028, 'subsample_freq': 4, 'colsample_bytree': 0.7640856526984129, 'reg_alpha': 9.507691870643964e-05, 'reg_lambda': 1.4688974608434415, 'min_split_gain': 0.23620681026757867}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:41,315] Trial 108 finished with value: 0.8389999999999999 and parameters: {'learning_rate': 0.010500490243402284, 'n_estimators': 600, 'num_leaves': 99, 'max_depth': 7, 'min_child_samples': 100, 'subsample': 0.6541914563316229, 'subsample_freq': 0, 'colsample_bytree': 0.7720993770402325, 'reg_alpha': 1.2867644945769967e-05, 'reg_lambda': 5.681386775063015, 'min_split_gain': 0.19907340648973584}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:44,835] Trial 109 finished with value: 0.8399000000000001 and parameters: {'learning_rate': 0.019439838316187386, 'n_estimators': 550, 'num_leaves': 93, 'max_depth': 8, 'min_child_samples': 81, 'subsample': 0.7382839060221909, 'subsample_freq': 2, 'colsample_bytree': 0.7507641799978062, 'reg_alpha': 0.00022146457461584074, 'reg_lambda': 0.22636290990379687, 'min_split_gain': 0.2222374036921008}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:49,490] Trial 110 finished with value: 0.8422000000000001 and parameters: {'learning_rate': 0.013905684483103198, 'n_estimators': 700, 'num_leaves': 88, 'max_depth': 9, 'min_child_samples': 97, 'subsample': 0.6655105359482876, 'subsample_freq': 3, 'colsample_bytree': 0.7394451164315369, 'reg_alpha': 5.997124672290257e-05, 'reg_lambda': 3.097087970851857, 'min_split_gain': 0.2852684315287657}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:54,680] Trial 111 finished with value: 0.8413999999999999 and parameters: {'learning_rate': 0.010003689747486855, 'n_estimators': 700, 'num_leaves': 111, 'max_depth': 9, 'min_child_samples': 96, 'subsample': 0.6676309582304703, 'subsample_freq': 3, 'colsample_bytree': 0.7326028364247926, 'reg_alpha': 5.4987009147372625e-05, 'reg_lambda': 2.9494810935180786, 'min_split_gain': 0.28941915137991947}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:26:58,840] Trial 112 finished with value: 0.8409000000000001 and parameters: {'learning_rate': 0.013773668203709816, 'n_estimators': 750, 'num_leaves': 93, 'max_depth': 8, 'min_child_samples': 92, 'subsample': 0.6135937785400777, 'subsample_freq': 3, 'colsample_bytree': 0.7590662537419811, 'reg_alpha': 8.05885322271718e-05, 'reg_lambda': 0.39351352306602455, 'min_split_gain': 0.3042468749327503}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:04,133] Trial 113 finished with value: 0.8413 and parameters: {'learning_rate': 0.011839688296709025, 'n_estimators': 650, 'num_leaves': 87, 'max_depth': 9, 'min_child_samples': 88, 'subsample': 0.6340004926715564, 'subsample_freq': 3, 'colsample_bytree': 0.7143914134482269, 'reg_alpha': 2.579326075717757e-05, 'reg_lambda': 0.03568683202744324, 'min_split_gain': 0.3222058889898576}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:08,011] Trial 114 finished with value: 0.8413999999999999 and parameters: {'learning_rate': 0.01507740080909876, 'n_estimators': 650, 'num_leaves': 146, 'max_depth': 7, 'min_child_samples': 97, 'subsample': 0.6209717529037118, 'subsample_freq': 2, 'colsample_bytree': 0.7428534583833845, 'reg_alpha': 0.0003398183475177238, 'reg_lambda': 1.988029423311463, 'min_split_gain': 0.30542827108808307}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:12,225] Trial 115 finished with value: 0.841 and parameters: {'learning_rate': 0.01665856131419772, 'n_estimators': 800, 'num_leaves': 104, 'max_depth': 8, 'min_child_samples': 94, 'subsample': 0.6005565031028237, 'subsample_freq': 4, 'colsample_bytree': 0.7257385570905416, 'reg_alpha': 0.0013550682140110507, 'reg_lambda': 5.989875670564698, 'min_split_gain': 0.28252246287343363}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:15,656] Trial 116 finished with value: 0.8398999999999999 and parameters: {'learning_rate': 0.02152225458889987, 'n_estimators': 700, 'num_leaves': 23, 'max_depth': 9, 'min_child_samples': 77, 'subsample': 0.6823768676164984, 'subsample_freq': 3, 'colsample_bytree': 0.7790992413453572, 'reg_alpha': 0.0001398060550974294, 'reg_lambda': 3.384525600565145, 'min_split_gain': 0.26594760547921936}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:20,601] Trial 117 finished with value: 0.8421 and parameters: {'learning_rate': 0.011019381909481164, 'n_estimators': 750, 'num_leaves': 83, 'max_depth': 7, 'min_child_samples': 84, 'subsample': 0.6396947020629422, 'subsample_freq': 2, 'colsample_bytree': 0.7412501447366351, 'reg_alpha': 4.931142100843153e-05, 'reg_lambda': 0.9675727687278702, 'min_split_gain': 0.24850485083763604}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:24,888] Trial 118 finished with value: 0.8412000000000001 and parameters: {'learning_rate': 0.011260141149518522, 'n_estimators': 750, 'num_leaves': 83, 'max_depth': 6, 'min_child_samples': 84, 'subsample': 0.663512747291758, 'subsample_freq': 3, 'colsample_bytree': 0.7395592011831047, 'reg_alpha': 6.015148157834198e-06, 'reg_lambda': 0.5313813258243539, 'min_split_gain': 0.3344474348654181}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:26,502] Trial 119 finished with value: 0.8402 and parameters: {'learning_rate': 0.048846090069918253, 'n_estimators': 800, 'num_leaves': 129, 'max_depth': 7, 'min_child_samples': 80, 'subsample': 0.641597734557789, 'subsample_freq': 3, 'colsample_bytree': 0.7009440229425445, 'reg_alpha': 1.6188269820703173e-05, 'reg_lambda': 0.9604334592600113, 'min_split_gain': 0.40283131972063885}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:31,111] Trial 120 finished with value: 0.8398 and parameters: {'learning_rate': 0.012530912884581826, 'n_estimators': 750, 'num_leaves': 77, 'max_depth': 7, 'min_child_samples': 73, 'subsample': 0.6559148110478387, 'subsample_freq': 2, 'colsample_bytree': 0.6884947340851685, 'reg_alpha': 4.81742849806516e-05, 'reg_lambda': 9.860705756322393, 'min_split_gain': 0.46784850970569414}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:32,924] Trial 121 finished with value: 0.8343999999999999 and parameters: {'learning_rate': 0.013731927789517123, 'n_estimators': 200, 'num_leaves': 108, 'max_depth': 8, 'min_child_samples': 89, 'subsample': 0.6291499699766503, 'subsample_freq': 2, 'colsample_bytree': 0.7507956408392032, 'reg_alpha': 8.740460457050517e-05, 'reg_lambda': 1.3053505934461909, 'min_split_gain': 0.25436475600054376}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:37,794] Trial 122 finished with value: 0.8427999999999999 and parameters: {'learning_rate': 0.010950609645614088, 'n_estimators': 650, 'num_leaves': 137, 'max_depth': 8, 'min_child_samples': 87, 'subsample': 0.6111162666240777, 'subsample_freq': 2, 'colsample_bytree': 0.7578016548465867, 'reg_alpha': 2.717523107036682e-05, 'reg_lambda': 0.6721411373405561, 'min_split_gain': 0.23693158493255734}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:42,487] Trial 123 finished with value: 0.8415000000000001 and parameters: {'learning_rate': 0.011459170029886808, 'n_estimators': 700, 'num_leaves': 138, 'max_depth': 7, 'min_child_samples': 91, 'subsample': 0.6120478780334789, 'subsample_freq': 2, 'colsample_bytree': 0.792471187363293, 'reg_alpha': 2.3326681303399907e-05, 'reg_lambda': 0.2665767506077391, 'min_split_gain': 0.18503900685112842}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:47,141] Trial 124 finished with value: 0.8411000000000002 and parameters: {'learning_rate': 0.010637833504384162, 'n_estimators': 550, 'num_leaves': 141, 'max_depth': 8, 'min_child_samples': 86, 'subsample': 0.6497764040496431, 'subsample_freq': 1, 'colsample_bytree': 0.7671147610325926, 'reg_alpha': 1.0138501847268947e-05, 'reg_lambda': 0.7263373678830511, 'min_split_gain': 0.23824625990677614}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:50,992] Trial 125 finished with value: 0.8407 and parameters: {'learning_rate': 0.012172924721049713, 'n_estimators': 600, 'num_leaves': 145, 'max_depth': 7, 'min_child_samples': 98, 'subsample': 0.6245406100963666, 'subsample_freq': 4, 'colsample_bytree': 0.7236591761575341, 'reg_alpha': 4.209256363270048e-05, 'reg_lambda': 2.3862845186778046, 'min_split_gain': 0.2046810023096957}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:55,758] Trial 126 finished with value: 0.8402999999999998 and parameters: {'learning_rate': 0.010658822167413498, 'n_estimators': 650, 'num_leaves': 90, 'max_depth': 8, 'min_child_samples': 94, 'subsample': 0.6374439794140293, 'subsample_freq': 2, 'colsample_bytree': 0.73655371105915, 'reg_alpha': 2.402510641450587e-05, 'reg_lambda': 0.43000114308009296, 'min_split_gain': 0.22201337166172846}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:27:59,934] Trial 127 finished with value: 0.841 and parameters: {'learning_rate': 0.013520146882072651, 'n_estimators': 750, 'num_leaves': 150, 'max_depth': 7, 'min_child_samples': 82, 'subsample': 0.6176600520733382, 'subsample_freq': 3, 'colsample_bytree': 0.7471632107758784, 'reg_alpha': 6.289295511582541e-05, 'reg_lambda': 0.09067430867172176, 'min_split_gain': 0.2705663042685977}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:05,134] Trial 128 finished with value: 0.8419000000000001 and parameters: {'learning_rate': 0.012842292442549258, 'n_estimators': 700, 'num_leaves': 136, 'max_depth': 12, 'min_child_samples': 91, 'subsample': 0.6106569679762262, 'subsample_freq': 3, 'colsample_bytree': 0.7763365504624781, 'reg_alpha': 1.3333117450109667e-06, 'reg_lambda': 0.8414862273696352, 'min_split_gain': 0.16624651034288612}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:10,096] Trial 129 finished with value: 0.8418000000000001 and parameters: {'learning_rate': 0.011512527057868295, 'n_estimators': 600, 'num_leaves': 120, 'max_depth': 8, 'min_child_samples': 70, 'subsample': 0.6285050256032707, 'subsample_freq': 2, 'colsample_bytree': 0.9635446957586337, 'reg_alpha': 3.309514475446629e-05, 'reg_lambda': 4.085296919381023, 'min_split_gain': 0.3153344493616391}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:11,000] Trial 130 finished with value: 0.8335000000000001 and parameters: {'learning_rate': 0.296866466139374, 'n_estimators': 650, 'num_leaves': 134, 'max_depth': 7, 'min_child_samples': 78, 'subsample': 0.6444360095321836, 'subsample_freq': 3, 'colsample_bytree': 0.7575319045646526, 'reg_alpha': 1.3901586452478603e-05, 'reg_lambda': 2.4029313350204866, 'min_split_gain': 0.2321219241040956}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:15,333] Trial 131 finished with value: 0.8401 and parameters: {'learning_rate': 0.014467293983449713, 'n_estimators': 650, 'num_leaves': 115, 'max_depth': 8, 'min_child_samples': 86, 'subsample': 0.6085745846218011, 'subsample_freq': 2, 'colsample_bytree': 0.7402486430161539, 'reg_alpha': 0.00016824989189313902, 'reg_lambda': 1.5926559708627288, 'min_split_gain': 0.24444773098662725}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:19,451] Trial 132 finished with value: 0.8423 and parameters: {'learning_rate': 0.015516603993889775, 'n_estimators': 600, 'num_leaves': 100, 'max_depth': 8, 'min_child_samples': 88, 'subsample': 0.6173142404006696, 'subsample_freq': 2, 'colsample_bytree': 0.7621040966988079, 'reg_alpha': 0.00010680050962646574, 'reg_lambda': 0.007150642224785079, 'min_split_gain': 0.2597687328361127}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:23,347] Trial 133 finished with value: 0.8413 and parameters: {'learning_rate': 0.016800657845659105, 'n_estimators': 600, 'num_leaves': 95, 'max_depth': 8, 'min_child_samples': 84, 'subsample': 0.6211363023760458, 'subsample_freq': 2, 'colsample_bytree': 0.7626555497874562, 'reg_alpha': 0.0005774546800374689, 'reg_lambda': 0.004822269023093145, 'min_split_gain': 0.26365024449597324}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:26,761] Trial 134 finished with value: 0.8419000000000001 and parameters: {'learning_rate': 0.018388419912209592, 'n_estimators': 550, 'num_leaves': 99, 'max_depth': 8, 'min_child_samples': 89, 'subsample': 0.6342483014569248, 'subsample_freq': 1, 'colsample_bytree': 0.7146800491824599, 'reg_alpha': 0.0003083625422161152, 'reg_lambda': 0.0067276053179314696, 'min_split_gain': 0.35585055220018424}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:31,542] Trial 135 finished with value: 0.8405999999999999 and parameters: {'learning_rate': 0.010048407355522017, 'n_estimators': 600, 'num_leaves': 32, 'max_depth': 9, 'min_child_samples': 93, 'subsample': 0.6799584883343864, 'subsample_freq': 2, 'colsample_bytree': 0.7714011896734622, 'reg_alpha': 8.279883206079302e-05, 'reg_lambda': 0.012468354547764418, 'min_split_gain': 0.28229986944050955}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:35,175] Trial 136 finished with value: 0.8406 and parameters: {'learning_rate': 0.01574185878215543, 'n_estimators': 500, 'num_leaves': 144, 'max_depth': 8, 'min_child_samples': 96, 'subsample': 0.6252540002241571, 'subsample_freq': 3, 'colsample_bytree': 0.7306088948439737, 'reg_alpha': 4.873532639714086e-05, 'reg_lambda': 0.0014060912789691763, 'min_split_gain': 0.2985101681313904}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:41,933] Trial 137 finished with value: 0.841 and parameters: {'learning_rate': 0.0125897140596881, 'n_estimators': 700, 'num_leaves': 101, 'max_depth': 7, 'min_child_samples': 12, 'subsample': 0.6166179978671616, 'subsample_freq': 2, 'colsample_bytree': 0.7817264578528925, 'reg_alpha': 3.1650355469820534e-05, 'reg_lambda': 0.15099729156478417, 'min_split_gain': 0.43409833741982695}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:46,434] Trial 138 finished with value: 0.8417999999999999 and parameters: {'learning_rate': 0.013965366409629604, 'n_estimators': 750, 'num_leaves': 125, 'max_depth': 8, 'min_child_samples': 88, 'subsample': 0.6355862512279404, 'subsample_freq': 3, 'colsample_bytree': 0.8141663627410053, 'reg_alpha': 5.503576980040032e-06, 'reg_lambda': 0.6217722779298259, 'min_split_gain': 0.21647723555456402}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:50,985] Trial 139 finished with value: 0.8417999999999999 and parameters: {'learning_rate': 0.011111298007520755, 'n_estimators': 600, 'num_leaves': 88, 'max_depth': 7, 'min_child_samples': 90, 'subsample': 0.6520311136398027, 'subsample_freq': 2, 'colsample_bytree': 0.7468259143773799, 'reg_alpha': 0.00026869057707680564, 'reg_lambda': 0.29084801878614125, 'min_split_gain': 0.2607449237463225}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:55,158] Trial 140 finished with value: 0.8422000000000001 and parameters: {'learning_rate': 0.011989629902513954, 'n_estimators': 650, 'num_leaves': 111, 'max_depth': 6, 'min_child_samples': 99, 'subsample': 0.6082740190206983, 'subsample_freq': 4, 'colsample_bytree': 0.6579810113235329, 'reg_alpha': 1.7049637790463064e-05, 'reg_lambda': 0.023537504456614976, 'min_split_gain': 0.194855262044868}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:28:58,829] Trial 141 finished with value: 0.8408 and parameters: {'learning_rate': 0.011721943744500116, 'n_estimators': 650, 'num_leaves': 104, 'max_depth': 6, 'min_child_samples': 99, 'subsample': 0.608258136285638, 'subsample_freq': 4, 'colsample_bytree': 0.6438183032003272, 'reg_alpha': 1.7314948275976464e-05, 'reg_lambda': 0.026890537191375664, 'min_split_gain': 0.18976146957652273}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:02,459] Trial 142 finished with value: 0.8413 and parameters: {'learning_rate': 0.013140189378117003, 'n_estimators': 700, 'num_leaves': 111, 'max_depth': 6, 'min_child_samples': 95, 'subsample': 0.6173190187155447, 'subsample_freq': 4, 'colsample_bytree': 0.6165700197403401, 'reg_alpha': 8.920758465761208e-06, 'reg_lambda': 0.04337533665921914, 'min_split_gain': 0.20249494692472803}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:06,767] Trial 143 finished with value: 0.8406 and parameters: {'learning_rate': 0.012307960629010604, 'n_estimators': 600, 'num_leaves': 118, 'max_depth': 8, 'min_child_samples': 92, 'subsample': 0.6076041175067342, 'subsample_freq': 4, 'colsample_bytree': 0.7550860959597574, 'reg_alpha': 0.00010855111865573396, 'reg_lambda': 0.018577175982788387, 'min_split_gain': 0.15859826921001535}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:08,817] Trial 144 finished with value: 0.8371999999999999 and parameters: {'learning_rate': 0.014929565608896158, 'n_estimators': 650, 'num_leaves': 113, 'max_depth': 3, 'min_child_samples': 99, 'subsample': 0.6270782417178286, 'subsample_freq': 3, 'colsample_bytree': 0.6373878302374475, 'reg_alpha': 6.040493205664662e-05, 'reg_lambda': 0.05482720779297238, 'min_split_gain': 0.18138882550287727}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:11,872] Trial 145 finished with value: 0.8417 and parameters: {'learning_rate': 0.01719274844002392, 'n_estimators': 700, 'num_leaves': 96, 'max_depth': 5, 'min_child_samples': 97, 'subsample': 0.6424737200004753, 'subsample_freq': 4, 'colsample_bytree': 0.6711115148299245, 'reg_alpha': 2.3854955741714932e-05, 'reg_lambda': 4.570716198107596, 'min_split_gain': 0.19438279011988485}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:15,713] Trial 146 finished with value: 0.8405000000000001 and parameters: {'learning_rate': 0.01087242133554808, 'n_estimators': 500, 'num_leaves': 84, 'max_depth': 8, 'min_child_samples': 85, 'subsample': 0.6168434552453089, 'subsample_freq': 2, 'colsample_bytree': 0.7223541984308693, 'reg_alpha': 4.4404345693272216e-05, 'reg_lambda': 1.1035188485457672, 'min_split_gain': 0.2269202100021112}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:16,826] Trial 147 finished with value: 0.8382000000000002 and parameters: {'learning_rate': 0.10148536952123417, 'n_estimators': 800, 'num_leaves': 110, 'max_depth': 8, 'min_child_samples': 93, 'subsample': 0.6283540167678606, 'subsample_freq': 3, 'colsample_bytree': 0.6584950474176191, 'reg_alpha': 0.00020421060570448895, 'reg_lambda': 0.4718756868560165, 'min_split_gain': 0.41354569426669546}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:19,132] Trial 148 finished with value: 0.8389 and parameters: {'learning_rate': 0.02045098149842627, 'n_estimators': 600, 'num_leaves': 92, 'max_depth': 4, 'min_child_samples': 83, 'subsample': 0.6008954380924773, 'subsample_freq': 2, 'colsample_bytree': 0.76310503431487, 'reg_alpha': 1.16064478993042e-05, 'reg_lambda': 0.0109737681247772, 'min_split_gain': 0.21100117344564684}. Best is trial 71 with value: 0.843.\n",
      "[I 2025-11-08 19:29:24,955] Trial 149 finished with value: 0.8382 and parameters: {'learning_rate': 0.016073539228443495, 'n_estimators': 650, 'num_leaves': 99, 'max_depth': 9, 'min_child_samples': 27, 'subsample': 0.6371881177390891, 'subsample_freq': 4, 'colsample_bytree': 0.7090371972499926, 'reg_alpha': 8.405051769187903e-05, 'reg_lambda': 0.0031453099715776124, 'min_split_gain': 0.17383318864100392}. Best is trial 71 with value: 0.843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Ottimizzazione completata!\n",
      "Miglior Accuracy (CV media): 0.8430\n",
      "Migliori parametri:\n",
      "    learning_rate: 0.013679823261876542\n",
      "    n_estimators: 650\n",
      "    num_leaves: 97\n",
      "    max_depth: 7\n",
      "    min_child_samples: 70\n",
      "    subsample: 0.6161988793364829\n",
      "    subsample_freq: 4\n",
      "    colsample_bytree: 0.6136973726187104\n",
      "    reg_alpha: 2.261339389106705e-06\n",
      "    reg_lambda: 1.8764227095178463\n",
      "    min_split_gain: 0.3554832229238166\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd # Assicurati che pandas sia importato\n",
    "\n",
    "# 1. PREPARAZIONE DATI ROBUSTA\n",
    "# Identifica le colonne da escludere (ID, target, eventuali errori)\n",
    "cols_to_drop = ['battle_id', 'player_won', 'error']\n",
    "\n",
    "# Identifica automaticamente le colonne numeriche\n",
    "# Questo passaggio è fondamentale per evitare l'errore \"could not convert string to float\"\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# La lista finale delle feature è: (colonne numeriche) MENO (colonne da escludere)\n",
    "FEATURES = [c for c in numeric_cols if c not in cols_to_drop]\n",
    "\n",
    "print(f\"Feature numeriche selezionate: {len(FEATURES)}\")\n",
    "# print(f\"Esempio feature escluse (non numeriche): {[c for c in train_df.columns if c not in numeric_cols][:5]}\")\n",
    "\n",
    "# Crea le matrici X e y\n",
    "X = train_df[FEATURES].values\n",
    "y = train_df['player_won'].astype(int).values\n",
    "\n",
    "print(f\"Optuna ready: X shape {X.shape}, y shape {y.shape}\")\n",
    "\n",
    "# 2. DEFINIZIONE FUNZIONE OBIETTIVO (senza pruning callback per sicurezza)\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 7),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.5),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**param)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='binary_logloss',\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        )\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores.append(accuracy_score(y_val, preds))\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# 3. ESECUZIONE STUDIO OPTUNA\n",
    "# Se esiste già uno studio precedente in memoria, potresti volerlo cancellare o dargli un nuovo nome\n",
    "try:\n",
    "    optuna.delete_study(study_name='LGBM_Pokemon_V4', storage=None)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Inizio ottimizzazione Optuna...\")\n",
    "study = optuna.create_study(direction='maximize', study_name='LGBM_Pokemon_V4')\n",
    "\n",
    "# Esegui per N trial o per un tempo massimo (es. 30 minuti = 1800 secondi)\n",
    "# 20-30 trial potrebbero bastare per vedere un miglioramento se hai poco tempo\n",
    "study.optimize(objective, n_trials=150, timeout=7200) \n",
    "\n",
    "print(\"\\n✅ Ottimizzazione completata!\")\n",
    "print(f\"Miglior Accuracy (CV media): {study.best_value:.4f}\")\n",
    "print(\"Migliori parametri:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90672b94",
   "metadata": {},
   "source": [
    "# 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb30d229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10-Fold Cross-Validation - LightGBM ===\n",
      "Parametri utilizzati: {'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt', 'verbosity': -1, 'seed': 42, 'learning_rate': 0.013679823261876542, 'n_estimators': 650, 'num_leaves': 97, 'max_depth': 7, 'min_child_samples': 70, 'subsample': 0.6161988793364829, 'subsample_freq': 4, 'colsample_bytree': 0.6136973726187104, 'reg_alpha': 2.261339389106705e-06, 'reg_lambda': 1.8764227095178463, 'min_split_gain': 0.3554832229238166}\n",
      "\n",
      "Fold 1: train=9000, val=1000, val_acc=83.20%, train_acc=87.31%, gap=4.11%, best_iter=311\n",
      "Fold 2: train=9000, val=1000, val_acc=84.60%, train_acc=89.83%, gap=5.23%, best_iter=579\n",
      "Fold 3: train=9000, val=1000, val_acc=84.10%, train_acc=89.99%, gap=5.89%, best_iter=582\n",
      "Fold 4: train=9000, val=1000, val_acc=85.00%, train_acc=89.99%, gap=4.99%, best_iter=612\n",
      "Fold 5: train=9000, val=1000, val_acc=85.10%, train_acc=89.24%, gap=4.14%, best_iter=502\n",
      "Fold 6: train=9000, val=1000, val_acc=83.60%, train_acc=89.06%, gap=5.46%, best_iter=485\n",
      "Fold 7: train=9000, val=1000, val_acc=82.80%, train_acc=89.49%, gap=6.69%, best_iter=544\n",
      "Fold 8: train=9000, val=1000, val_acc=84.40%, train_acc=89.80%, gap=5.40%, best_iter=563\n",
      "Fold 9: train=9000, val=1000, val_acc=83.60%, train_acc=88.28%, gap=4.68%, best_iter=401\n",
      "Fold 10: train=9000, val=1000, val_acc=84.70%, train_acc=88.58%, gap=3.88%, best_iter=438\n",
      "\n",
      "============================================================\n",
      "Risultati Cross-Validation\n",
      "============================================================\n",
      "  Fold 1: val_acc=83.20%, train_acc=87.31%, gap=4.11%\n",
      "  Fold 2: val_acc=84.60%, train_acc=89.83%, gap=5.23%\n",
      "  Fold 3: val_acc=84.10%, train_acc=89.99%, gap=5.89%\n",
      "  Fold 4: val_acc=85.00%, train_acc=89.99%, gap=4.99%\n",
      "  Fold 5: val_acc=85.10%, train_acc=89.24%, gap=4.14%\n",
      "  Fold 6: val_acc=83.60%, train_acc=89.06%, gap=5.46%\n",
      "  Fold 7: val_acc=82.80%, train_acc=89.49%, gap=6.69%\n",
      "  Fold 8: val_acc=84.40%, train_acc=89.80%, gap=5.40%\n",
      "  Fold 9: val_acc=83.60%, train_acc=88.28%, gap=4.68%\n",
      "  Fold 10: val_acc=84.70%, train_acc=88.58%, gap=3.88%\n",
      "\n",
      "Mean CV accuracy: 84.11%\n",
      "Std CV accuracy:  0.74%\n",
      "Mean train accuracy: 89.16%\n",
      "Mean gap (train - val): 5.05%\n",
      "Min/Max val acc:  82.80% / 85.10%\n",
      "\n",
      "Peggiore fold: #7 con val_acc=82.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 10-Fold Cross-Validation - LightGBM ===\")\n",
    "best_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "    'learning_rate': 0.013679823261876542,\n",
    "    'n_estimators': 650,\n",
    "    'num_leaves': 97,\n",
    "    'max_depth': 7,\n",
    "    'min_child_samples': 70,\n",
    "    'subsample': 0.6161988793364829,\n",
    "    'subsample_freq': 4,\n",
    "    'colsample_bytree': 0.6136973726187104,\n",
    "    'reg_alpha': 2.261339389106705e-06,\n",
    "    'reg_lambda': 1.8764227095178463,\n",
    "    'min_split_gain': 0.3554832229238166\n",
    "}\n",
    "\n",
    "print(f\"Parametri utilizzati: {best_params}\\n\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_accuracies = []\n",
    "train_accuracies = []\n",
    "train_val_gaps = []\n",
    "folds_info = []\n",
    "\n",
    "fold_idx = 0\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    fold_idx += 1\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Train LightGBM con early stopping\n",
    "    clf = lgb.LGBMClassifier(**best_params)\n",
    "    clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Validation predictions\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_proba_val = clf.predict_proba(X_val)[:, 1]\n",
    "    val_acc = accuracy_score(y_val, y_pred_val)\n",
    "    outer_accuracies.append(val_acc)\n",
    "    \n",
    "    # Train accuracy\n",
    "    y_pred_tr = clf.predict(X_tr)\n",
    "    tr_acc = accuracy_score(y_tr, y_pred_tr)\n",
    "    gap = tr_acc - val_acc\n",
    "    train_accuracies.append(tr_acc)\n",
    "    train_val_gaps.append(gap)\n",
    "    \n",
    "    # Best iteration info\n",
    "    best_iter = clf.best_iteration_ if hasattr(clf, 'best_iteration_') else clf.n_estimators\n",
    "    \n",
    "    folds_info.append({\n",
    "        'fold': fold_idx,\n",
    "        'val_acc': float(val_acc),\n",
    "        'train_acc': float(tr_acc),\n",
    "        'gap': float(gap),\n",
    "        'best_iteration': int(best_iter),\n",
    "        'val_idx': val_idx,\n",
    "        'y_true': y_val.astype(int),\n",
    "        'y_pred': y_pred_val.astype(int),\n",
    "        'y_proba': y_proba_val.astype(float)\n",
    "    })\n",
    "    \n",
    "    print(f'Fold {fold_idx}: train={len(y_tr)}, val={len(y_val)}, '\n",
    "          f'val_acc={val_acc*100:.2f}%, train_acc={tr_acc*100:.2f}%, '\n",
    "          f'gap={gap*100:.2f}%, best_iter={best_iter}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Risultati Cross-Validation')\n",
    "print('='*60)\n",
    "for i, info in enumerate(folds_info, 1):\n",
    "    print(f\"  Fold {i}: val_acc={info['val_acc']*100:.2f}%, \"\n",
    "          f\"train_acc={info['train_acc']*100:.2f}%, gap={info['gap']*100:.2f}%\")\n",
    "\n",
    "print(f'\\nMean CV accuracy: {np.mean(outer_accuracies)*100:.2f}%')\n",
    "print(f'Std CV accuracy:  {np.std(outer_accuracies)*100:.2f}%')\n",
    "print(f'Mean train accuracy: {np.mean(train_accuracies)*100:.2f}%')\n",
    "print(f'Mean gap (train - val): {np.mean(train_val_gaps)*100:.2f}%')\n",
    "print(f'Min/Max val acc:  {np.min(outer_accuracies)*100:.2f}% / {np.max(outer_accuracies)*100:.2f}%')\n",
    "\n",
    "worst_idx = int(np.argmin(outer_accuracies))\n",
    "print(f\"\\nPeggiore fold: #{worst_idx+1} con val_acc={outer_accuracies[worst_idx]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56eb9c",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c5a5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission con LightGBM trainato su tutto il dataset ===\n",
      "✅ File di submission salvato in submission_lightgbm.csv\n",
      "Modello: LightGBM trainato su 10000 samples\n",
      "Stima CV accuracy: 84.11% ± 0.74%\n",
      "Mean gap: 5.05%\n",
      "\n",
      "Preview submission:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           1\n",
       "2          2           1\n",
       "3          3           1\n",
       "4          4           1\n",
       "5          5           1\n",
       "6          6           1\n",
       "7          7           1\n",
       "8          8           1\n",
       "9          9           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuzione predizioni: {0: 2542, 1: 2458}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Submission con LightGBM trainato su tutto il dataset ===\")\n",
    "\n",
    "# Train finale su tutto il dataset\n",
    "submission_model = lgb.LGBMClassifier(**best_params)\n",
    "submission_model.fit(X, y)\n",
    "\n",
    "# Predict su test\n",
    "X_test_matrix = test_preproc_df.values\n",
    "test_predictions = submission_model.predict(X_test_matrix).astype(int)\n",
    "\n",
    "# Crea submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'].astype(np.int64),\n",
    "    'player_won': test_predictions.astype(np.int64)\n",
    "})\n",
    "\n",
    "submission_path = 'submission_lightgbm.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"✅ File di submission salvato in {submission_path}\")\n",
    "print(f\"Modello: LightGBM trainato su {len(X)} samples\")\n",
    "print(f\"Stima CV accuracy: {np.mean(outer_accuracies)*100:.2f}% ± {np.std(outer_accuracies)*100:.2f}%\")\n",
    "print(f\"Mean gap: {np.mean(train_val_gaps)*100:.2f}%\")\n",
    "print(\"\\nPreview submission:\")\n",
    "display(submission_df.head(10))\n",
    "print(f\"\\nDistribuzione predizioni: {submission_df['player_won'].value_counts().to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
